{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-wfQGGu8Q1P6"
   },
   "source": [
    "# Your name:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fy5axhusQ1P_"
   },
   "source": [
    "# Starter Code for Google Colab\n",
    "\n",
    "This notebook implements starter code to help you get started with the assignment. This starter code can be used when you are using the Google Colab for this lab assignment. Copy this file to your Google Drive, and open this notebook with the Google Colab.\n",
    "\n",
    "To run this notebook you must __download all the data files from the Kaggle competition page into your google drive (e.g., to the folder with name \"dataset\")__. \n",
    "\n",
    "To use GPU acceleration with Google Colab, select 'GPU' in Edit > Notebook settings > Hardware accelerator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GZ3JQWb_Q1P_"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "params = {\n",
    "    'log_interval': 1000,\n",
    "    'epochs': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LS5l0MbVTYWX",
    "outputId": "20af62f9-ab36-41fc-d432-102a4d37c0fb"
   },
   "outputs": [],
   "source": [
    "# Check the GPU\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"Using {}\".format('GPU' if use_cuda else 'CPU'))\n",
    "\n",
    "# Mounting the dataset foloder in the drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "PATH=\"/content/drive/MyDrive/dataset\" # \"PATH TO YOUR DATASET FOLDER IN YOUR GOOGLE DRIVE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XejwavirT2De",
    "outputId": "348737db-f3e9-46df-ed8d-e9587114be7f"
   },
   "outputs": [],
   "source": [
    "# Check whether the dataset drive has been mounted correctly\n",
    "!ls \"/content/drive/MyDrive/dataset\"\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "udMX6PJ-Q1QA"
   },
   "source": [
    "## Load the dataset\n",
    "\n",
    "Read the class labels from the train_labels.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rKCJCydCQ1QA"
   },
   "outputs": [],
   "source": [
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "def read_labels(label_file):\n",
    "    labels = np.zeros(50000).astype(np.uint8)\n",
    "    with open(label_file, 'r') as f:\n",
    "        n, header_seen = 0, False\n",
    "        for line in f:\n",
    "            if not header_seen:\n",
    "                header_seen = True\n",
    "                continue\n",
    "            labels[n] = int(line.strip().split(',')[1])\n",
    "            n += 1\n",
    "    return labels\n",
    "\n",
    "train_val_labels = read_labels(os.path.join(PATH, \"train_labels.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wohnex-GQ1QA",
    "outputId": "89661923-8f46-42c0-aac5-c38b821839e3"
   },
   "outputs": [],
   "source": [
    "train_val_images = np.load(os.path.join(PATH, \"train_data.npy\"))\n",
    "# train_val_images = np.transpose(train_val_images, (0,3,1,2))\n",
    "train_val_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AUBWyfYZQ1QB"
   },
   "source": [
    "Load training and validation image datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sC_bRg8cQ1QB"
   },
   "source": [
    "Split the training dataset into a training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Njj7rSuGQ1QB"
   },
   "outputs": [],
   "source": [
    "train_labels = train_val_labels[:40000]\n",
    "val_labels = train_val_labels[40000:]\n",
    "all_labels = {'train': train_labels, 'validation': val_labels}\n",
    "\n",
    "train_images = train_val_images[:40000]\n",
    "val_images = train_val_images[40000:]\n",
    "all_images = {'train': train_images, 'validation': val_images}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "onu0BP8MQ1QB"
   },
   "source": [
    "Visualize a few sample training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "id": "Kg2S9RlUQ1QB",
    "outputId": "af6cdc3b-9ee1-4f8b-a575-fdcd41b2feb0"
   },
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(8,4))\n",
    "\n",
    "train_to_plot = np.transpose(train_images, (0,2,3,1))\n",
    "H, W = 6, 3\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        n = y*W+x\n",
    "        plt.subplot(W,H,n+1)\n",
    "        plt.imshow(train_to_plot[n, :, :, :])\n",
    "        plt.title(\"%s\" % (class_names[train_labels[n]]))\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzvONFJdQ1QC"
   },
   "source": [
    "## Network Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TlibTy8SQ1QC"
   },
   "source": [
    "Starter code to set up the network and optimizer (from the PyTorch tutorial page). You will almost certainly need to use a better network topology here. Also, copy the network definition to `network-profile.ipynb` and run the energy/latency estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yQ0wBhnzQ1QC"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3lV6qJbQ1QE"
   },
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XFtN1gJxQ1QE",
    "outputId": "d61b72e3-dee3-4a74-e4fb-3f6c12640ec4"
   },
   "outputs": [],
   "source": [
    "# convert numpy arrays to format required for pytorch\n",
    "\n",
    "train_images_torch = torch.from_numpy(np.expand_dims(train_images, axis=1))\n",
    "train_images_torch = (train_images_torch/255.0)*2.0-1 # normalization [-1 to 1]\n",
    "train_labels_torch = torch.from_numpy(train_labels)\n",
    "\n",
    "val_images_torch = torch.from_numpy(np.expand_dims(val_images, axis=1))\n",
    "val_images_torch = (val_images_torch/255.0)*2.0-1 # normalization [-1 to 1]\n",
    "val_labels_torch = torch.from_numpy(val_labels)\n",
    "\n",
    "# initialize weights and biases\n",
    "nn.init.kaiming_uniform_(net.conv1.weight, nonlinearity = 'relu')\n",
    "stdv = 1./np.sqrt(net.conv1.bias.size(0))\n",
    "nn.init.uniform_(net.conv1.bias, -stdv, stdv)\n",
    "nn.init.kaiming_uniform_(net.conv2.weight, nonlinearity = 'relu')\n",
    "stdv = 1./np.sqrt(net.conv2.bias.size(0))\n",
    "nn.init.uniform_(net.conv2.bias, -stdv, stdv)\n",
    "nn.init.kaiming_uniform_(net.fc1.weight, nonlinearity = 'relu')\n",
    "stdv = 1./np.sqrt(net.fc1.bias.size(0))\n",
    "nn.init.uniform_(net.fc1.bias, -stdv, stdv)\n",
    "nn.init.kaiming_uniform_(net.fc2.weight, nonlinearity = 'relu')\n",
    "stdv = 1./np.sqrt(net.fc2.bias.size(0))\n",
    "nn.init.uniform_(net.fc2.bias, -stdv, stdv)\n",
    "nn.init.kaiming_uniform_(net.fc3.weight, nonlinearity = 'relu')\n",
    "stdv = 1./np.sqrt(net.fc2.bias.size(0))\n",
    "nn.init.uniform_(net.fc2.bias, -stdv, stdv)\n",
    "\n",
    "training_error_log = np.zeros(int(params['epochs']*train_images_torch.shape[0]/params['log_interval']))\n",
    "training_loss_log = np.zeros(int(params['epochs']*train_images_torch.shape[0]/params['log_interval']))\n",
    "valid_error_vect = np.zeros(params['epochs'])\n",
    "\n",
    "if use_cuda:\n",
    "    net.cuda()\n",
    "    criterion.cuda()\n",
    "\n",
    "# train\n",
    "for epoch in range(params['epochs']):  # loop over the dataset multiple times\n",
    "\n",
    "    total_train = 0\n",
    "    correct_train = 0\n",
    "    \n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i in range(train_images_torch.shape[0]):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs = train_images_torch[i].float()\n",
    "        labels = train_labels_torch[i].long()\n",
    "        labels = labels.unsqueeze(0)\n",
    "        if use_cuda:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        #print(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        training_error = 1 - correct_train / total_train\n",
    "        if i % params['log_interval'] == params['log_interval']-1:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f, training error: %.1f%%' % \n",
    "                  (epoch + 1, i + 1, running_loss / params['log_interval'], training_error*100))\n",
    "            training_loss_log[int((epoch*train_images_torch.shape[0]/params['log_interval'])+(i+1)/params['log_interval']-1)] = running_loss/params['log_interval']\n",
    "            training_error_log[int((epoch*train_images_torch.shape[0]/params['log_interval'])+(i+1)/params['log_interval']-1)] = training_error\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    # calculate validation accuracy after every epoch\n",
    "    with torch.no_grad():\n",
    "        for i in range(val_images_torch.shape[0]):\n",
    "            images = val_images_torch[i].float()\n",
    "            labels = val_labels_torch[i].long()\n",
    "            labels = labels.unsqueeze(0)\n",
    "            if use_cuda:\n",
    "                images, labels = images.cuda(), labels.cuda()\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "            \n",
    "    print('Error on validation set after epoch %d: %.1f %%' % (epoch+1,\n",
    "    100*(1 - correct_val / total_val)))\n",
    "    valid_error = 1 - correct_val / total_val\n",
    "    valid_error_vect[epoch] = valid_error\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWgY_Ge-Q1QF"
   },
   "source": [
    "## Test the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ela-wXm_Q1QF"
   },
   "source": [
    "Some metrics from training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "id": "tqsrnFHjQ1QF",
    "outputId": "3a637a69-a4a5-45a8-8a98-ebf72e5f81bc"
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(np.arange(training_loss_log.size)*params['log_interval'], training_loss_log, 'o')\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(np.arange(training_error_log.size)*params['log_interval'], training_error_log, '-o')\n",
    "plt.plot(np.arange(valid_error_vect.size)*train_images_torch.shape[0]+train_images_torch.shape[0], valid_error_vect, '-o')\n",
    "\n",
    "print(\"Final Training Accuracy: %g%%\" % ((1-training_error_log[-1])*100))\n",
    "print(\"Final Validation Accuracy: %g%%\" % ((1-valid_error_vect[-1])*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e03wVRckQ1QF"
   },
   "source": [
    "Save model& download the model from the colab workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "Qe-jHXS5Q1QG",
    "outputId": "d9258cdf-1ce5-4bf1-b6f1-7d921a90444a"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "MODELPATH = './cifar10_sample.pth.tar'\n",
    "torch.save(net.state_dict(), MODELPATH)\n",
    "files.download('./cifar10_sample.pth.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "blm4RyErQ1QG"
   },
   "source": [
    "## Estimate assignment grade on validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzyZLJ1G6CZJ"
   },
   "source": [
    "Run the network profiler in `network-profile.ipynb` using your model description. Then copy your result into the network_complexity dictionary below. Please check the unit conversion, and round the value to four decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "balOYRtL6CZJ"
   },
   "outputs": [],
   "source": [
    "network_complexity = {}\n",
    "network_complexity['energy'] = 0.02305514 # Estimated energy in mJ.\n",
    "network_complexity['latency'] = 0.02236600 # Number of cycles in Million (1e6).\n",
    "network_complexity['activation'] = 31104 # Activation size in byte. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IN4OjTEnQ1QG",
    "outputId": "429f4686-40a6-4473-f614-17b35840f62f"
   },
   "outputs": [],
   "source": [
    "accuracy = 1-valid_error_vect[-1]\n",
    "\n",
    "def get_score(accuracy, network_complexity):\n",
    "    error_rate = (1-accuracy) * 100\n",
    "    loss = error_rate / 12 + network_complexity['latency'] / 0.3\n",
    "    \n",
    "    if error_rate > 50:\n",
    "        return (0, loss)\n",
    "    elif network_complexity['activation'] > 1000000:\n",
    "        return (0, loss)\n",
    "    else:\n",
    "        score = 0\n",
    "        if network_complexity['energy'] > 2:\n",
    "            score += 0\n",
    "        elif network_complexity['energy'] > 1.5:\n",
    "            score += 5\n",
    "        elif network_complexity['energy'] > 1:\n",
    "            score += 10\n",
    "        elif network_complexity['energy'] > 0.5:\n",
    "            score += 15\n",
    "        else:\n",
    "            score += 20\n",
    "            \n",
    "        if network_complexity['latency'] > 1:\n",
    "            score += 0\n",
    "        elif network_complexity['latency'] > 0.5:\n",
    "            score += 5\n",
    "        elif network_complexity['latency'] > 0.25:\n",
    "            score += 10\n",
    "        elif network_complexity['latency'] > 0.1:\n",
    "            score += 15\n",
    "        else:\n",
    "            score += 20\n",
    "            \n",
    "        if error_rate < 5:\n",
    "            score += 80\n",
    "        elif error_rate < 10:\n",
    "            score += 70\n",
    "        elif error_rate < 20:\n",
    "            score += 60\n",
    "        elif error_rate < 30:\n",
    "            score += 50\n",
    "        elif error_rate < 40:\n",
    "            score += 40\n",
    "        else:\n",
    "            score += 30\n",
    "            \n",
    "        return (score, loss)\n",
    "\n",
    "base_score, loss = get_score(accuracy, network_complexity)\n",
    "    \n",
    "# Calculated at the end of the competition based on everyones loss\n",
    "competition_bonus = 0\n",
    "final_score = base_score + (competition_bonus if base_score > 0 else 0)\n",
    "\n",
    "print(\"Base Score: %d, Loss: %g\" % (base_score, loss))\n",
    "print(\"Final Score: %d\" % (final_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3aQD_rY7dUc0"
   },
   "source": [
    "## Generate a Kaggle submission file and download the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "id": "B0lc3JGOQ1QG",
    "outputId": "4dfcbd9b-f2dd-4520-cbe6-e7a0685811ae"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def create_submission(labels, network_complexity):\n",
    "    now = time.time()\n",
    "    now_str = datetime.datetime.fromtimestamp(now).strftime('%m%d-%H%M%S')\n",
    "    complexity_str = '{:.4f}-{:.4f}-{}'.format(network_complexity['energy'], \\\n",
    "                                               network_complexity['latency'], \\\n",
    "                                               network_complexity['activation']).replace('.', 'p')\n",
    "    filename = 'submission-%s-%s.csv' % (complexity_str, now_str)\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for n in range(labels.shape[0]):\n",
    "            f.write(\"%d,%d\\n\" % (n,labels[n]))\n",
    "    return now_str, filename\n",
    "\n",
    "\n",
    "test_images = np.load(os.path.join(PATH, \"test_data.npy\"))\n",
    "\n",
    "# convert to torch format\n",
    "test_images = torch.from_numpy(np.expand_dims(test_images, axis=1))\n",
    "test_result = torch.zeros(test_images.shape[0])\n",
    "\n",
    "# test on validation data\n",
    "with torch.no_grad():\n",
    "    for i in range(test_images.shape[0]):\n",
    "        images = test_images[i]\n",
    "        images = (images/255.0)*2.0-1 # normalization [-1 to 1]\n",
    "        images = images.float() # convert to torch format\n",
    "        if use_cuda:\n",
    "            images =images.cuda()\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        test_result[i] = predicted\n",
    "        if i % 10000 == 9999:\n",
    "            print('Test data processed: %d/300000' % (i+1))\n",
    "\n",
    "now_str, filename = create_submission(test_result.numpy(), network_complexity)\n",
    "files.download(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-P9MmUcR6CZK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "starter-code-colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
