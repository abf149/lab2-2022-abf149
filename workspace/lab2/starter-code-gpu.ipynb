{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your name:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starter Code\n",
    "\n",
    "This notebook implements starter code to help you get started with the assignment. If you have a personal GPU, copy this starter code to another directory and run this notebook using your personal GPU. In that case, the docker we provide will not support PyTorch with GPU, and you can create your own virtual environment (e.g., conda) with PyTorch support (https://pytorch.org/get-started/locally/). \n",
    "\n",
    "To run this notebook you must __first create a folder called `./dataset` and download all the data files from the Kaggle competition page__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "params = {\n",
    "    'log_interval': 1000,\n",
    "    'epochs': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU setup\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"Using {}\".format('GPU' if use_cuda else 'CPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "\n",
    "Read the class labels from the train_labels.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "def read_labels(label_file):\n",
    "    labels = np.zeros(50000).astype(np.uint8)\n",
    "    with open(label_file, 'r') as f:\n",
    "        n, header_seen = 0, False\n",
    "        for line in f:\n",
    "            if not header_seen:\n",
    "                header_seen = True\n",
    "                continue\n",
    "            labels[n] = int(line.strip().split(',')[1])\n",
    "            n += 1\n",
    "    return labels\n",
    "\n",
    "train_val_labels = read_labels(\"dataset/train_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_images = np.load(\"dataset/train_data.npy\")\n",
    "# train_val_images = np.transpose(train_val_images, (0,3,1,2))\n",
    "train_val_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training and validation image datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the training dataset into a training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_val_labels[:40000]\n",
    "val_labels = train_val_labels[40000:]\n",
    "all_labels = {'train': train_labels, 'validation': val_labels}\n",
    "\n",
    "train_images = train_val_images[:40000]\n",
    "val_images = train_val_images[40000:]\n",
    "all_images = {'train': train_images, 'validation': val_images}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize a few sample training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(8,4))\n",
    "\n",
    "train_to_plot = np.transpose(train_images, (0,2,3,1))\n",
    "H, W = 6, 3\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        n = y*W+x\n",
    "        plt.subplot(W,H,n+1)\n",
    "        plt.imshow(train_to_plot[n, :, :, :])\n",
    "        plt.title(\"%s\" % (class_names[train_labels[n]]))\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Definition\n",
    "\n",
    "Starter code to set up the network and optimizer (from the PyTorch tutorial page). You will almost certainly need to use a better network topology here. Also, copy the network definition to `network-profile.ipynb` and run the energy/latency estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starter code to set up the network and optimizer (from the PyTorch tutorial page). You will almost certainly need to use a better network topology here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numpy arrays to format required for pytorch\n",
    "\n",
    "train_images_torch = torch.from_numpy(np.expand_dims(train_images, axis=1))\n",
    "train_images_torch = (train_images_torch/255.0)*2.0-1 # normalization [-1 to 1]\n",
    "train_labels_torch = torch.from_numpy(train_labels)\n",
    "\n",
    "val_images_torch = torch.from_numpy(np.expand_dims(val_images, axis=1))\n",
    "val_images_torch = (val_images_torch/255.0)*2.0-1 # normalization [-1 to 1]\n",
    "val_labels_torch = torch.from_numpy(val_labels)\n",
    "\n",
    "# initialize weights and biases\n",
    "nn.init.kaiming_uniform_(net.conv1.weight, nonlinearity = 'relu')\n",
    "stdv = 1./np.sqrt(net.conv1.bias.size(0))\n",
    "nn.init.uniform_(net.conv1.bias, -stdv, stdv)\n",
    "nn.init.kaiming_uniform_(net.conv2.weight, nonlinearity = 'relu')\n",
    "stdv = 1./np.sqrt(net.conv2.bias.size(0))\n",
    "nn.init.uniform_(net.conv2.bias, -stdv, stdv)\n",
    "nn.init.kaiming_uniform_(net.fc1.weight, nonlinearity = 'relu')\n",
    "stdv = 1./np.sqrt(net.fc1.bias.size(0))\n",
    "nn.init.uniform_(net.fc1.bias, -stdv, stdv)\n",
    "nn.init.kaiming_uniform_(net.fc2.weight, nonlinearity = 'relu')\n",
    "stdv = 1./np.sqrt(net.fc2.bias.size(0))\n",
    "nn.init.uniform_(net.fc2.bias, -stdv, stdv)\n",
    "nn.init.kaiming_uniform_(net.fc3.weight, nonlinearity = 'relu')\n",
    "stdv = 1./np.sqrt(net.fc2.bias.size(0))\n",
    "nn.init.uniform_(net.fc2.bias, -stdv, stdv)\n",
    "\n",
    "training_error_log = np.zeros(int(params['epochs']*train_images_torch.shape[0]/params['log_interval']))\n",
    "training_loss_log = np.zeros(int(params['epochs']*train_images_torch.shape[0]/params['log_interval']))\n",
    "valid_error_vect = np.zeros(params['epochs'])\n",
    "\n",
    "if use_cuda:\n",
    "    net.cuda()\n",
    "    criterion.cuda()\n",
    "    \n",
    "# train\n",
    "for epoch in range(params['epochs']):  # loop over the dataset multiple times\n",
    "\n",
    "    total_train = 0\n",
    "    correct_train = 0\n",
    "    \n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i in range(train_images_torch.shape[0]):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs = train_images_torch[i].float()\n",
    "        labels = train_labels_torch[i].long()\n",
    "        labels = labels.unsqueeze(0)\n",
    "        #print(labels)\n",
    "        if use_cuda:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        training_error = 1 - correct_train / total_train\n",
    "        if i % params['log_interval'] == params['log_interval']-1:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f, training error: %.1f%%' % \n",
    "                  (epoch + 1, i + 1, running_loss / params['log_interval'], training_error*100))\n",
    "            training_loss_log[int((epoch*train_images_torch.shape[0]/params['log_interval'])+(i+1)/params['log_interval']-1)] = running_loss/params['log_interval']\n",
    "            training_error_log[int((epoch*train_images_torch.shape[0]/params['log_interval'])+(i+1)/params['log_interval']-1)] = training_error\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    # calculate validation accuracy after every epoch\n",
    "    with torch.no_grad():\n",
    "        for i in range(val_images_torch.shape[0]):\n",
    "            images = val_images_torch[i].float()\n",
    "            labels = val_labels_torch[i].long()\n",
    "            labels = labels.unsqueeze(0)\n",
    "            if use_cuda:\n",
    "                images, labels = images.cuda(), labels.cuda()\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "            \n",
    "    print('Error on validation set after epoch %d: %.1f %%' % (epoch+1,\n",
    "    100*(1 - correct_val / total_val)))\n",
    "    valid_error = 1 - correct_val / total_val\n",
    "    valid_error_vect[epoch] = valid_error\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some metrics from training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(np.arange(training_loss_log.size)*params['log_interval'], training_loss_log, 'o')\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(np.arange(training_error_log.size)*params['log_interval'], training_error_log, '-o')\n",
    "plt.plot(np.arange(valid_error_vect.size)*train_images_torch.shape[0]+train_images_torch.shape[0], valid_error_vect, '-o')\n",
    "\n",
    "print(\"Final Training Accuracy: %g%%\" % ((1-training_error_log[-1])*100))\n",
    "print(\"Final Validation Accuracy: %g%%\" % ((1-valid_error_vect[-1])*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELPATH = './cifar10_sample.pth.tar'\n",
    "torch.save(net.state_dict(), MODELPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate assignment grade on validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the network profiler in `network-profile.ipynb` using your model description. Then copy your result into the network_complexity dictionary below. Please check the unit conversion, and round the value to four decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_complexity = {}\n",
    "network_complexity['energy'] = 0.02305514 # Estimated energy in mJ.\n",
    "network_complexity['latency'] = 0.02236600 # Number of cycles in Million (1e6).\n",
    "network_complexity['activation'] = 31104 # Activation size in byte. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 1-valid_error_vect[-1]\n",
    "\n",
    "def get_score(accuracy, network_complexity):\n",
    "    error_rate = (1-accuracy) * 100\n",
    "    loss = error_rate / 12 + network_complexity['latency'] / 0.3\n",
    "    \n",
    "    if error_rate > 50:\n",
    "        return (0, loss)\n",
    "    elif network_complexity['activation'] > 1000000:\n",
    "        return (0, loss)\n",
    "    else:\n",
    "        score = 0\n",
    "        if network_complexity['energy'] > 2:\n",
    "            score += 0\n",
    "        elif network_complexity['energy'] > 1.5:\n",
    "            score += 5\n",
    "        elif network_complexity['energy'] > 1:\n",
    "            score += 10\n",
    "        elif network_complexity['energy'] > 0.5:\n",
    "            score += 15\n",
    "        else:\n",
    "            score += 20\n",
    "            \n",
    "        if network_complexity['latency'] > 1:\n",
    "            score += 0\n",
    "        elif network_complexity['latency'] > 0.5:\n",
    "            score += 5\n",
    "        elif network_complexity['latency'] > 0.25:\n",
    "            score += 10\n",
    "        elif network_complexity['latency'] > 0.1:\n",
    "            score += 15\n",
    "        else:\n",
    "            score += 20\n",
    "            \n",
    "        if error_rate < 5:\n",
    "            score += 80\n",
    "        elif error_rate < 10:\n",
    "            score += 70\n",
    "        elif error_rate < 20:\n",
    "            score += 60\n",
    "        elif error_rate < 30:\n",
    "            score += 50\n",
    "        elif error_rate < 40:\n",
    "            score += 40\n",
    "        else:\n",
    "            score += 30\n",
    "            \n",
    "        return (score, loss)\n",
    "\n",
    "base_score, loss = get_score(accuracy, network_complexity)\n",
    "    \n",
    "# Calculated at the end of the competition based on everyones loss\n",
    "competition_bonus = 0\n",
    "final_score = base_score + (competition_bonus if base_score > 0 else 0)\n",
    "\n",
    "print(\"Base Score: %d, Loss: %g\" % (base_score, loss))\n",
    "print(\"Final Score: %d\" % (final_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a Kaggle submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def create_submission(labels):\n",
    "    now = time.time()\n",
    "    now_str = datetime.datetime.fromtimestamp(now).strftime('%m%d-%H%M%S')\n",
    "    complexity_str = '{:.4f}-{:.4f}-{}'.format(network_complexity['energy'], \\\n",
    "                                               network_complexity['latency'], \\\n",
    "                                               network_complexity['activation']).replace('.', 'p')\n",
    "    filename = 'submission-%s-%s.csv' % (complexity_str, now_str)\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for n in range(labels.shape[0]):\n",
    "            f.write(\"%d,%d\\n\" % (n,labels[n]))\n",
    "    return now_str, filename\n",
    "\n",
    "test_images = np.load(\"dataset/test_data.npy\")\n",
    "\n",
    "# convert to torch format\n",
    "test_images = torch.from_numpy(np.expand_dims(test_images, axis=1))\n",
    "test_result = torch.zeros(test_images.shape[0])\n",
    "\n",
    "# test on validation data\n",
    "with torch.no_grad():\n",
    "    for i in range(test_images.shape[0]):\n",
    "        images = test_images[i]\n",
    "        images = (images/255.0)*2.0-1 # normalization [-1 to 1]\n",
    "        images = images.float() # convert to torch format\n",
    "        if use_cuda:\n",
    "            images =images.cuda()\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        test_result[i] = predicted\n",
    "        if i % 10000 == 9999:\n",
    "            print('Test data processed: %d/300000' % (i+1))\n",
    "\n",
    "now_str, filename = create_submission(test_result.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
