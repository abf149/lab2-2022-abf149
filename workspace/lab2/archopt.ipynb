{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your name:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starter Code\n",
    "\n",
    "This notebook implements starter code to help you get started with the assignment. If you have a personal GPU, copy this starter code to another directory and run this notebook using your personal GPU. In that case, the docker we provide will not support PyTorch with GPU, and you can create your own virtual environment (e.g., conda) with PyTorch support (https://pytorch.org/get-started/locally/). \n",
    "\n",
    "To run this notebook you must __first create a folder called `./dataset` and download all the data files from the Kaggle competition page__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "%matplotlib inline\n",
    "\n",
    "log_interval = 1000,\n",
    "epochs = 1\n",
    "\n",
    "params = {\n",
    "    'log_interval': 1000,\n",
    "    'epochs': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "# GPU setup\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"Using {}\".format('GPU' if use_cuda else 'CPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abstract a \"one-of-N\" or N-way one-hot decision (usually for assigning a factor of a rank to a memory level)\n",
    "#\n",
    "# Initialization:\n",
    "# - num_factors: number of decision ways (factors) to choose between\n",
    "#\n",
    "# Input: \n",
    "# - x: [factors, baselines, temperature]\n",
    "# - factors is a list length num_factors containing the factors to select among\n",
    "# - baselines is a list of length num_factors containing the way-wise value that \n",
    "#   an output way should have when it is unselected\n",
    "# - temperature is a software parameter; high temperature smooths the softmax, \n",
    "#   low temperature approximates a discrete decision\n",
    "#\n",
    "# Trainable parameters:\n",
    "# - W: way-wise weights input to softmax\n",
    "#\n",
    "# Output: tensor of num_factors outputs. The way i which is weighted highest in W \n",
    "#         should be railed to factors[i], the other ways should be weighted to baselines[i]\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class FactorMux(nn.Module):\n",
    "    def __init__(self, num_factors):\n",
    "        super(FactorMux, self).__init__()\n",
    "        self.num_factors = num_factors\n",
    "        self.W = torch.nn.Parameter(torch.randn(self.num_factors))\n",
    "        self.W.requires_grad = True\n",
    "        self.softmax1 = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [factors, baselines, temperature]\n",
    "        \n",
    "        assert len(x) == 2*self.num_factors + 1\n",
    "        \n",
    "        factors = x[0:self.num_factors]\n",
    "        baselines = x[self.num_factors:(2*self.num_factors)]\n",
    "        temperature = x[2*self.num_factors].item()\n",
    "        \n",
    "        #print(factors, baselines, 1.0/temperature)\n",
    "        \n",
    "        x = self.softmax1((1.0/temperature)*self.W) * (factors - baselines) + baselines\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "fmux = FactorMux(2)\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2., 1.], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test FactorMux\n",
    "fmux.W.data = torch.tensor([1, 0])\n",
    "fmux(torch.tensor([2.0, 2.0, 1.0, 1.0, 0.01]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LoopNestSelector(FactorMux):\n",
    "    def __init__(self, num_datatypes):\n",
    "        super(LoopNestSelector, self).__init__(num_datatypes) # FactorMux num_factors\n",
    "        self.baseline = 1.0\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [factors, temperature]\n",
    "\n",
    "        if not torch.is_tensor(x):\n",
    "            x = torch.tensor(x)\n",
    "        \n",
    "        reuse_factors = x[0:self.num_factors]\n",
    "        temperature = torch.tensor([x[self.num_factors].item()])\n",
    "        \n",
    "        #print(reuse_factors, reuse_factors*0.0 + self.baseline, temperature)\n",
    "        \n",
    "        inputs = torch.cat((reuse_factors, reuse_factors*0.0 + self.baseline, temperature), 0)\n",
    "        x = super().forward(inputs)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1., 4., 1.], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmux = LoopNestSelector(3)\n",
    "rmux.W.data = torch.tensor([0.0,0.1,0.0])\n",
    "rmux([3, 4, 5, 0.001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RankLoopBoundSelector(nn.Module):\n",
    "    def __init__(self, num_rank_loops, rank_factor_list):\n",
    "        super(RankLoopBoundSelector, self).__init__() # FactorMux\n",
    "            \n",
    "        if not torch.is_tensor(rank_factor_list):\n",
    "            rank_factor_list = torch.tensor(rank_factor_list)            \n",
    "        \n",
    "        self.num_rank_loops = num_rank_loops\n",
    "        self.rank_factor_list = rank_factor_list\n",
    "        self.num_rank_factors = len(self.rank_factor_list)\n",
    "        self.factorMuxes = nn.ModuleList([FactorMux(self.num_rank_loops) for factor in self.rank_factor_list])\n",
    "        \n",
    "        self.baseline = 1.0\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [temperature]\n",
    "\n",
    "        if not torch.is_tensor(x):\n",
    "            x = torch.tensor([x])\n",
    "        \n",
    "        x = torch.stack( \\\n",
    "            [self.factorMuxes[mdx](\n",
    "            torch.cat( \\\n",
    "            (torch.full((self.num_rank_loops,), self.rank_factor_list[mdx]), torch.full((self.num_rank_loops,), self.baseline), \\\n",
    "            x),0) \\\n",
    "            ) \\\n",
    "            for mdx in range(self.num_rank_factors)])\n",
    "        \n",
    "        x = torch.prod(x,0)\n",
    "        \n",
    "        #print(x)\n",
    "        \n",
    "        #x = torch.tensor([  for vec in x])\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlbs = RankLoopBoundSelector(3, [3, 2, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.,  3.,  1.], grad_fn=<ProdBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "print(rlbs(0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([ 0.4519,  1.5944, -0.8727], requires_grad=True), Parameter containing:\n",
       " tensor([-0.8233, -1.8675, -1.6099], requires_grad=True), Parameter containing:\n",
       " tensor([ 1.9083,  0.6641, -0.5992], requires_grad=True)]"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(rlbs.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 61]"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "\n",
    "primes(244)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.426264754702098"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.log(86,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MapSelector_spGEMM(nn.Module):\n",
    "    \n",
    "    def repeat_prime(self, n, d):\n",
    "        lst = [d]\n",
    "        fac = d\n",
    "\n",
    "        while n % (fac * d) == 0:\n",
    "            fac = fac * d\n",
    "            lst.append(d)\n",
    "\n",
    "        return lst\n",
    "\n",
    "    # https://stackoverflow.com/questions/16996217/prime-factorization-list\n",
    "    def primes(self, n):\n",
    "        divisors = [ self.repeat_prime(n, d) for d in range(2,n//2+1) if n % d == 0 ]\n",
    "        divisors = sum(divisors, [])\n",
    "        return [ d for d in divisors if \\\n",
    "                 all( d % od != 0 for od in divisors if od != d ) ]    \n",
    "    \n",
    "    def __init__(self, M, K, N):\n",
    "        super(MapSelector_spGEMM, self).__init__() # FactorMux\n",
    "        \n",
    "        self.M = M\n",
    "        self.K = K\n",
    "        self.N = N\n",
    "        self.M_factors = self.primes(self.M)\n",
    "        self.K_factors = self.primes(self.K)\n",
    "        self.N_factors = self.primes(self.N)\n",
    "        self.main_mem_loops = 2\n",
    "        self.local_mem_loops = 1\n",
    "        self.total_loops = self.main_mem_loops + self.local_mem_loops\n",
    "        \n",
    "        # Loop bounds\n",
    "        self.M_bound_selector = RankLoopBoundSelector(self.total_loops, self.M_factors)\n",
    "        self.K_bound_selector = RankLoopBoundSelector(self.total_loops, self.K_factors)\n",
    "        self.N_bound_selector = RankLoopBoundSelector(self.total_loops, self.N_factors)        \n",
    "        \n",
    "        # Loop nest ordering\n",
    "        self.num_datatypes = 3\n",
    "        self.main_mem_temporal_LoopNestSelector = LoopNestSelector(self.num_datatypes)        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [temperature]\n",
    "\n",
    "        if not torch.is_tensor(x):\n",
    "            x = torch.tensor([x])\n",
    "        \n",
    "        # Calculate loop bounds\n",
    "        M_loop_bounds = self.M_bound_selector(x)\n",
    "        K_loop_bounds = self.K_bound_selector(x)\n",
    "        N_loop_bounds = self.N_bound_selector(x)        \n",
    "        M_main_mem_temporal = M_loop_bounds[1][None] # B reuse ceiling\n",
    "        K_main_mem_temporal = K_loop_bounds[1][None] # Z reuse ceiling\n",
    "        N_main_mem_temporal = N_loop_bounds[1][None] # A reuse ceiling\n",
    "        \n",
    "        #print(torch.flatten(torch.cat((N_main_mem_temporal, M_main_mem_temporal, K_main_mem_temporal, x),0)))\n",
    "        \n",
    "        # Calculate loop nest ordering\n",
    "        main_mem_loop_nest = self.main_mem_temporal_LoopNestSelector( \\\n",
    "            torch.flatten(torch.cat((N_main_mem_temporal, M_main_mem_temporal, K_main_mem_temporal, x),0)))\n",
    "        \n",
    "        #print(M_loop_bounds,K_loop_bounds,N_loop_bounds, main_mem_loop_nest)        \n",
    "        \n",
    "        x = torch.cat((M_loop_bounds,K_loop_bounds,N_loop_bounds, main_mem_loop_nest),0)\n",
    "        \n",
    "        # torch.tensor([L1 spatial bound & L1 temporal bound & L0 temporal bound For ranks M, K, N; reuse factor for A, B, Z])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1., 3., 2., 5., 5., 1., 1., 7., 3., 1., 3., 1.], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSs = MapSelector_spGEMM(2*3, 5*5, 3*7)\n",
    "MSs(0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.,  1.,  4.,  3.,  1.,  5., 35.,  1.,  1.,  1.,  1.,  1.],\n",
       "       grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.calcMap(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2., 1., 1.], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(list(net.named_children())[0][1].named_children())[3][1](torch.tensor([2,2,2,0.0001]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([-1.2506,  0.5754,  1.9506], requires_grad=True), Parameter containing:\n",
       " tensor([0.0230, 0.0995, 2.2719], requires_grad=True), Parameter containing:\n",
       " tensor([ 0.3401,  0.1958, -0.2907], requires_grad=True), Parameter containing:\n",
       " tensor([ 1.7408, -1.7152, -0.9421], requires_grad=True), Parameter containing:\n",
       " tensor([0.6512, 0.2699, 1.4484], requires_grad=True), Parameter containing:\n",
       " tensor([-0.2385, -1.4325, -2.4605], requires_grad=True), Parameter containing:\n",
       " tensor([-0.2442, -0.2462, -0.5304], requires_grad=True), Parameter containing:\n",
       " tensor([2.0660, 1.8921, 1.9983], requires_grad=True)]"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class ArchMap_spGEMM(nn.Module): \n",
    "    \n",
    "    def __init__(self, M, K, N):\n",
    "        super(ArchMap_spGEMM, self).__init__() # FactorMux\n",
    "        \n",
    "        self.M = M\n",
    "        self.K = K\n",
    "        self.N = N\n",
    "        self.mapper = MapSelector_spGEMM(M, K, N)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [temperature]\n",
    "\n",
    "        if not torch.is_tensor(x):\n",
    "            x = torch.tensor([x])\n",
    "        \n",
    "        # Problem characteristics\n",
    "        M = float(self.M)\n",
    "        K = float(self.K)\n",
    "        N = float(self.N)\n",
    "        A_matrix_size = M*K\n",
    "        B_matrix_size = K*N\n",
    "        Z_matrix_size = M*N\n",
    "        main_memory_size = A_matrix_size+B_matrix_size+Z_matrix_size\n",
    "        total_num_macs = M*K*N\n",
    "        \n",
    "        T = x\n",
    "        \n",
    "        # Calculate map (loop bounds & loop nest)\n",
    "        # torch.tensor([L1 spatial bound & L1 temporal bound & L0 temporal bound For ranks M, K, N; reuse factor for A, B, Z])\n",
    "        x = self.mapper(x)\n",
    "        \n",
    "        self.x = x\n",
    "        \n",
    "        # Break out map parameters\n",
    "        M_L1_spatial_bound = x[0]\n",
    "        M_L1_temporal_bound = x[1]\n",
    "        M_L0_temporal_bound = x[2]\n",
    "        K_L1_spatial_bound = x[3]\n",
    "        K_L1_temporal_bound = x[4]\n",
    "        K_L0_temporal_bound = x[5]\n",
    "        N_L1_spatial_bound = x[6]\n",
    "        N_L1_temporal_bound = x[7]\n",
    "        N_L0_temporal_bound = x[8]        \n",
    "        A_reuse = x[9]\n",
    "        B_reuse = x[10]\n",
    "        Z_reuse = x[11]\n",
    "\n",
    "        # Hook\n",
    "        self.M_L1_spatial_bound = M_L1_spatial_bound\n",
    "        self.M_L1_temporal_bound = M_L1_temporal_bound\n",
    "        self.M_L0_temporal_bound = M_L0_temporal_bound\n",
    "        self.K_L1_spatial_bound = K_L1_spatial_bound\n",
    "        self.K_L1_temporal_bound = K_L1_temporal_bound\n",
    "        self.K_L0_temporal_bound = K_L0_temporal_bound\n",
    "        self.N_L1_spatial_bound = N_L1_spatial_bound\n",
    "        self.N_L1_temporal_bound = N_L1_temporal_bound\n",
    "        self.N_L0_temporal_bound = N_L0_temporal_bound       \n",
    "        self.A_reuse = A_reuse\n",
    "        self.B_reuse = B_reuse\n",
    "        self.Z_reuse = Z_reuse \n",
    "        \n",
    "        # Spatial characteristics\n",
    "        spatial_fan_out = M_L1_spatial_bound*K_L1_spatial_bound*N_L1_spatial_bound\n",
    "        \n",
    "        # Tiling\n",
    "        main_memory_tile_pair_count = M*K*N/M_L0_temporal_bound/K_L0_temporal_bound/N_L0_temporal_bound\n",
    "        A_tile_size = M_L0_temporal_bound*K_L0_temporal_bound\n",
    "        B_tile_size = K_L0_temporal_bound*N_L0_temporal_bound\n",
    "        Z_tile_size = M_L0_temporal_bound*N_L0_temporal_bound \n",
    "        local_memory_num_macs_per_tile = M_L0_temporal_bound*K_L0_temporal_bound*N_L0_temporal_bound\n",
    "        \n",
    "        # Per-PE characteristics\n",
    "        local_memory_size = A_tile_size + B_tile_size + Z_tile_size\n",
    "        local_num_macs = M*K*N/spatial_fan_out\n",
    "        \n",
    "        # Global characteristics\n",
    "        total_local_memory_size = local_memory_size*spatial_fan_out\n",
    "        \n",
    "        # Access counts\n",
    "        main_memory_reads = main_memory_tile_pair_count*(A_tile_size/A_reuse + B_tile_size/B_reuse + Z_tile_size/Z_reuse)\n",
    "        main_memory_writes = main_memory_tile_pair_count*(Z_tile_size/Z_reuse)\n",
    "        local_memory_reads = local_num_macs*3 # A, B, Z\n",
    "        local_memory_writes = local_num_macs # Just Z\n",
    "        total_local_memory_reads = local_memory_reads * spatial_fan_out\n",
    "        total_local_memory_writes = local_memory_writes * spatial_fan_out\n",
    "        \n",
    "        # Energy constants (currently arbitrary)\n",
    "        E_DRAM_static = 0.05\n",
    "        E_SRAM_static = 0.02\n",
    "        E_DRAM_acc = 1.0\n",
    "        E_SRAM_acc = 0.7\n",
    "        E_MAC = 0.1\n",
    "        \n",
    "        # Scale energy consumption of memories to memory size\n",
    "        main_memory_unit_read_energy = E_DRAM_acc*main_memory_size\n",
    "        main_memory_unit_write_energy = main_memory_unit_read_energy\n",
    "        local_memory_static_energy = E_SRAM_static*local_memory_size\n",
    "        local_memory_unit_read_energy = E_SRAM_acc*local_memory_size\n",
    "        local_memory_unit_write_energy = local_memory_unit_read_energy\n",
    "        \n",
    "        # Calculate energy consumption\n",
    "        total_main_memory_access_energy = main_memory_reads*main_memory_unit_read_energy + \\\n",
    "                                          main_memory_writes*main_memory_unit_write_energy\n",
    "        total_local_memory_static_energy = local_memory_static_energy*spatial_fan_out\n",
    "        total_local_memory_access_energy = total_local_memory_reads*local_memory_unit_read_energy + \\\n",
    "                                           total_local_memory_writes*local_memory_unit_write_energy\n",
    "        total_MAC_energy = total_num_macs*E_MAC\n",
    "        total_problem_energy = total_MAC_energy + total_local_memory_access_energy + \\\n",
    "                               total_local_memory_static_energy + total_main_memory_access_energy\n",
    "        \n",
    "        # Calculate latency in cycles\n",
    "        total_problem_latency = local_num_macs\n",
    "        \n",
    "        problem_edp = total_problem_energy*total_problem_latency\n",
    "        \n",
    "        self.problem_edp = problem_edp\n",
    "        # Calculate EDP\n",
    "        if spatial_fan_out.item() > 512.0:\n",
    "\n",
    "            problem_edp = problem_edp + 1.0e10*((spatial_fan_out - 512.0)/T.item())   \n",
    "            #print(1.0e20*((spatial_fan_out - 512.0)))\n",
    "#            problem_edp = total_problem_energy*total_problem_latency + torch.exp((spatial_fan_out - 512.0))\n",
    "#            print(\"Being used: \", torch.exp((spatial_fan_out - 512.0)), \\\n",
    "#                   \"delta: \", spatial_fan_out - 512.0, \\\n",
    "#                   \"spatial fan-out: \", spatial_fan_out)\n",
    "\n",
    "            #            problem_edp = total_problem_energy*total_problem_latency + torch.exp(-(spatial_fan_out.item() - 512.0)/T.item())\n",
    "            \n",
    "            #1.0e10/(1+math.exp(-(spatial_fan_out.item() - 512.0)/T.item()))\n",
    "\n",
    "        \n",
    "        return problem_edp\n",
    "    \n",
    "    def calcMap(self,x):\n",
    "        return self.x\n",
    "    \n",
    "    def archMapStats(self):\n",
    "        # Problem characteristics\n",
    "        M = float(self.M)\n",
    "        K = float(self.K)\n",
    "        N = float(self.N)\n",
    "        A_matrix_size = M*K\n",
    "        B_matrix_size = K*N\n",
    "        Z_matrix_size = M*N\n",
    "        main_memory_size = A_matrix_size+B_matrix_size+Z_matrix_size\n",
    "        total_num_macs = M*K*N        \n",
    "        \n",
    "        x = self.calcMap(1.0)\n",
    "        \n",
    "        M_L1_spatial_bound = x[0]\n",
    "        M_L1_temporal_bound = x[1]\n",
    "        M_L0_temporal_bound = x[2]\n",
    "        K_L1_spatial_bound = x[3]\n",
    "        K_L1_temporal_bound = x[4]\n",
    "        K_L0_temporal_bound = x[5]\n",
    "        N_L1_spatial_bound = x[6]\n",
    "        N_L1_temporal_bound = x[7]\n",
    "        N_L0_temporal_bound = x[8]        \n",
    "        A_reuse = x[9]\n",
    "        B_reuse = x[10]\n",
    "        Z_reuse = x[11]  \n",
    "        \n",
    "        # Spatial characteristics\n",
    "        spatial_fan_out = M_L1_spatial_bound*K_L1_spatial_bound*N_L1_spatial_bound\n",
    "        \n",
    "        # Tiling\n",
    "        main_memory_tile_pair_count = M*K*N/M_L0_temporal_bound/K_L0_temporal_bound/N_L0_temporal_bound\n",
    "        A_tile_size = M_L0_temporal_bound*K_L0_temporal_bound\n",
    "        B_tile_size = K_L0_temporal_bound*N_L0_temporal_bound\n",
    "        Z_tile_size = M_L0_temporal_bound*N_L0_temporal_bound \n",
    "        local_memory_num_macs_per_tile = M_L0_temporal_bound*K_L0_temporal_bound*N_L0_temporal_bound\n",
    "        \n",
    "        # Per-PE characteristics\n",
    "        local_memory_size = A_tile_size + B_tile_size + Z_tile_size\n",
    "        local_num_macs = M*K*N/spatial_fan_out\n",
    "        \n",
    "        print(\"Spatial fan-out: \", spatial_fan_out.item())\n",
    "        print(\"Local memory size: \", local_memory_size.item())\n",
    "        print(\"A tile size: \", A_tile_size.item(), \"B tile size: \", B_tile_size.item(), \"Z tile size: \", Z_tile_size.item())\n",
    "        \n",
    "        # Global characteristics\n",
    "        total_local_memory_size = local_memory_size*spatial_fan_out\n",
    "        \n",
    "        # Access counts\n",
    "        main_memory_reads = main_memory_tile_pair_count*(A_tile_size/A_reuse + B_tile_size/B_reuse + Z_tile_size/Z_reuse)\n",
    "        main_memory_writes = main_memory_tile_pair_count*(Z_tile_size/Z_reuse)\n",
    "        local_memory_reads = local_num_macs*3 # A, B, Z\n",
    "        local_memory_writes = local_num_macs # Just Z\n",
    "        total_local_memory_reads = local_memory_reads * spatial_fan_out\n",
    "        total_local_memory_writes = local_memory_writes * spatial_fan_out\n",
    "        \n",
    "        # Energy constants (currently arbitrary)\n",
    "        E_DRAM_static = 0.05\n",
    "        E_SRAM_static = 0.02\n",
    "        E_DRAM_acc = 1.0\n",
    "        E_SRAM_acc = 0.7\n",
    "        E_MAC = 0.1\n",
    "        \n",
    "        # Scale energy consumption of memories to memory size\n",
    "        main_memory_unit_read_energy = E_DRAM_acc*main_memory_size\n",
    "        main_memory_unit_write_energy = main_memory_unit_read_energy\n",
    "        local_memory_static_energy = E_SRAM_static*local_memory_size\n",
    "        local_memory_unit_read_energy = E_SRAM_acc*local_memory_size\n",
    "        local_memory_unit_write_energy = local_memory_unit_read_energy\n",
    "        \n",
    "        # Calculate energy consumption\n",
    "        total_main_memory_access_energy = main_memory_reads*main_memory_unit_read_energy + \\\n",
    "                                          main_memory_writes*main_memory_unit_write_energy\n",
    "        total_local_memory_static_energy = local_memory_static_energy*spatial_fan_out\n",
    "        total_local_memory_access_energy = total_local_memory_reads*local_memory_unit_read_energy + \\\n",
    "                                           total_local_memory_writes*local_memory_unit_write_energy\n",
    "        total_MAC_energy = total_num_macs*E_MAC\n",
    "        total_problem_energy = total_MAC_energy + total_local_memory_access_energy + \\\n",
    "                               total_local_memory_static_energy + total_main_memory_access_energy\n",
    "        \n",
    "        # Calculate latency in cycles\n",
    "        total_problem_latency = local_num_macs\n",
    "        \n",
    "        # Calculate EDP\n",
    "        problem_edp = total_problem_energy*total_problem_latency\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.718281828459045"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "net = ArchMap_spGEMM(2*3, 5*5, 3*7)\n",
    "T = torch.tensor([1.0])\n",
    "net(T)\n",
    "optimizer = optim.Adam(net.parameters() , lr=0.002) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = torch.tensor([1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad() # clear gradients\n",
    "edp = net(T) # forward step\n",
    "loss = edp\n",
    "loss.backward() # backprop\n",
    "optimizer.step() # optimize weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.4132e+08, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature:  1.0\n",
      "Map:  tensor([ 1.6632,  2.5762,  4.9245,  4.9196,  1.6904,  4.1455, 11.4745,  6.8821,\n",
      "         3.2003,  2.4318,  1.4156,  1.3403], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  93.88699340820312\n",
      "Local memory size:  49.44091796875\n",
      "A tile size:  20.41436195373535 B tile size:  13.26671314239502 Z tile size:  15.759841918945312\n",
      "-----------------------\n",
      "EDP:  359095360.0 EDP (penalized):  359095360.0  % decrease:  100.0\n",
      "EDP:  319233408.0 EDP (penalized):  319233408.0  % decrease:  5.600087359277235\n",
      "Percentage threshold reached\n",
      "Temperature:  0.5\n",
      "Map:  tensor([ 1.7207,  2.5533,  4.8444,  5.1206,  1.6685,  4.0542, 12.2376,  6.5026,\n",
      "         3.0871,  2.4386,  1.3998,  1.3217], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  107.82756042480469\n",
      "Local memory size:  47.11121368408203\n",
      "A tile size:  19.64008140563965 B tile size:  12.515769958496094 Z tile size:  14.955358505249023\n",
      "-----------------------\n",
      "EDP:  378526752.0 EDP (penalized):  378526752.0  % decrease:  9.313090973322367\n",
      "Percentage threshold reached\n",
      "Temperature:  0.25\n",
      "Map:  tensor([ 1.5127,  2.3615,  5.0286,  4.2751,  1.2196,  4.3930, 17.2348,  4.5926,\n",
      "         1.9223,  1.8487,  1.2442,  1.1283], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  111.45645904541016\n",
      "Local memory size:  40.201988220214844\n",
      "A tile size:  22.090723037719727 B tile size:  8.444733619689941 Z tile size:  9.666531562805176\n",
      "-----------------------\n",
      "EDP:  469941216.0 EDP (penalized):  469941216.0  % decrease:  12.328493081696125\n",
      "EDP:  377858368.0 EDP (penalized):  377858368.0  % decrease:  9.951886178921308\n",
      "Percentage threshold reached\n",
      "Temperature:  0.125\n",
      "Map:  tensor([ 1.6152,  2.2840,  4.4330,  3.4083,  1.0316,  4.8325, 25.3343,  2.5421,\n",
      "         1.4394,  1.3986,  1.1826,  1.0189], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  139.47116088867188\n",
      "Local memory size:  34.759830474853516\n",
      "A tile size:  21.422651290893555 B tile size:  6.956130504608154 Z tile size:  6.381048679351807\n",
      "-----------------------\n",
      "EDP:  377259456.0 EDP (penalized):  377259456.0  % decrease:  14.011235455966213\n",
      "EDP:  301249056.0 EDP (penalized):  301249056.0  % decrease:  9.788688361449605\n",
      "Percentage threshold reached\n",
      "Temperature:  0.0625\n",
      "Map:  tensor([ 2.1957,  1.7931,  4.0448,  3.0203,  1.0003,  4.9929, 31.1869,  1.6039,\n",
      "         1.1588,  1.2426,  1.1039,  1.0001], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  206.8195343017578\n",
      "Local memory size:  30.66886329650879\n",
      "A tile size:  20.195560455322266 B tile size:  5.785977363586426 Z tile size:  4.687326908111572\n",
      "-----------------------\n",
      "EDP:  252034704.0 EDP (penalized):  252034704.0  % decrease:  6.862771878913442\n",
      "Percentage threshold reached\n",
      "Temperature:  0.03125\n",
      "Map:  tensor([ 2.7721,  1.2278,  4.0003,  3.0000,  1.0000,  5.0000, 33.7952,  1.2292,\n",
      "         1.0118,  1.1403,  1.0115,  1.0000], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  281.0559387207031\n",
      "Local memory size:  29.10799217224121\n",
      "A tile size:  20.00162124633789 B tile size:  5.058902263641357 Z tile size:  4.047468185424805\n",
      "-----------------------\n",
      "EDP:  237951552.0 EDP (penalized):  237951552.0  % decrease:  2.8280983876503636\n",
      "Percentage threshold reached\n",
      "Temperature:  0.015625\n",
      "Map:  tensor([ 2.9802,  1.0198,  4.0000,  3.0000,  1.0000,  5.0000, 34.5096,  1.0980,\n",
      "         1.0001,  1.0846,  1.0001,  1.0000], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  308.5312805175781\n",
      "Local memory size:  29.00074005126953\n",
      "A tile size:  20.0 B tile size:  5.000411033630371 Z tile size:  4.00032901763916\n",
      "-----------------------\n",
      "EDP:  222987632.0 EDP (penalized):  222987632.0  % decrease:  8.52425939922293\n",
      "Percentage threshold reached\n",
      "Temperature:  0.0078125\n",
      "Map:  tensor([ 2.9998,  1.0002,  4.0000,  3.0000,  1.0000,  5.0000, 33.6475,  1.2705,\n",
      "         1.0000,  1.2659,  1.0000,  1.0000], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  302.8075256347656\n",
      "Local memory size:  29.0\n",
      "A tile size:  20.0 B tile size:  5.0 Z tile size:  4.0\n",
      "-----------------------\n",
      "EDP:  201330816.0 EDP (penalized):  201330816.0  % decrease:  0.0010172209143163035\n",
      "Percentage threshold reached\n",
      "Temperature:  0.00390625\n",
      "Map:  tensor([ 3.0000,  1.0000,  4.0000,  3.0000,  1.0000,  5.0000, 28.8998,  2.2200,\n",
      "         1.0000,  2.2198,  1.0000,  1.0000], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  260.09808349609375\n",
      "Local memory size:  29.0\n",
      "A tile size:  20.0 B tile size:  5.0 Z tile size:  4.0\n",
      "-----------------------\n",
      "EDP:  201323472.0 EDP (penalized):  201323472.0  % decrease:  0.0\n",
      "Percentage threshold reached\n",
      "Temperature:  0.001953125\n",
      "Map:  tensor([ 3.0000,  1.0000,  4.0000,  3.0000,  1.0000,  5.0000, 28.8996,  2.2201,\n",
      "         1.0000,  2.2201,  1.0000,  1.0000], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  260.0966491699219\n",
      "Local memory size:  29.0\n",
      "A tile size:  20.0 B tile size:  5.0 Z tile size:  4.0\n",
      "-----------------------\n",
      "EDP:  201323472.0 EDP (penalized):  201323472.0  % decrease:  0.0\n",
      "Percentage threshold reached\n",
      "Temperature:  0.0009765625\n",
      "Map:  tensor([ 3.0000,  1.0000,  4.0000,  3.0000,  1.0000,  5.0000, 28.8996,  2.2201,\n",
      "         1.0000,  2.2201,  1.0000,  1.0000], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  260.0964660644531\n",
      "Local memory size:  29.0\n",
      "A tile size:  20.0 B tile size:  5.0 Z tile size:  4.0\n",
      "-----------------------\n",
      "EDP:  201323472.0 EDP (penalized):  201323472.0  % decrease:  0.0\n",
      "Percentage threshold reached\n",
      "Temperature:  0.00048828125\n",
      "Map:  tensor([ 3.0000,  1.0000,  4.0000,  3.0000,  1.0000,  5.0000, 28.8996,  2.2201,\n",
      "         1.0000,  2.2201,  1.0000,  1.0000], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  260.0964660644531\n",
      "Local memory size:  29.0\n",
      "A tile size:  20.0 B tile size:  5.0 Z tile size:  4.0\n",
      "-----------------------\n",
      "EDP:  201323472.0 EDP (penalized):  201323472.0  % decrease:  0.0\n",
      "Percentage threshold reached\n",
      "Temperature:  0.000244140625\n",
      "Map:  tensor([ 3.0000,  1.0000,  4.0000,  3.0000,  1.0000,  5.0000, 28.8996,  2.2201,\n",
      "         1.0000,  2.2201,  1.0000,  1.0000], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  260.0964660644531\n",
      "Local memory size:  29.0\n",
      "A tile size:  20.0 B tile size:  5.0 Z tile size:  4.0\n",
      "-----------------------\n",
      "EDP:  201323488.0 EDP (penalized):  201323488.0  % decrease:  7.947409132701625e-06\n",
      "Percentage threshold reached\n",
      "Temperature:  0.0001220703125\n",
      "Map:  tensor([ 3.0000,  1.0000,  4.0000,  3.0000,  1.0000,  5.0000, 28.8998,  2.2200,\n",
      "         1.0000,  2.2200,  1.0000,  1.0000], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  260.0978088378906\n",
      "Local memory size:  29.0\n",
      "A tile size:  20.0 B tile size:  5.0 Z tile size:  4.0\n",
      "-----------------------\n",
      "EDP:  201323472.0 EDP (penalized):  201323472.0  % decrease:  0.0\n",
      "Percentage threshold reached\n",
      "Temperature:  6.103515625e-05\n",
      "Map:  tensor([ 3.0000,  1.0000,  4.0000,  3.0000,  1.0000,  5.0000, 28.8995,  2.2201,\n",
      "         1.0000,  2.2201,  1.0000,  1.0000], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  260.09515380859375\n",
      "Local memory size:  29.0\n",
      "A tile size:  20.0 B tile size:  5.0 Z tile size:  4.0\n",
      "-----------------------\n",
      "EDP:  244134960.0 EDP (penalized):  244134960.0  % decrease:  0.0\n",
      "Percentage threshold reached\n",
      "Temperature:  3.0517578125e-05\n",
      "Map:  tensor([ 3.,  1.,  4.,  3.,  1.,  5., 35.,  1.,  1.,  1.,  1.,  1.],\n",
      "       grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  315.0\n",
      "Local memory size:  29.0\n",
      "A tile size:  20.0 B tile size:  5.0 Z tile size:  4.0\n",
      "-----------------------\n",
      "EDP:  244134960.0 EDP (penalized):  244134960.0  % decrease:  0.0\n",
      "Percentage threshold reached\n",
      "Temperature:  1.52587890625e-05\n",
      "Map:  tensor([ 3.,  1.,  4.,  3.,  1.,  5., 35.,  1.,  1.,  1.,  1.,  1.],\n",
      "       grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  315.0\n",
      "Local memory size:  29.0\n",
      "A tile size:  20.0 B tile size:  5.0 Z tile size:  4.0\n",
      "-----------------------\n",
      "EDP:  244134960.0 EDP (penalized):  244134960.0  % decrease:  0.0\n",
      "Percentage threshold reached\n",
      "EDP:  tensor(2.4413e+08, grad_fn=<MulBackward0>)  Map:  tensor([ 3.,  1.,  4.,  3.,  1.,  5., 35.,  1.,  1.,  1.,  1.,  1.],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "net = ArchMap_spGEMM(2*3*2, 5*3, 5*7)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters() , lr=0.00005)\n",
    "\n",
    "T = torch.tensor([1.0])\n",
    "\n",
    "edp_list = []\n",
    "edp_pen_list = []\n",
    "cooling_points = []\n",
    "temperature_list = []\n",
    "\n",
    "thresh_pct = 0.5\n",
    "\n",
    "edp = 0.0\n",
    "\n",
    "pct = 100.0\n",
    "\n",
    "i = 0\n",
    "\n",
    "net(T)\n",
    "\n",
    "while(T.item() > 1.0e-05):\n",
    "    cooling_points.append(i)\n",
    "    temperature_list.append(T.item())\n",
    "    \n",
    "    print(\"Temperature: \", T.item())\n",
    "    print(\"Map: \", net.calcMap(T))\n",
    "    print(\"Arch details:\")\n",
    "    net.archMapStats()\n",
    "    print(\"-----------------------\")\n",
    "    pct = 100.0\n",
    "    \n",
    "    j = i\n",
    "    while((pct > 10.0) and T.item() > 1.0e-05 and (i-j)<100000):\n",
    "        optimizer.zero_grad() # clear gradients\n",
    "        edp_pen = net(T) # forward step\n",
    "        edp = net.problem_edp\n",
    "        edp_pen_list.append(edp_pen.item())\n",
    "        edp_list.append(edp.item())\n",
    "        loss = edp_pen\n",
    "        loss.backward() # backprop\n",
    "        optimizer.step() # optimize weights\n",
    "        if i % 1000 == 0:\n",
    "            pct = 100.0\n",
    "            if i > 0:\n",
    "                pct = 100.0*abs(edp_list[-1]-edp_list[-500])/edp_list[-500] #100.0*abs(edp_list[-1]-edp_list[-2])/edp_list[-2]\n",
    "            print(\"EDP: \", edp_list[-1], \"EDP (penalized): \",  edp_pen_list[-1], \" % decrease: \", pct)    \n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "        i = i + 1\n",
    "    print(\"Percentage threshold reached\")\n",
    "    T = T/2.0\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(edp_list)\n",
    "plt.xlabel(\"Gradient descent iterations\")\n",
    "plt.ylabel(\"EDP\")\n",
    "plt.title(\"Gradient-descent optimization of mapping + architecture\")\n",
    "plt.grid(\"on\")\n",
    "\n",
    "for jdx in range(len(cooling_points)):\n",
    "    plt.plot(np.array([cooling_points[jdx],cooling_points[jdx]]), np.array([-10.0,edp_list[0]]))\n",
    "# len(edp_list)<2 or 100.0*math.abs(edp_list[-1]-edp_list[-2])/edp_list[-2] > thresh_pct\n",
    "\n",
    "print(\"EDP: \", net(T), \" Map: \", net.calcMap(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gca.set_ylim([25, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(edp_list)\n",
    "plt.xlabel(\"Gradient descent iterations\")\n",
    "plt.ylabel(\"EDP\")\n",
    "plt.title(\"Gradient-descent optimization of mapping + architecture\")\n",
    "plt.grid(\"on\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(10119563., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6.,  1.,  1., 25.,  1.,  1., 21.,  1.,  1.,  1.,  1.,  1.],\n",
       "       grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.calcMap(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature:  1.0\n",
      "-----------------------\n",
      "tensor(1.4132e+08, grad_fn=<MulBackward0>)\n",
      "tensor(1.4044e+08, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16999984., grad_fn=<MulBackward0>)\n",
      "tensor(11566562., grad_fn=<MulBackward0>)\n",
      "tensor(9905352., grad_fn=<MulBackward0>)\n",
      "tensor(9195953., grad_fn=<MulBackward0>)\n",
      "tensor(8873597., grad_fn=<MulBackward0>)\n",
      "tensor(8706566., grad_fn=<MulBackward0>)\n",
      "tensor(8613530., grad_fn=<MulBackward0>)\n",
      "tensor(8559025., grad_fn=<MulBackward0>)\n",
      "tensor(8526076., grad_fn=<MulBackward0>)\n",
      "tensor(8505949., grad_fn=<MulBackward0>)\n",
      "tensor(8493617., grad_fn=<MulBackward0>)\n",
      "tensor(8486057., grad_fn=<MulBackward0>)\n",
      "tensor(8481417., grad_fn=<MulBackward0>)\n",
      "tensor(8478573., grad_fn=<MulBackward0>)\n",
      "tensor(8476829., grad_fn=<MulBackward0>)\n",
      "tensor(8475757., grad_fn=<MulBackward0>)\n",
      "tensor(8475103., grad_fn=<MulBackward0>)\n",
      "tensor(8474698., grad_fn=<MulBackward0>)\n",
      "tensor(8474454., grad_fn=<MulBackward0>)\n",
      "-----\n",
      "Final EDP:  tensor(8474303., grad_fn=<MulBackward0>)\n",
      "Final map:  tensor([ 5.7557,  1.0000,  1.1221, 19.6578,  1.0000,  2.4532, 18.6267,  1.4193,\n",
      "         1.3717,  1.4193,  1.0000,  1.0000], grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "T = torch.tensor([1.0])\n",
    "print(\"Temperature: \", T.item())\n",
    "print(\"-----------------------\")\n",
    "print(net(T))\n",
    "for i in range(20000):\n",
    "    optimizer.zero_grad() # clear gradients\n",
    "    edp = net(T) # forward step\n",
    "    loss = edp\n",
    "    loss.backward() # backprop\n",
    "    optimizer.step() # optimize weights\n",
    "    if i % 1000 == 0:\n",
    "        print(net(T))\n",
    "print(\"-----\")\n",
    "print(\"Final EDP: \", net(T))\n",
    "print(\"Final map: \", net.calcMap(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final map:  tensor([1.7869, 3.3463, 1.5824, 5.2726, 3.2067, 6.5668, 5.0695, 6.7205, 2.4300,\n",
      "        2.7369, 1.3967, 2.1636], grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Final map: \", net.calcMap(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature:  0.10000000149011612\n",
      "-----------------------\n",
      "tensor(8512693., grad_fn=<MulBackward0>)\n",
      "tensor(8512693., grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8512692., grad_fn=<MulBackward0>)\n",
      "tensor(8512693., grad_fn=<MulBackward0>)\n",
      "tensor(8474068., grad_fn=<MulBackward0>)\n",
      "tensor(8474070., grad_fn=<MulBackward0>)\n",
      "tensor(8474067., grad_fn=<MulBackward0>)\n",
      "tensor(8474067., grad_fn=<MulBackward0>)\n",
      "tensor(8474068., grad_fn=<MulBackward0>)\n",
      "tensor(8474066., grad_fn=<MulBackward0>)\n",
      "tensor(8474067., grad_fn=<MulBackward0>)\n",
      "tensor(8474066., grad_fn=<MulBackward0>)\n",
      "tensor(8474065., grad_fn=<MulBackward0>)\n",
      "tensor(8474066., grad_fn=<MulBackward0>)\n",
      "tensor(8474065., grad_fn=<MulBackward0>)\n",
      "tensor(8474065., grad_fn=<MulBackward0>)\n",
      "tensor(8474068., grad_fn=<MulBackward0>)\n",
      "tensor(8474066., grad_fn=<MulBackward0>)\n",
      "tensor(8474066., grad_fn=<MulBackward0>)\n",
      "tensor(8474065., grad_fn=<MulBackward0>)\n",
      "tensor(8474067., grad_fn=<MulBackward0>)\n",
      "-----\n",
      "Final EDP:  tensor(8474069., grad_fn=<MulBackward0>)\n",
      "Final map:  tensor([ 5.7559,  1.0000,  1.1221, 19.6561,  1.0000,  2.4539, 18.6278,  1.4192,\n",
      "         1.3716,  1.4192,  1.0000,  1.0000], grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "T = torch.tensor([0.1])\n",
    "print(\"Temperature: \", T.item())\n",
    "print(\"-----------------------\")\n",
    "print(net(T))\n",
    "for i in range(20000):\n",
    "    optimizer.zero_grad() # clear gradients\n",
    "    edp = net(T) # forward step\n",
    "    loss = edp\n",
    "    loss.backward() # backprop\n",
    "    optimizer.step() # optimize weights\n",
    "    if i % 1000 == 0:\n",
    "        print(net(T))\n",
    "print(\"-----\")\n",
    "print(\"Final EDP: \", net(T))\n",
    "print(\"Final map: \", net.calcMap(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature:  0.0010000000474974513\n",
      "-----------------------\n",
      "tensor(10119563., grad_fn=<MulBackward0>)\n",
      "tensor(10119563., grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10119563., grad_fn=<MulBackward0>)\n",
      "tensor(10119563., grad_fn=<MulBackward0>)\n",
      "tensor(10119563., grad_fn=<MulBackward0>)\n",
      "tensor(10119563., grad_fn=<MulBackward0>)\n",
      "tensor(10119563., grad_fn=<MulBackward0>)\n",
      "tensor(10119563., grad_fn=<MulBackward0>)\n",
      "tensor(10119563., grad_fn=<MulBackward0>)\n",
      "tensor(10119563., grad_fn=<MulBackward0>)\n",
      "tensor(10119563., grad_fn=<MulBackward0>)\n",
      "-----\n",
      "Final EDP:  tensor(10119563., grad_fn=<MulBackward0>)\n",
      "Final map:  tensor([ 6.,  1.,  1., 25.,  1.,  1., 21.,  1.,  1.,  1.,  1.,  1.],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "T = torch.tensor([0.001])\n",
    "print(\"Temperature: \", T.item())\n",
    "print(\"-----------------------\")\n",
    "print(net(T))\n",
    "for i in range(10000):\n",
    "    optimizer.zero_grad() # clear gradients\n",
    "    edp = net(T) # forward step\n",
    "    loss = edp\n",
    "    loss.backward() # backprop\n",
    "    optimizer.step() # optimize weights\n",
    "    if i % 1000 == 0:\n",
    "        print(net(T))\n",
    "print(\"-----\")\n",
    "print(\"Final EDP: \", net(T))\n",
    "print(\"Final map: \", net.calcMap(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature:  0.009999999776482582\n",
      "-----------------------\n",
      "tensor(9359604., grad_fn=<MulBackward0>)\n",
      "tensor(9359609., grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9359602., grad_fn=<MulBackward0>)\n",
      "tensor(9359610., grad_fn=<MulBackward0>)\n",
      "tensor(9359603., grad_fn=<MulBackward0>)\n",
      "tensor(9359601., grad_fn=<MulBackward0>)\n",
      "tensor(9359624., grad_fn=<MulBackward0>)\n",
      "tensor(9359604., grad_fn=<MulBackward0>)\n",
      "tensor(9359759., grad_fn=<MulBackward0>)\n",
      "tensor(9359612., grad_fn=<MulBackward0>)\n",
      "tensor(9048232., grad_fn=<MulBackward0>)\n",
      "-----\n",
      "Final EDP:  tensor(9048230., grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Temperature: \", T.item())\n",
    "print(\"-----------------------\")\n",
    "print(net(T))\n",
    "for i in range(10000):\n",
    "    optimizer.zero_grad() # clear gradients\n",
    "    edp = net(T) # forward step\n",
    "    loss = edp\n",
    "    loss.backward() # backprop\n",
    "    optimizer.step() # optimize weights\n",
    "    if i % 1000 == 0:\n",
    "        print(net(T))\n",
    "print(\"-----\")\n",
    "print(\"Final EDP: \", net(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
