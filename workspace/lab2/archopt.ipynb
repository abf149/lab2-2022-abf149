{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your name:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starter Code\n",
    "\n",
    "This notebook implements starter code to help you get started with the assignment. If you have a personal GPU, copy this starter code to another directory and run this notebook using your personal GPU. In that case, the docker we provide will not support PyTorch with GPU, and you can create your own virtual environment (e.g., conda) with PyTorch support (https://pytorch.org/get-started/locally/). \n",
    "\n",
    "To run this notebook you must __first create a folder called `./dataset` and download all the data files from the Kaggle competition page__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "%matplotlib inline\n",
    "\n",
    "log_interval = 1000,\n",
    "epochs = 1\n",
    "\n",
    "params = {\n",
    "    'log_interval': 1000,\n",
    "    'epochs': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "# GPU setup\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"Using {}\".format('GPU' if use_cuda else 'CPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abstract a \"one-of-N\" or N-way one-hot decision (usually for assigning a factor of a rank to a memory level)\n",
    "#\n",
    "# Initialization:\n",
    "# - num_factors: number of decision ways (factors) to choose between\n",
    "#\n",
    "# Input: \n",
    "# - x: [factors, baselines, temperature]\n",
    "# - factors is a list length num_factors containing the factors to select among\n",
    "# - baselines is a list of length num_factors containing the way-wise value that \n",
    "#   an output way should have when it is unselected\n",
    "# - temperature is a software parameter; high temperature smooths the softmax, \n",
    "#   low temperature approximates a discrete decision\n",
    "#\n",
    "# Trainable parameters:\n",
    "# - W: way-wise weights input to softmax\n",
    "#\n",
    "# Output: tensor of num_factors outputs. The way i which is weighted highest in W \n",
    "#         should be railed to factors[i], the other ways should be weighted to baselines[i]\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class FactorMux(nn.Module):\n",
    "    def __init__(self, num_factors):\n",
    "        super(FactorMux, self).__init__()\n",
    "        self.num_factors = num_factors\n",
    "        self.W = torch.nn.Parameter(torch.randn(self.num_factors))\n",
    "        self.W.requires_grad = True\n",
    "        self.softmax1 = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [factors, baselines, temperature]\n",
    "        \n",
    "        assert len(x) == 2*self.num_factors + 1\n",
    "        \n",
    "        factors = x[0:self.num_factors]\n",
    "        baselines = x[self.num_factors:(2*self.num_factors)]\n",
    "        temperature = x[2*self.num_factors].item()\n",
    "        \n",
    "        #print(factors, baselines, 1.0/temperature)\n",
    "        \n",
    "        x = self.softmax1((1.0/temperature)*self.W) * (factors - baselines) + baselines\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "fmux = FactorMux(2)\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2., 1.], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test FactorMux\n",
    "fmux.W.data = torch.tensor([1, 0])\n",
    "fmux(torch.tensor([2.0, 2.0, 1.0, 1.0, 0.01]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LoopNestSelector(FactorMux):\n",
    "    def __init__(self, num_datatypes):\n",
    "        super(LoopNestSelector, self).__init__(num_datatypes) # FactorMux num_factors\n",
    "        self.baseline = 1.0\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [factors, temperature]\n",
    "\n",
    "        if not torch.is_tensor(x):\n",
    "            x = torch.tensor(x)\n",
    "        \n",
    "        reuse_factors = x[0:self.num_factors]\n",
    "        temperature = torch.tensor([x[self.num_factors].item()])\n",
    "        \n",
    "        #print(reuse_factors, reuse_factors*0.0 + self.baseline, temperature)\n",
    "        \n",
    "        inputs = torch.cat((reuse_factors, reuse_factors*0.0 + self.baseline, temperature), 0)\n",
    "        x = super().forward(inputs)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1., 4., 1.], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmux = LoopNestSelector(3)\n",
    "rmux.W.data = torch.tensor([0.0,0.1,0.0])\n",
    "rmux([3, 4, 5, 0.001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RankLoopBoundSelector(nn.Module):\n",
    "    def __init__(self, num_rank_loops, rank_factor_list):\n",
    "        super(RankLoopBoundSelector, self).__init__() # FactorMux\n",
    "            \n",
    "        if not torch.is_tensor(rank_factor_list):\n",
    "            rank_factor_list = torch.tensor(rank_factor_list)            \n",
    "        \n",
    "        self.num_rank_loops = num_rank_loops\n",
    "        self.rank_factor_list = rank_factor_list\n",
    "        self.num_rank_factors = len(self.rank_factor_list)\n",
    "        self.factorMuxes = nn.ModuleList([FactorMux(self.num_rank_loops) for factor in self.rank_factor_list])\n",
    "        \n",
    "        self.baseline = 1.0\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [temperature]\n",
    "\n",
    "        if not torch.is_tensor(x):\n",
    "            x = torch.tensor([x])\n",
    "        \n",
    "        x = torch.stack( \\\n",
    "            [self.factorMuxes[mdx](\n",
    "            torch.cat( \\\n",
    "            (torch.full((self.num_rank_loops,), self.rank_factor_list[mdx]), torch.full((self.num_rank_loops,), self.baseline), \\\n",
    "            x),0) \\\n",
    "            ) \\\n",
    "            for mdx in range(self.num_rank_factors)])\n",
    "        \n",
    "        x = torch.prod(x,0)\n",
    "        \n",
    "        #print(x)\n",
    "        \n",
    "        #x = torch.tensor([  for vec in x])\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlbs = RankLoopBoundSelector(3, [3, 2, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 3., 5.], grad_fn=<ProdBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "print(rlbs(0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([ 0.0168,  0.2230, -0.1170], requires_grad=True), Parameter containing:\n",
       " tensor([ 1.5208, -0.1559, -1.6177], requires_grad=True), Parameter containing:\n",
       " tensor([-0.5039, -0.8544,  0.7811], requires_grad=True)]"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(rlbs.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 61]"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "\n",
    "primes(244)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.426264754702098"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.log(86,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MapSelector_spGEMM(nn.Module):\n",
    "    \n",
    "    def repeat_prime(self, n, d):\n",
    "        lst = [d]\n",
    "        fac = d\n",
    "\n",
    "        while n % (fac * d) == 0:\n",
    "            fac = fac * d\n",
    "            lst.append(d)\n",
    "\n",
    "        return lst\n",
    "\n",
    "    # https://stackoverflow.com/questions/16996217/prime-factorization-list\n",
    "    def primes(self, n):\n",
    "        divisors = [ self.repeat_prime(n, d) for d in range(2,n//2+1) if n % d == 0 ]\n",
    "        divisors = sum(divisors, [])\n",
    "        return [ d for d in divisors if \\\n",
    "                 all( d % od != 0 for od in divisors if od != d ) ]    \n",
    "    \n",
    "    def __init__(self, M, K, N):\n",
    "        super(MapSelector_spGEMM, self).__init__() # FactorMux\n",
    "        \n",
    "        self.M = M\n",
    "        self.K = K\n",
    "        self.N = N\n",
    "        self.M_factors = self.primes(self.M)\n",
    "        self.K_factors = self.primes(self.K)\n",
    "        self.N_factors = self.primes(self.N)\n",
    "        self.main_mem_loops = 2\n",
    "        self.local_mem_loops = 1\n",
    "        self.total_loops = self.main_mem_loops + self.local_mem_loops\n",
    "        \n",
    "        # Loop bounds\n",
    "        self.M_bound_selector = RankLoopBoundSelector(self.total_loops, self.M_factors)\n",
    "        self.K_bound_selector = RankLoopBoundSelector(self.total_loops, self.K_factors)\n",
    "        self.N_bound_selector = RankLoopBoundSelector(self.total_loops, self.N_factors)        \n",
    "        \n",
    "        # Loop nest ordering\n",
    "        self.num_datatypes = 3\n",
    "        self.main_mem_temporal_LoopNestSelector = LoopNestSelector(self.num_datatypes)        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [temperature]\n",
    "\n",
    "        if not torch.is_tensor(x):\n",
    "            x = torch.tensor([x])\n",
    "        \n",
    "        # Calculate loop bounds\n",
    "        M_loop_bounds = self.M_bound_selector(x)\n",
    "        K_loop_bounds = self.K_bound_selector(x)\n",
    "        N_loop_bounds = self.N_bound_selector(x)        \n",
    "        M_main_mem_temporal = M_loop_bounds[1][None] # B reuse ceiling\n",
    "        K_main_mem_temporal = K_loop_bounds[1][None] # Z reuse ceiling\n",
    "        N_main_mem_temporal = N_loop_bounds[1][None] # A reuse ceiling\n",
    "        \n",
    "        #print(torch.flatten(torch.cat((N_main_mem_temporal, M_main_mem_temporal, K_main_mem_temporal, x),0)))\n",
    "        \n",
    "        # Calculate loop nest ordering\n",
    "        main_mem_loop_nest = self.main_mem_temporal_LoopNestSelector( \\\n",
    "            torch.flatten(torch.cat((N_main_mem_temporal, M_main_mem_temporal, K_main_mem_temporal, x),0)))\n",
    "        \n",
    "        #print(M_loop_bounds,K_loop_bounds,N_loop_bounds, main_mem_loop_nest)        \n",
    "        \n",
    "        x = torch.cat((M_loop_bounds,K_loop_bounds,N_loop_bounds, main_mem_loop_nest),0)\n",
    "        \n",
    "        # torch.tensor([L1 spatial bound & L1 temporal bound & L0 temporal bound For ranks M, K, N; reuse factor for A, B, Z])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  2.,  3.,  5.,  5.,  1.,  1., 21.,  1.,  1.,  2.,  1.],\n",
       "       grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSs = MapSelector_spGEMM(2*3, 5*5, 3*7)\n",
    "MSs(0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ArchMap_spGEMM(nn.Module): \n",
    "    \n",
    "    def __init__(self, M, K, N):\n",
    "        super(ArchMap_spGEMM, self).__init__() # FactorMux\n",
    "        \n",
    "        self.M = M\n",
    "        self.K = K\n",
    "        self.N = N\n",
    "        self.mapper = MapSelector_spGEMM(M, K, N)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [temperature]\n",
    "\n",
    "        if not torch.is_tensor(x):\n",
    "            x = torch.tensor([x])\n",
    "        \n",
    "        # Problem characteristics\n",
    "        M = float(self.M)\n",
    "        K = float(self.K)\n",
    "        N = float(self.N)\n",
    "        A_matrix_size = M*K\n",
    "        B_matrix_size = K*N\n",
    "        Z_matrix_size = M*N\n",
    "        main_memory_size = A_matrix_size+B_matrix_size+Z_matrix_size\n",
    "        total_num_macs = M*K*N\n",
    "        \n",
    "        # Calculate map (loop bounds & loop nest)\n",
    "        # torch.tensor([L1 spatial bound & L1 temporal bound & L0 temporal bound For ranks M, K, N; reuse factor for A, B, Z])\n",
    "        x = self.mapper(x)\n",
    "        \n",
    "        self.x = x\n",
    "        \n",
    "        # Break out map parameters\n",
    "        M_L1_spatial_bound = x[0]\n",
    "        M_L1_temporal_bound = x[1]\n",
    "        M_L0_temporal_bound = x[2]\n",
    "        K_L1_spatial_bound = x[3]\n",
    "        K_L1_temporal_bound = x[4]\n",
    "        K_L0_temporal_bound = x[5]\n",
    "        N_L1_spatial_bound = x[6]\n",
    "        N_L1_temporal_bound = x[7]\n",
    "        N_L0_temporal_bound = x[8]        \n",
    "        A_reuse = x[9]\n",
    "        B_reuse = x[10]\n",
    "        Z_reuse = x[11]\n",
    "\n",
    "        # Hook\n",
    "        self.M_L1_spatial_bound = M_L1_spatial_bound\n",
    "        self.M_L1_temporal_bound = M_L1_temporal_bound\n",
    "        self.M_L0_temporal_bound = M_L0_temporal_bound\n",
    "        self.K_L1_spatial_bound = K_L1_spatial_bound\n",
    "        self.K_L1_temporal_bound = K_L1_temporal_bound\n",
    "        self.K_L0_temporal_bound = K_L0_temporal_bound\n",
    "        self.N_L1_spatial_bound = N_L1_spatial_bound\n",
    "        self.N_L1_temporal_bound = N_L1_temporal_bound\n",
    "        self.N_L0_temporal_bound = N_L0_temporal_bound       \n",
    "        self.A_reuse = A_reuse\n",
    "        self.B_reuse = B_reuse\n",
    "        self.Z_reuse = Z_reuse \n",
    "        \n",
    "        # Spatial characteristics\n",
    "        spatial_fan_out = M_L1_spatial_bound*K_L1_spatial_bound*N_L1_spatial_bound\n",
    "        \n",
    "        # Tiling\n",
    "        main_memory_tile_pair_count = M*K*N/M_L0_temporal_bound/K_L0_temporal_bound/N_L0_temporal_bound\n",
    "        A_tile_size = M_L0_temporal_bound*K_L0_temporal_bound\n",
    "        B_tile_size = K_L0_temporal_bound*N_L0_temporal_bound\n",
    "        Z_tile_size = M_L0_temporal_bound*N_L0_temporal_bound \n",
    "        local_memory_num_macs_per_tile = M_L0_temporal_bound*K_L0_temporal_bound*N_L0_temporal_bound\n",
    "        \n",
    "        # Per-PE characteristics\n",
    "        local_memory_size = A_tile_size + B_tile_size + Z_tile_size\n",
    "        local_num_macs = M*K*N/spatial_fan_out\n",
    "        \n",
    "        # Global characteristics\n",
    "        total_local_memory_size = local_memory_size*spatial_fan_out\n",
    "        \n",
    "        # Access counts\n",
    "        main_memory_reads = main_memory_tile_pair_count*(A_tile_size/A_reuse + B_tile_size/B_reuse + Z_tile_size/Z_reuse)\n",
    "        main_memory_writes = main_memory_tile_pair_count*(Z_tile_size/Z_reuse)\n",
    "        local_memory_reads = local_num_macs*3 # A, B, Z\n",
    "        local_memory_writes = local_num_macs # Just Z\n",
    "        total_local_memory_reads = local_memory_reads * spatial_fan_out\n",
    "        total_local_memory_writes = local_memory_writes * spatial_fan_out\n",
    "        \n",
    "        # Energy constants (currently arbitrary)\n",
    "        E_DRAM_static = 0.05\n",
    "        E_SRAM_static = 0.02\n",
    "        E_DRAM_acc = 1.0\n",
    "        E_SRAM_acc = 0.7\n",
    "        E_MAC = 0.1\n",
    "        \n",
    "        # Scale energy consumption of memories to memory size\n",
    "        main_memory_unit_read_energy = E_DRAM_acc*main_memory_size\n",
    "        main_memory_unit_write_energy = main_memory_unit_read_energy\n",
    "        local_memory_static_energy = E_SRAM_static*local_memory_size\n",
    "        local_memory_unit_read_energy = E_SRAM_acc*local_memory_size\n",
    "        local_memory_unit_write_energy = local_memory_unit_read_energy\n",
    "        \n",
    "        # Calculate energy consumption\n",
    "        total_main_memory_access_energy = main_memory_reads*main_memory_unit_read_energy + \\\n",
    "                                          main_memory_writes*main_memory_unit_write_energy\n",
    "        total_local_memory_static_energy = local_memory_static_energy*spatial_fan_out\n",
    "        total_local_memory_access_energy = total_local_memory_reads*local_memory_unit_read_energy + \\\n",
    "                                           total_local_memory_writes*local_memory_unit_write_energy\n",
    "        total_MAC_energy = total_num_macs*E_MAC\n",
    "        total_problem_energy = total_MAC_energy + total_local_memory_access_energy + \\\n",
    "                               total_local_memory_static_energy + total_main_memory_access_energy\n",
    "        \n",
    "        # Calculate latency in cycles\n",
    "        total_problem_latency = local_num_macs\n",
    "        \n",
    "        # Calculate EDP\n",
    "        problem_edp = total_problem_energy*total_problem_latency\n",
    "        \n",
    "        return problem_edp\n",
    "    \n",
    "    def calcMap(self,x):\n",
    "        return self.x\n",
    "    \n",
    "    def archMapStats(self):\n",
    "        # Problem characteristics\n",
    "        M = float(self.M)\n",
    "        K = float(self.K)\n",
    "        N = float(self.N)\n",
    "        A_matrix_size = M*K\n",
    "        B_matrix_size = K*N\n",
    "        Z_matrix_size = M*N\n",
    "        main_memory_size = A_matrix_size+B_matrix_size+Z_matrix_size\n",
    "        total_num_macs = M*K*N        \n",
    "        \n",
    "        x = self.calcMap(1.0)\n",
    "        \n",
    "        M_L1_spatial_bound = x[0]\n",
    "        M_L1_temporal_bound = x[1]\n",
    "        M_L0_temporal_bound = x[2]\n",
    "        K_L1_spatial_bound = x[3]\n",
    "        K_L1_temporal_bound = x[4]\n",
    "        K_L0_temporal_bound = x[5]\n",
    "        N_L1_spatial_bound = x[6]\n",
    "        N_L1_temporal_bound = x[7]\n",
    "        N_L0_temporal_bound = x[8]        \n",
    "        A_reuse = x[9]\n",
    "        B_reuse = x[10]\n",
    "        Z_reuse = x[11]  \n",
    "        \n",
    "        # Spatial characteristics\n",
    "        spatial_fan_out = M_L1_spatial_bound*K_L1_spatial_bound*N_L1_spatial_bound\n",
    "        \n",
    "        # Tiling\n",
    "        main_memory_tile_pair_count = M*K*N/M_L0_temporal_bound/K_L0_temporal_bound/N_L0_temporal_bound\n",
    "        A_tile_size = M_L0_temporal_bound*K_L0_temporal_bound\n",
    "        B_tile_size = K_L0_temporal_bound*N_L0_temporal_bound\n",
    "        Z_tile_size = M_L0_temporal_bound*N_L0_temporal_bound \n",
    "        local_memory_num_macs_per_tile = M_L0_temporal_bound*K_L0_temporal_bound*N_L0_temporal_bound\n",
    "        \n",
    "        # Per-PE characteristics\n",
    "        local_memory_size = A_tile_size + B_tile_size + Z_tile_size\n",
    "        local_num_macs = M*K*N/spatial_fan_out\n",
    "        \n",
    "        print(\"Local memory size: \", local_memory_size.item())\n",
    "        print(\"A tile size: \", A_tile_size.item(), \"B tile size: \", B_tile_size.item(), \"Z tile size: \", Z_tile_size.item())\n",
    "        \n",
    "        # Global characteristics\n",
    "        total_local_memory_size = local_memory_size*spatial_fan_out\n",
    "        \n",
    "        # Access counts\n",
    "        main_memory_reads = main_memory_tile_pair_count*(A_tile_size/A_reuse + B_tile_size/B_reuse + Z_tile_size/Z_reuse)\n",
    "        main_memory_writes = main_memory_tile_pair_count*(Z_tile_size/Z_reuse)\n",
    "        local_memory_reads = local_num_macs*3 # A, B, Z\n",
    "        local_memory_writes = local_num_macs # Just Z\n",
    "        total_local_memory_reads = local_memory_reads * spatial_fan_out\n",
    "        total_local_memory_writes = local_memory_writes * spatial_fan_out\n",
    "        \n",
    "        # Energy constants (currently arbitrary)\n",
    "        E_DRAM_static = 0.05\n",
    "        E_SRAM_static = 0.02\n",
    "        E_DRAM_acc = 1.0\n",
    "        E_SRAM_acc = 0.7\n",
    "        E_MAC = 0.1\n",
    "        \n",
    "        # Scale energy consumption of memories to memory size\n",
    "        main_memory_unit_read_energy = E_DRAM_acc*main_memory_size\n",
    "        main_memory_unit_write_energy = main_memory_unit_read_energy\n",
    "        local_memory_static_energy = E_SRAM_static*local_memory_size\n",
    "        local_memory_unit_read_energy = E_SRAM_acc*local_memory_size\n",
    "        local_memory_unit_write_energy = local_memory_unit_read_energy\n",
    "        \n",
    "        # Calculate energy consumption\n",
    "        total_main_memory_access_energy = main_memory_reads*main_memory_unit_read_energy + \\\n",
    "                                          main_memory_writes*main_memory_unit_write_energy\n",
    "        total_local_memory_static_energy = local_memory_static_energy*spatial_fan_out\n",
    "        total_local_memory_access_energy = total_local_memory_reads*local_memory_unit_read_energy + \\\n",
    "                                           total_local_memory_writes*local_memory_unit_write_energy\n",
    "        total_MAC_energy = total_num_macs*E_MAC\n",
    "        total_problem_energy = total_MAC_energy + total_local_memory_access_energy + \\\n",
    "                               total_local_memory_static_energy + total_main_memory_access_energy\n",
    "        \n",
    "        # Calculate latency in cycles\n",
    "        total_problem_latency = local_num_macs\n",
    "        \n",
    "        # Calculate EDP\n",
    "        problem_edp = total_problem_energy*total_problem_latency        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "net = ArchMap_spGEMM(2*3, 5*5, 3*7)\n",
    "T = torch.tensor([1.0])\n",
    "net(T)\n",
    "optimizer = optim.Adam(net.parameters() , lr=0.002) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = torch.tensor([1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad() # clear gradients\n",
    "edp = net(T) # forward step\n",
    "loss = edp\n",
    "loss.backward() # backprop\n",
    "optimizer.step() # optimize weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.4132e+08, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature:  1.0\n",
      "Map:  tensor([2.8819, 1.9805, 1.5924, 4.4404, 9.2277, 2.8219, 3.5587, 6.8508, 4.4910,\n",
      "        3.3511, 1.0883, 5.1808], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Local memory size:  tensor(24.3181, grad_fn=<AddBackward0>)\n",
      "A tile size:  4.493528842926025 B tile size:  12.673213958740234 Z tile size:  7.1513237953186035\n",
      "-----------------------\n",
      "EDP:  150115984.0  % decrease:  100.0\n",
      "EDP:  17329150.0  % decrease:  42.08555386445385\n",
      "EDP:  11516963.0  % decrease:  13.48444603263261\n",
      "EDP:  9911864.0  % decrease:  5.887812509315919\n",
      "EDP:  9178046.0  % decrease:  3.208151363175912\n",
      "EDP:  8803955.0  % decrease:  1.7469935047963534\n",
      "EDP:  8601455.0  % decrease:  0.9983941718751727\n",
      "EDP:  8484581.0  % decrease:  0.5932883515654381\n",
      "EDP:  8415228.0  % decrease:  0.35759935634247175\n",
      "EDP:  8373475.0  % decrease:  0.2173088216227759\n",
      "EDP:  8348116.0  % decrease:  0.13275136627318573\n",
      "EDP:  8332643.0  % decrease:  0.08131244351387269\n",
      "EDP:  8323172.0  % decrease:  0.049853911766802095\n",
      "EDP:  8317367.5  % decrease:  0.030595255301509902\n",
      "EDP:  8313808.5  % decrease:  0.018748407317386726\n",
      "EDP:  8311629.5  % decrease:  0.011506646486827747\n",
      "EDP:  8310295.0  % decrease:  0.007026933369270161\n",
      "EDP:  8309475.5  % decrease:  0.004308148634497392\n",
      "EDP:  8308977.0  % decrease:  0.0025995301108627383\n",
      "EDP:  8308669.5  % decrease:  0.0016247824822451895\n",
      "EDP:  8308481.0  % decrease:  0.0009748978839600713\n",
      "EDP:  8308367.0  % decrease:  0.0006138352323008284\n",
      "EDP:  8308299.5  % decrease:  0.00033099323124860156\n",
      "EDP:  8308251.5  % decrease:  0.0002467419976003438\n",
      "EDP:  8308224.0  % decrease:  0.00018054363131738717\n",
      "EDP:  8308211.0  % decrease:  4.212697407000492e-05\n",
      "EDP:  8308201.0  % decrease:  6.0181453099239516e-05\n",
      "EDP:  8308198.5  % decrease:  1.2036303658368296e-05\n",
      "EDP:  8308194.0  % decrease:  4.212707801591814e-05\n",
      "EDP:  8308191.5  % decrease:  1.805446961264256e-05\n",
      "EDP:  8308189.0  % decrease:  5.416341861684563e-05\n",
      "EDP:  8308186.5  % decrease:  6.018160521553049e-06\n",
      "Percentage threshold reached\n",
      "Temperature:  0.5\n",
      "Map:  tensor([ 5.7123,  1.0000,  1.1438, 19.0101,  1.7878,  1.6974, 18.9327,  1.0000,\n",
      "         1.6891,  1.0000,  1.0000,  1.7878], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Local memory size:  tensor(6.7407, grad_fn=<AddBackward0>)\n",
      "A tile size:  1.9415570497512817 B tile size:  2.867084503173828 Z tile size:  1.9320812225341797\n",
      "-----------------------\n",
      "EDP:  8308186.5  % decrease:  0.0\n",
      "Percentage threshold reached\n",
      "Temperature:  0.25\n",
      "Map:  tensor([ 5.7123,  1.0000,  1.1438, 19.0100,  1.7879,  1.6974, 18.9327,  1.0000,\n",
      "         1.6891,  1.0000,  1.0000,  1.7879], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Local memory size:  tensor(6.7407, grad_fn=<AddBackward0>)\n",
      "A tile size:  1.9415637254714966 B tile size:  2.867083787918091 Z tile size:  1.932065725326538\n",
      "-----------------------\n",
      "EDP:  8308187.0  % decrease:  6.018160521553049e-06\n",
      "Percentage threshold reached\n",
      "Temperature:  0.125\n",
      "Map:  tensor([ 5.7123,  1.0000,  1.1438, 19.0100,  1.7879,  1.6974, 18.9327,  1.0000,\n",
      "         1.6891,  1.0000,  1.0000,  1.7879], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Local memory size:  tensor(6.7407, grad_fn=<AddBackward0>)\n",
      "A tile size:  1.941563606262207 B tile size:  2.8670825958251953 Z tile size:  1.9320653676986694\n",
      "-----------------------\n",
      "EDP:  8308188.5  % decrease:  0.0\n",
      "Percentage threshold reached\n",
      "Temperature:  0.0625\n",
      "Map:  tensor([ 5.7123,  1.0000,  1.1438, 19.0100,  1.7879,  1.6974, 18.9327,  1.0000,\n",
      "         1.6891,  1.0000,  1.0000,  1.7879], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Local memory size:  tensor(6.7407, grad_fn=<AddBackward0>)\n",
      "A tile size:  1.941563606262207 B tile size:  2.867084503173828 Z tile size:  1.932066559791565\n",
      "-----------------------\n",
      "EDP:  8308188.0  % decrease:  0.0\n",
      "Percentage threshold reached\n",
      "Temperature:  0.03125\n",
      "Map:  tensor([ 5.7123,  1.0000,  1.1438, 19.0100,  1.7879,  1.6974, 18.9327,  1.0000,\n",
      "         1.6891,  1.0000,  1.0000,  1.7879], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Local memory size:  tensor(6.7407, grad_fn=<AddBackward0>)\n",
      "A tile size:  1.9415652751922607 B tile size:  2.8670856952667236 Z tile size:  1.9320673942565918\n",
      "-----------------------\n",
      "EDP:  8308186.5  % decrease:  3.610895009075082e-05\n",
      "EDP:  8308186.5  % decrease:  1.8054484824302782e-05\n",
      "EDP:  8308187.5  % decrease:  3.0090808040504636e-05\n",
      "EDP:  8308186.0  % decrease:  2.4072649329865588e-05\n",
      "EDP:  8308187.0  % decrease:  1.2036321043106097e-05\n",
      "EDP:  8308316.0  % decrease:  0.0012698319464682182\n",
      "EDP:  8308186.5  % decrease:  3.0090806229591285e-05\n",
      "EDP:  8308301.0  % decrease:  0.0009328145440110628\n",
      "EDP:  8308187.0  % decrease:  6.018160521553049e-06\n",
      "Percentage threshold reached\n",
      "Temperature:  0.015625\n",
      "Map:  tensor([ 5.7123,  1.0000,  1.1438, 19.0097,  1.7879,  1.6974, 18.9328,  1.0000,\n",
      "         1.6891,  1.0000,  1.0000,  1.7879], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Local memory size:  tensor(6.7407, grad_fn=<AddBackward0>)\n",
      "A tile size:  1.9415963888168335 B tile size:  2.8670754432678223 Z tile size:  1.9319987297058105\n",
      "-----------------------\n",
      "EDP:  8308185.5  % decrease:  3.0090808040504636e-05\n",
      "EDP:  8308183.0  % decrease:  6.018161608100927e-06\n",
      "Percentage threshold reached\n",
      "Temperature:  0.0078125\n",
      "Map:  tensor([ 5.7123,  1.0000,  1.1438, 19.0100,  1.7879,  1.6974, 18.9326,  1.0000,\n",
      "         1.6891,  1.0000,  1.0000,  1.7879], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Local memory size:  tensor(6.7408, grad_fn=<AddBackward0>)\n",
      "A tile size:  1.9415631294250488 B tile size:  2.8671274185180664 Z tile size:  1.9321012496948242\n",
      "-----------------------\n",
      "EDP:  8360204.0  % decrease:  0.0028048752918954176\n",
      "EDP:  8308185.5  % decrease:  1.8054481564659145e-05\n",
      "EDP:  8308185.0  % decrease:  6.01816015937051e-06\n",
      "Percentage threshold reached\n",
      "Temperature:  0.00390625\n",
      "Map:  tensor([ 5.7123,  1.0000,  1.1438, 19.0098,  1.7879,  1.6974, 18.9327,  1.0000,\n",
      "         1.6891,  1.0000,  1.0000,  1.7879], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Local memory size:  tensor(6.7408, grad_fn=<AddBackward0>)\n",
      "A tile size:  1.9416087865829468 B tile size:  2.867152690887451 Z tile size:  1.932086706161499\n",
      "-----------------------\n",
      "EDP:  10119563.0  % decrease:  0.0\n",
      "Percentage threshold reached\n",
      "Temperature:  0.001953125\n",
      "Map:  tensor([ 6.,  1.,  1., 25.,  1.,  1., 21.,  1.,  1.,  1.,  1.,  1.],\n",
      "       grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Local memory size:  tensor(3., grad_fn=<AddBackward0>)\n",
      "A tile size:  1.0 B tile size:  1.0 Z tile size:  1.0\n",
      "-----------------------\n",
      "EDP:  10119563.0  % decrease:  0.0\n",
      "Percentage threshold reached\n",
      "Temperature:  0.0009765625\n",
      "Map:  tensor([ 6.,  1.,  1., 25.,  1.,  1., 21.,  1.,  1.,  1.,  1.,  1.],\n",
      "       grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Local memory size:  tensor(3., grad_fn=<AddBackward0>)\n",
      "A tile size:  1.0 B tile size:  1.0 Z tile size:  1.0\n",
      "-----------------------\n",
      "EDP:  10119563.0  % decrease:  0.0\n",
      "Percentage threshold reached\n",
      "Temperature:  0.00048828125\n",
      "Map:  tensor([ 6.,  1.,  1., 25.,  1.,  1., 21.,  1.,  1.,  1.,  1.,  1.],\n",
      "       grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Local memory size:  tensor(3., grad_fn=<AddBackward0>)\n",
      "A tile size:  1.0 B tile size:  1.0 Z tile size:  1.0\n",
      "-----------------------\n",
      "EDP:  10119563.0  % decrease:  0.0\n",
      "Percentage threshold reached\n",
      "Temperature:  0.000244140625\n",
      "Map:  tensor([ 6.,  1.,  1., 25.,  1.,  1., 21.,  1.,  1.,  1.,  1.,  1.],\n",
      "       grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Local memory size:  tensor(3., grad_fn=<AddBackward0>)\n",
      "A tile size:  1.0 B tile size:  1.0 Z tile size:  1.0\n",
      "-----------------------\n",
      "EDP:  10119563.0  % decrease:  0.0\n",
      "Percentage threshold reached\n",
      "Temperature:  0.0001220703125\n",
      "Map:  tensor([ 6.,  1.,  1., 25.,  1.,  1., 21.,  1.,  1.,  1.,  1.,  1.],\n",
      "       grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Local memory size:  tensor(3., grad_fn=<AddBackward0>)\n",
      "A tile size:  1.0 B tile size:  1.0 Z tile size:  1.0\n",
      "-----------------------\n",
      "EDP:  10119563.0  % decrease:  0.0\n",
      "Percentage threshold reached\n",
      "Temperature:  6.103515625e-05\n",
      "Map:  tensor([ 6.,  1.,  1., 25.,  1.,  1., 21.,  1.,  1.,  1.,  1.,  1.],\n",
      "       grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Local memory size:  tensor(3., grad_fn=<AddBackward0>)\n",
      "A tile size:  1.0 B tile size:  1.0 Z tile size:  1.0\n",
      "-----------------------\n",
      "EDP:  10119563.0  % decrease:  0.0\n",
      "Percentage threshold reached\n",
      "Temperature:  3.0517578125e-05\n",
      "Map:  tensor([ 6.,  1.,  1., 25.,  1.,  1., 21.,  1.,  1.,  1.,  1.,  1.],\n",
      "       grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Local memory size:  tensor(3., grad_fn=<AddBackward0>)\n",
      "A tile size:  1.0 B tile size:  1.0 Z tile size:  1.0\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDP:  10119563.0  % decrease:  0.0\n",
      "Percentage threshold reached\n",
      "Temperature:  1.52587890625e-05\n",
      "Map:  tensor([ 6.,  1.,  1., 25.,  1.,  1., 21.,  1.,  1.,  1.,  1.,  1.],\n",
      "       grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Local memory size:  tensor(3., grad_fn=<AddBackward0>)\n",
      "A tile size:  1.0 B tile size:  1.0 Z tile size:  1.0\n",
      "-----------------------\n",
      "EDP:  10119563.0  % decrease:  0.0\n",
      "Percentage threshold reached\n",
      "EDP:  tensor(10119563., grad_fn=<MulBackward0>)  Map:  tensor([ 6.,  1.,  1., 25.,  1.,  1., 21.,  1.,  1.,  1.,  1.,  1.],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "net = ArchMap_spGEMM(2*3, 5*5, 3*7)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters() , lr=0.002)\n",
    "\n",
    "T = torch.tensor([1.0])\n",
    "\n",
    "edp_list = []\n",
    "cooling_points = []\n",
    "temperature_list = []\n",
    "\n",
    "thresh_pct = 0.5\n",
    "\n",
    "pct = 100.0\n",
    "\n",
    "i = 0\n",
    "\n",
    "net(T)\n",
    "\n",
    "while(T.item() > 1.0e-05):\n",
    "    cooling_points.append(i)\n",
    "    temperature_list.append(T.item())\n",
    "    \n",
    "    print(\"Temperature: \", T.item())\n",
    "    print(\"Map: \", net.calcMap(T))\n",
    "    print(\"Arch details:\")\n",
    "    net.archMapStats()\n",
    "    print(\"-----------------------\")\n",
    "    pct = 100.0\n",
    "    while(pct > 0.00001 and T.item() > 1.0e-05):\n",
    "        optimizer.zero_grad() # clear gradients\n",
    "        edp = net(T) # forward step\n",
    "        edp_list.append(edp.item())\n",
    "        loss = edp\n",
    "        loss.backward() # backprop\n",
    "        optimizer.step() # optimize weights\n",
    "        if i % 1000 == 0:\n",
    "            pct = 100.0\n",
    "            if i > 0:\n",
    "                pct = 100.0*abs(edp_list[-1]-edp_list[-500])/edp_list[-500] #100.0*abs(edp_list[-1]-edp_list[-2])/edp_list[-2]\n",
    "            print(\"EDP: \", net(T).item(), \" % decrease: \", pct)    \n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "        i = i + 1\n",
    "    print(\"Percentage threshold reached\")\n",
    "    T = T/2.0\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(edp_list)\n",
    "plt.xlabel(\"Gradient descent iterations\")\n",
    "plt.ylabel(\"EDP\")\n",
    "plt.title(\"Gradient-descent optimization of mapping + architecture\")\n",
    "plt.grid(\"on\")\n",
    "\n",
    "for jdx in range(len(cooling_points)):\n",
    "    plt.plot(np.array([cooling_points[jdx],cooling_points[jdx]]), np.array([-10.0,edp_list[0]]))\n",
    "# len(edp_list)<2 or 100.0*math.abs(edp_list[-1]-edp_list[-2])/edp_list[-2] > thresh_pct\n",
    "\n",
    "print(\"EDP: \", net(T), \" Map: \", net.calcMap(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(edp_list)\n",
    "plt.xlabel(\"Gradient descent iterations\")\n",
    "plt.ylabel(\"EDP\")\n",
    "plt.title(\"Gradient-descent optimization of mapping + architecture\")\n",
    "plt.grid(\"on\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(10119563., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6.,  1.,  1., 25.,  1.,  1., 21.,  1.,  1.,  1.,  1.,  1.],\n",
       "       grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.calcMap(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature:  1.0\n",
      "-----------------------\n",
      "tensor(1.4132e+08, grad_fn=<MulBackward0>)\n",
      "tensor(1.4044e+08, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16999984., grad_fn=<MulBackward0>)\n",
      "tensor(11566562., grad_fn=<MulBackward0>)\n",
      "tensor(9905352., grad_fn=<MulBackward0>)\n",
      "tensor(9195953., grad_fn=<MulBackward0>)\n",
      "tensor(8873597., grad_fn=<MulBackward0>)\n",
      "tensor(8706566., grad_fn=<MulBackward0>)\n",
      "tensor(8613530., grad_fn=<MulBackward0>)\n",
      "tensor(8559025., grad_fn=<MulBackward0>)\n",
      "tensor(8526076., grad_fn=<MulBackward0>)\n",
      "tensor(8505949., grad_fn=<MulBackward0>)\n",
      "tensor(8493617., grad_fn=<MulBackward0>)\n",
      "tensor(8486057., grad_fn=<MulBackward0>)\n",
      "tensor(8481417., grad_fn=<MulBackward0>)\n",
      "tensor(8478573., grad_fn=<MulBackward0>)\n",
      "tensor(8476829., grad_fn=<MulBackward0>)\n",
      "tensor(8475757., grad_fn=<MulBackward0>)\n",
      "tensor(8475103., grad_fn=<MulBackward0>)\n",
      "tensor(8474698., grad_fn=<MulBackward0>)\n",
      "tensor(8474454., grad_fn=<MulBackward0>)\n",
      "-----\n",
      "Final EDP:  tensor(8474303., grad_fn=<MulBackward0>)\n",
      "Final map:  tensor([ 5.7557,  1.0000,  1.1221, 19.6578,  1.0000,  2.4532, 18.6267,  1.4193,\n",
      "         1.3717,  1.4193,  1.0000,  1.0000], grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "T = torch.tensor([1.0])\n",
    "print(\"Temperature: \", T.item())\n",
    "print(\"-----------------------\")\n",
    "print(net(T))\n",
    "for i in range(20000):\n",
    "    optimizer.zero_grad() # clear gradients\n",
    "    edp = net(T) # forward step\n",
    "    loss = edp\n",
    "    loss.backward() # backprop\n",
    "    optimizer.step() # optimize weights\n",
    "    if i % 1000 == 0:\n",
    "        print(net(T))\n",
    "print(\"-----\")\n",
    "print(\"Final EDP: \", net(T))\n",
    "print(\"Final map: \", net.calcMap(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final map:  tensor([1.7869, 3.3463, 1.5824, 5.2726, 3.2067, 6.5668, 5.0695, 6.7205, 2.4300,\n",
      "        2.7369, 1.3967, 2.1636], grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Final map: \", net.calcMap(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature:  0.10000000149011612\n",
      "-----------------------\n",
      "tensor(8512693., grad_fn=<MulBackward0>)\n",
      "tensor(8512693., grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8512692., grad_fn=<MulBackward0>)\n",
      "tensor(8512693., grad_fn=<MulBackward0>)\n",
      "tensor(8474068., grad_fn=<MulBackward0>)\n",
      "tensor(8474070., grad_fn=<MulBackward0>)\n",
      "tensor(8474067., grad_fn=<MulBackward0>)\n",
      "tensor(8474067., grad_fn=<MulBackward0>)\n",
      "tensor(8474068., grad_fn=<MulBackward0>)\n",
      "tensor(8474066., grad_fn=<MulBackward0>)\n",
      "tensor(8474067., grad_fn=<MulBackward0>)\n",
      "tensor(8474066., grad_fn=<MulBackward0>)\n",
      "tensor(8474065., grad_fn=<MulBackward0>)\n",
      "tensor(8474066., grad_fn=<MulBackward0>)\n",
      "tensor(8474065., grad_fn=<MulBackward0>)\n",
      "tensor(8474065., grad_fn=<MulBackward0>)\n",
      "tensor(8474068., grad_fn=<MulBackward0>)\n",
      "tensor(8474066., grad_fn=<MulBackward0>)\n",
      "tensor(8474066., grad_fn=<MulBackward0>)\n",
      "tensor(8474065., grad_fn=<MulBackward0>)\n",
      "tensor(8474067., grad_fn=<MulBackward0>)\n",
      "-----\n",
      "Final EDP:  tensor(8474069., grad_fn=<MulBackward0>)\n",
      "Final map:  tensor([ 5.7559,  1.0000,  1.1221, 19.6561,  1.0000,  2.4539, 18.6278,  1.4192,\n",
      "         1.3716,  1.4192,  1.0000,  1.0000], grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "T = torch.tensor([0.1])\n",
    "print(\"Temperature: \", T.item())\n",
    "print(\"-----------------------\")\n",
    "print(net(T))\n",
    "for i in range(20000):\n",
    "    optimizer.zero_grad() # clear gradients\n",
    "    edp = net(T) # forward step\n",
    "    loss = edp\n",
    "    loss.backward() # backprop\n",
    "    optimizer.step() # optimize weights\n",
    "    if i % 1000 == 0:\n",
    "        print(net(T))\n",
    "print(\"-----\")\n",
    "print(\"Final EDP: \", net(T))\n",
    "print(\"Final map: \", net.calcMap(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature:  0.0010000000474974513\n",
      "-----------------------\n",
      "tensor(10119563., grad_fn=<MulBackward0>)\n",
      "tensor(10119563., grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10119563., grad_fn=<MulBackward0>)\n",
      "tensor(10119563., grad_fn=<MulBackward0>)\n",
      "tensor(10119563., grad_fn=<MulBackward0>)\n",
      "tensor(10119563., grad_fn=<MulBackward0>)\n",
      "tensor(10119563., grad_fn=<MulBackward0>)\n",
      "tensor(10119563., grad_fn=<MulBackward0>)\n",
      "tensor(10119563., grad_fn=<MulBackward0>)\n",
      "tensor(10119563., grad_fn=<MulBackward0>)\n",
      "tensor(10119563., grad_fn=<MulBackward0>)\n",
      "-----\n",
      "Final EDP:  tensor(10119563., grad_fn=<MulBackward0>)\n",
      "Final map:  tensor([ 6.,  1.,  1., 25.,  1.,  1., 21.,  1.,  1.,  1.,  1.,  1.],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "T = torch.tensor([0.001])\n",
    "print(\"Temperature: \", T.item())\n",
    "print(\"-----------------------\")\n",
    "print(net(T))\n",
    "for i in range(10000):\n",
    "    optimizer.zero_grad() # clear gradients\n",
    "    edp = net(T) # forward step\n",
    "    loss = edp\n",
    "    loss.backward() # backprop\n",
    "    optimizer.step() # optimize weights\n",
    "    if i % 1000 == 0:\n",
    "        print(net(T))\n",
    "print(\"-----\")\n",
    "print(\"Final EDP: \", net(T))\n",
    "print(\"Final map: \", net.calcMap(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature:  0.009999999776482582\n",
      "-----------------------\n",
      "tensor(9359604., grad_fn=<MulBackward0>)\n",
      "tensor(9359609., grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9359602., grad_fn=<MulBackward0>)\n",
      "tensor(9359610., grad_fn=<MulBackward0>)\n",
      "tensor(9359603., grad_fn=<MulBackward0>)\n",
      "tensor(9359601., grad_fn=<MulBackward0>)\n",
      "tensor(9359624., grad_fn=<MulBackward0>)\n",
      "tensor(9359604., grad_fn=<MulBackward0>)\n",
      "tensor(9359759., grad_fn=<MulBackward0>)\n",
      "tensor(9359612., grad_fn=<MulBackward0>)\n",
      "tensor(9048232., grad_fn=<MulBackward0>)\n",
      "-----\n",
      "Final EDP:  tensor(9048230., grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Temperature: \", T.item())\n",
    "print(\"-----------------------\")\n",
    "print(net(T))\n",
    "for i in range(10000):\n",
    "    optimizer.zero_grad() # clear gradients\n",
    "    edp = net(T) # forward step\n",
    "    loss = edp\n",
    "    loss.backward() # backprop\n",
    "    optimizer.step() # optimize weights\n",
    "    if i % 1000 == 0:\n",
    "        print(net(T))\n",
    "print(\"-----\")\n",
    "print(\"Final EDP: \", net(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
