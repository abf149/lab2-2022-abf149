{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your name:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starter Code\n",
    "\n",
    "This notebook implements starter code to help you get started with the assignment. If you have a personal GPU, copy this starter code to another directory and run this notebook using your personal GPU. In that case, the docker we provide will not support PyTorch with GPU, and you can create your own virtual environment (e.g., conda) with PyTorch support (https://pytorch.org/get-started/locally/). \n",
    "\n",
    "To run this notebook you must __first create a folder called `./dataset` and download all the data files from the Kaggle competition page__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "%matplotlib inline\n",
    "\n",
    "log_interval = 1000,\n",
    "epochs = 1\n",
    "\n",
    "params = {\n",
    "    'log_interval': 1000,\n",
    "    'epochs': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/conda/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "bypass_cuda=True\n",
    "\n",
    "# GPU setup\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"Using {}\".format('GPU' if use_cuda else 'CPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abstract a \"one-of-N\" or N-way one-hot decision (usually for assigning a factor of a rank to a memory level)\n",
    "#\n",
    "# Initialization:\n",
    "# - num_factors: number of decision ways (factors) to choose between\n",
    "#\n",
    "# Input: \n",
    "# - x: [factors, baselines, temperature]\n",
    "# - factors is a list length num_factors containing the factors to select among\n",
    "# - baselines is a list of length num_factors containing the way-wise value that \n",
    "#   an output way should have when it is unselected\n",
    "# - temperature is a software parameter; high temperature smooths the softmax, \n",
    "#   low temperature approximates a discrete decision\n",
    "#\n",
    "# Trainable parameters:\n",
    "# - W: way-wise weights input to softmax\n",
    "#\n",
    "# Output: tensor of num_factors outputs. The way i which is weighted highest in W \n",
    "#         should be railed to factors[i], the other ways should be weighted to baselines[i]\n",
    "\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class FactorMux(nn.Module):\n",
    "    def __init__(self, num_factors):\n",
    "        super(FactorMux, self).__init__()\n",
    "        self.num_factors = num_factors\n",
    "        self.W = torch.nn.Parameter(torch.randn(self.num_factors))\n",
    "        self.W.requires_grad = True\n",
    "        self.softmax1 = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [factors, baselines, temperature]\n",
    "        \n",
    "        assert len(x) == 2*self.num_factors + 1\n",
    "        \n",
    "        factors = x[0:self.num_factors]\n",
    "        baselines = x[self.num_factors:(2*self.num_factors)]\n",
    "        temperature = x[2*self.num_factors].item()\n",
    "        \n",
    "        #print(factors, baselines, 1.0/temperature)\n",
    "        \n",
    "        x = self.softmax1((1.0/temperature)*self.W) * (factors - baselines) + baselines\n",
    "        \n",
    "        return x\n",
    "\n",
    "class LoopNestSelector(FactorMux):\n",
    "    def __init__(self, num_datatypes):\n",
    "        super(LoopNestSelector, self).__init__(num_datatypes) # FactorMux num_factors\n",
    "        \n",
    "        use_cuda = torch.cuda.is_available()\n",
    "        self.use_cuda = use_cuda        \n",
    "        \n",
    "        if use_cuda and (not bypass_cuda):\n",
    "            self.baseline = torch.full((num_datatypes,),1.0).cuda()            \n",
    "        else:\n",
    "            self.baseline = torch.full((num_datatypes,),1.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [factors, temperature]\n",
    "\n",
    "        if not torch.is_tensor(x):\n",
    "            x = torch.tensor(x)\n",
    "        \n",
    "        reuse_factors = x[0:self.num_factors]\n",
    "        temperature = x[self.num_factors][None]\n",
    "        \n",
    "        inputs = torch.cat((reuse_factors, self.baseline, temperature), 0)\n",
    "        x = super().forward(inputs)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class RankLoopBoundSelector(nn.Module):\n",
    "    def __init__(self, num_rank_loops, rank_factor_list):\n",
    "        super(RankLoopBoundSelector, self).__init__() # FactorMux\n",
    "        \n",
    "        use_cuda = torch.cuda.is_available()\n",
    "        self.use_cuda = use_cuda\n",
    "    \n",
    "        if not torch.is_tensor(rank_factor_list):\n",
    "            rank_factor_list = torch.tensor(rank_factor_list)            \n",
    "            \n",
    "        if not torch.is_tensor(num_rank_loops):\n",
    "            num_rank_loops = torch.tensor(num_rank_loops)\n",
    "            \n",
    "        if use_cuda  and (not bypass_cuda):\n",
    "            #print(\"USING CUDA\")\n",
    "            rank_factor_list = rank_factor_list.cuda()\n",
    "            num_rank_loops = num_rank_loops.cuda()\n",
    "        \n",
    "        self.num_rank_loops = num_rank_loops\n",
    "        self.rank_factor_list = rank_factor_list\n",
    "        self.num_rank_factors = len(self.rank_factor_list)\n",
    "        self.factorMuxes = nn.ModuleList([FactorMux(self.num_rank_loops) for factor in self.rank_factor_list])\n",
    "        \n",
    "        self.baseline = 1.0\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [temperature]\n",
    "\n",
    "        if not torch.is_tensor(x):\n",
    "            x = torch.tensor([x])\n",
    "        \n",
    "        torch.full((self.num_rank_loops,), self.rank_factor_list[self.num_rank_factors-1])\n",
    "\n",
    "\n",
    "        #rint(torch.full((self.num_rank_loops,), self.rank_factor_list[self.num_rank_factors-1]).cuda().device)\n",
    "        #rint(torch.full((self.num_rank_loops,), self.baseline).device)\n",
    "        #rint(x.device)       \n",
    "        \n",
    "        if self.use_cuda  and (not bypass_cuda):\n",
    "            x = torch.stack( \\\n",
    "                [self.factorMuxes[mdx](\n",
    "                torch.cat( \\\n",
    "                (torch.full((self.num_rank_loops,), self.rank_factor_list[mdx]).cuda(), torch.full((self.num_rank_loops,), self.baseline).cuda(), \\\n",
    "                x),0) \\\n",
    "                ) \\\n",
    "                for mdx in range(self.num_rank_factors)])\n",
    "        else:\n",
    "            x = torch.stack( \\\n",
    "                [self.factorMuxes[mdx](\n",
    "                torch.cat( \\\n",
    "                (torch.full((self.num_rank_loops,), self.rank_factor_list[mdx]), torch.full((self.num_rank_loops,), self.baseline), \\\n",
    "                x),0) \\\n",
    "                ) \\\n",
    "                for mdx in range(self.num_rank_factors)])            \n",
    "        \n",
    "        x = torch.prod(x,0)\n",
    "        \n",
    "        #print(x)\n",
    "        \n",
    "        #x = torch.tensor([  for vec in x])\n",
    "        \n",
    "        return x\n",
    "\n",
    "class MapSelector_spGEMM(nn.Module):\n",
    "    \n",
    "    def repeat_prime(self, n, d):\n",
    "        lst = [d]\n",
    "        fac = d\n",
    "\n",
    "        while n % (fac * d) == 0:\n",
    "            fac = fac * d\n",
    "            lst.append(d)\n",
    "\n",
    "        return lst\n",
    "\n",
    "    # https://stackoverflow.com/questions/16996217/prime-factorization-list\n",
    "    def primes(self, n):\n",
    "        divisors = [ self.repeat_prime(n, d) for d in range(2,n//2+1) if n % d == 0 ]\n",
    "        divisors = sum(divisors, [])\n",
    "        return [ d for d in divisors if \\\n",
    "                 all( d % od != 0 for od in divisors if od != d ) ]    \n",
    "    \n",
    "    def __init__(self, M, K, N):\n",
    "        super(MapSelector_spGEMM, self).__init__() # FactorMux\n",
    "        \n",
    "        self.M = M\n",
    "        self.K = K\n",
    "        self.N = N\n",
    "        self.M_factors = self.primes(self.M)\n",
    "        self.K_factors = self.primes(self.K)\n",
    "        self.N_factors = self.primes(self.N)\n",
    "        self.main_mem_loops = 2\n",
    "        self.local_mem_loops = 1\n",
    "        self.total_loops = self.main_mem_loops + self.local_mem_loops\n",
    "        \n",
    "        # Loop bounds\n",
    "        self.M_bound_selector = RankLoopBoundSelector(self.total_loops, self.M_factors)\n",
    "        self.K_bound_selector = RankLoopBoundSelector(self.total_loops, self.K_factors)\n",
    "        self.N_bound_selector = RankLoopBoundSelector(self.total_loops, self.N_factors)        \n",
    "        \n",
    "        # Loop nest ordering\n",
    "        self.num_datatypes = 3\n",
    "        self.main_mem_temporal_LoopNestSelector = LoopNestSelector(self.num_datatypes)        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [temperature]\n",
    "\n",
    "        if not torch.is_tensor(x):\n",
    "            x = torch.tensor([x])\n",
    "        \n",
    "        # Calculate loop bounds\n",
    "        M_loop_bounds = self.M_bound_selector(x)\n",
    "        K_loop_bounds = self.K_bound_selector(x)\n",
    "        N_loop_bounds = self.N_bound_selector(x)        \n",
    "        M_main_mem_temporal = M_loop_bounds[1][None] # B reuse ceiling\n",
    "        K_main_mem_temporal = K_loop_bounds[1][None] # Z reuse ceiling\n",
    "        N_main_mem_temporal = N_loop_bounds[1][None] # A reuse ceiling\n",
    "        \n",
    "        #print(torch.flatten(torch.cat((N_main_mem_temporal, M_main_mem_temporal, K_main_mem_temporal, x),0)))\n",
    "        \n",
    "        # Calculate loop nest ordering\n",
    "        main_mem_loop_nest = self.main_mem_temporal_LoopNestSelector( \\\n",
    "            torch.flatten(torch.cat((N_main_mem_temporal, M_main_mem_temporal, K_main_mem_temporal, x),0)))\n",
    "        \n",
    "        #print(M_loop_bounds,K_loop_bounds,N_loop_bounds, main_mem_loop_nest)        \n",
    "        \n",
    "        x = torch.cat((M_loop_bounds,K_loop_bounds,N_loop_bounds, main_mem_loop_nest),0)\n",
    "        \n",
    "        # torch.tensor([L1 spatial bound & L1 temporal bound & L0 temporal bound For ranks M, K, N; reuse factor for A, B, Z])\n",
    "        return x\n",
    "\n",
    "class ArchMap_spGEMM(nn.Module): \n",
    "    \n",
    "    def __init__(self, M, K, N):\n",
    "        super(ArchMap_spGEMM, self).__init__() # FactorMux\n",
    "        \n",
    "        self.M = M\n",
    "        self.K = K\n",
    "        self.N = N\n",
    "        self.mapper = MapSelector_spGEMM(M, K, N)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [temperature]\n",
    "\n",
    "        if not torch.is_tensor(x):\n",
    "            x = torch.tensor([x])\n",
    "        \n",
    "        # Problem characteristics\n",
    "        M = float(self.M)\n",
    "        K = float(self.K)\n",
    "        N = float(self.N)\n",
    "        A_matrix_size = M*K\n",
    "        B_matrix_size = K*N\n",
    "        Z_matrix_size = M*N\n",
    "        main_memory_size = A_matrix_size+B_matrix_size+Z_matrix_size\n",
    "        total_num_macs = M*K*N\n",
    "        \n",
    "        T = x\n",
    "        \n",
    "        # Calculate map (loop bounds & loop nest)\n",
    "        # torch.tensor([L1 spatial bound & L1 temporal bound & L0 temporal bound For ranks M, K, N; reuse factor for A, B, Z])\n",
    "        x = self.mapper(x)\n",
    "        \n",
    "        self.x = x\n",
    "        \n",
    "        # Break out map parameters\n",
    "        M_L1_spatial_bound = x[0]\n",
    "        M_L1_temporal_bound = x[1]\n",
    "        M_L0_temporal_bound = x[2]\n",
    "        K_L1_spatial_bound = x[3]\n",
    "        K_L1_temporal_bound = x[4]\n",
    "        K_L0_temporal_bound = x[5]\n",
    "        N_L1_spatial_bound = x[6]\n",
    "        N_L1_temporal_bound = x[7]\n",
    "        N_L0_temporal_bound = x[8]        \n",
    "        A_reuse = x[9]\n",
    "        B_reuse = x[10]\n",
    "        Z_reuse = x[11]\n",
    "\n",
    "        # Hook\n",
    "        self.M_L1_spatial_bound = M_L1_spatial_bound\n",
    "        self.M_L1_temporal_bound = M_L1_temporal_bound\n",
    "        self.M_L0_temporal_bound = M_L0_temporal_bound\n",
    "        self.K_L1_spatial_bound = K_L1_spatial_bound\n",
    "        self.K_L1_temporal_bound = K_L1_temporal_bound\n",
    "        self.K_L0_temporal_bound = K_L0_temporal_bound\n",
    "        self.N_L1_spatial_bound = N_L1_spatial_bound\n",
    "        self.N_L1_temporal_bound = N_L1_temporal_bound\n",
    "        self.N_L0_temporal_bound = N_L0_temporal_bound       \n",
    "        self.A_reuse = A_reuse\n",
    "        self.B_reuse = B_reuse\n",
    "        self.Z_reuse = Z_reuse \n",
    "        \n",
    "        # Spatial characteristics\n",
    "        spatial_fan_out = M_L1_spatial_bound*K_L1_spatial_bound*N_L1_spatial_bound\n",
    "        \n",
    "        # Tiling\n",
    "        main_memory_tile_pair_count = M*K*N/M_L0_temporal_bound/K_L0_temporal_bound/N_L0_temporal_bound\n",
    "        A_tile_size = M_L0_temporal_bound*K_L0_temporal_bound\n",
    "        B_tile_size = K_L0_temporal_bound*N_L0_temporal_bound\n",
    "        Z_tile_size = M_L0_temporal_bound*N_L0_temporal_bound \n",
    "        local_memory_num_macs_per_tile = M_L0_temporal_bound*K_L0_temporal_bound*N_L0_temporal_bound\n",
    "        \n",
    "        # Per-PE characteristics\n",
    "        local_memory_size = A_tile_size + B_tile_size + Z_tile_size\n",
    "        local_num_macs = M*K*N/spatial_fan_out\n",
    "        \n",
    "        # Global characteristics\n",
    "        total_local_memory_size = local_memory_size*spatial_fan_out\n",
    "        \n",
    "        # Access counts\n",
    "        main_memory_reads = main_memory_tile_pair_count*(A_tile_size/A_reuse + B_tile_size/B_reuse + Z_tile_size/Z_reuse)\n",
    "        main_memory_writes = main_memory_tile_pair_count*(Z_tile_size/Z_reuse)\n",
    "        local_memory_reads = local_num_macs*3 # A, B, Z\n",
    "        local_memory_writes = local_num_macs # Just Z\n",
    "        total_local_memory_reads = local_memory_reads * spatial_fan_out\n",
    "        total_local_memory_writes = local_memory_writes * spatial_fan_out\n",
    "        \n",
    "        # Energy constants (currently arbitrary)\n",
    "        E_DRAM_static = 0.05\n",
    "        E_SRAM_static = 0.02\n",
    "        E_DRAM_acc = 1.0\n",
    "        E_SRAM_acc = 0.7\n",
    "        E_MAC = 0.1\n",
    "        \n",
    "        # Scale energy consumption of memories to memory size\n",
    "        main_memory_unit_read_energy = E_DRAM_acc*main_memory_size\n",
    "        main_memory_unit_write_energy = main_memory_unit_read_energy\n",
    "        local_memory_static_energy = E_SRAM_static*local_memory_size\n",
    "        local_memory_unit_read_energy = E_SRAM_acc*local_memory_size\n",
    "        local_memory_unit_write_energy = local_memory_unit_read_energy\n",
    "        \n",
    "        # Calculate energy consumption\n",
    "        total_main_memory_access_energy = main_memory_reads*main_memory_unit_read_energy + \\\n",
    "                                          main_memory_writes*main_memory_unit_write_energy\n",
    "        total_local_memory_static_energy = local_memory_static_energy*spatial_fan_out\n",
    "        total_local_memory_access_energy = total_local_memory_reads*local_memory_unit_read_energy + \\\n",
    "                                           total_local_memory_writes*local_memory_unit_write_energy\n",
    "        total_MAC_energy = total_num_macs*E_MAC\n",
    "        total_problem_energy = total_MAC_energy + total_local_memory_access_energy + \\\n",
    "                               total_local_memory_static_energy + total_main_memory_access_energy\n",
    "        \n",
    "        # Calculate latency in cycles\n",
    "        total_problem_latency = local_num_macs\n",
    "        \n",
    "        problem_edp = total_problem_energy*total_problem_latency\n",
    "        \n",
    "        self.problem_edp = problem_edp\n",
    "        \n",
    "        limit_spatial_fan_out = 512.0\n",
    "        \n",
    "        self.constraint_violation = False\n",
    "        \n",
    "        # Calculate EDP\n",
    "        if spatial_fan_out.item() > limit_spatial_fan_out:\n",
    "\n",
    "            self.constraint_violation = True\n",
    "            \n",
    "            problem_edp = problem_edp + 1.0e10*((spatial_fan_out - limit_spatial_fan_out)/T.item())   \n",
    "            #print(1.0e20*((spatial_fan_out - 512.0)))\n",
    "#            problem_edp = total_problem_energy*total_problem_latency + torch.exp((spatial_fan_out - 512.0))\n",
    "#            print(\"Being used: \", torch.exp((spatial_fan_out - 512.0)), \\\n",
    "#                   \"delta: \", spatial_fan_out - 512.0, \\\n",
    "#                   \"spatial fan-out: \", spatial_fan_out)\n",
    "\n",
    "            #            problem_edp = total_problem_energy*total_problem_latency + torch.exp(-(spatial_fan_out.item() - 512.0)/T.item())\n",
    "            \n",
    "            #1.0e10/(1+math.exp(-(spatial_fan_out.item() - 512.0)/T.item()))\n",
    "\n",
    "        limit_local_memory_size = 10.0\n",
    "        \n",
    "        if local_memory_size.item() > limit_local_memory_size:\n",
    "            \n",
    "            self.constraint_violation = True\n",
    "            \n",
    "            problem_edp = problem_edp + 1.0e10*((local_memory_size - limit_local_memory_size)/T.item())   \n",
    "        \n",
    "        return problem_edp\n",
    "    \n",
    "    def calcMap(self,x):\n",
    "        return self.x\n",
    "    \n",
    "    def archMapStats(self):\n",
    "        # Problem characteristics\n",
    "        M = float(self.M)\n",
    "        K = float(self.K)\n",
    "        N = float(self.N)\n",
    "        A_matrix_size = M*K\n",
    "        B_matrix_size = K*N\n",
    "        Z_matrix_size = M*N\n",
    "        main_memory_size = A_matrix_size+B_matrix_size+Z_matrix_size\n",
    "        total_num_macs = M*K*N        \n",
    "        \n",
    "        x = self.calcMap(1.0)\n",
    "        \n",
    "        M_L1_spatial_bound = x[0]\n",
    "        M_L1_temporal_bound = x[1]\n",
    "        M_L0_temporal_bound = x[2]\n",
    "        K_L1_spatial_bound = x[3]\n",
    "        K_L1_temporal_bound = x[4]\n",
    "        K_L0_temporal_bound = x[5]\n",
    "        N_L1_spatial_bound = x[6]\n",
    "        N_L1_temporal_bound = x[7]\n",
    "        N_L0_temporal_bound = x[8]        \n",
    "        A_reuse = x[9]\n",
    "        B_reuse = x[10]\n",
    "        Z_reuse = x[11]  \n",
    "        \n",
    "        # Spatial characteristics\n",
    "        spatial_fan_out = M_L1_spatial_bound*K_L1_spatial_bound*N_L1_spatial_bound\n",
    "        \n",
    "        # Tiling\n",
    "        main_memory_tile_pair_count = M*K*N/M_L0_temporal_bound/K_L0_temporal_bound/N_L0_temporal_bound\n",
    "        A_tile_size = M_L0_temporal_bound*K_L0_temporal_bound\n",
    "        B_tile_size = K_L0_temporal_bound*N_L0_temporal_bound\n",
    "        Z_tile_size = M_L0_temporal_bound*N_L0_temporal_bound \n",
    "        local_memory_num_macs_per_tile = M_L0_temporal_bound*K_L0_temporal_bound*N_L0_temporal_bound\n",
    "        \n",
    "        # Per-PE characteristics\n",
    "        local_memory_size = A_tile_size + B_tile_size + Z_tile_size\n",
    "        local_num_macs = M*K*N/spatial_fan_out\n",
    "        \n",
    "        print(\"Spatial fan-out: \", spatial_fan_out.item())\n",
    "        print(\"Local memory size: \", local_memory_size.item())\n",
    "        print(\"A tile size: \", A_tile_size.item(), \"B tile size: \", B_tile_size.item(), \"Z tile size: \", Z_tile_size.item())\n",
    "        \n",
    "        # Global characteristics\n",
    "        total_local_memory_size = local_memory_size*spatial_fan_out\n",
    "        \n",
    "        # Access counts\n",
    "        main_memory_reads = main_memory_tile_pair_count*(A_tile_size/A_reuse + B_tile_size/B_reuse + Z_tile_size/Z_reuse)\n",
    "        main_memory_writes = main_memory_tile_pair_count*(Z_tile_size/Z_reuse)\n",
    "        local_memory_reads = local_num_macs*3 # A, B, Z\n",
    "        local_memory_writes = local_num_macs # Just Z\n",
    "        total_local_memory_reads = local_memory_reads * spatial_fan_out\n",
    "        total_local_memory_writes = local_memory_writes * spatial_fan_out\n",
    "        \n",
    "        # Energy constants (currently arbitrary)\n",
    "        E_DRAM_static = 0.05\n",
    "        E_SRAM_static = 0.02\n",
    "        E_DRAM_acc = 1.0\n",
    "        E_SRAM_acc = 0.7\n",
    "        E_MAC = 0.1\n",
    "        \n",
    "        # Scale energy consumption of memories to memory size\n",
    "        main_memory_unit_read_energy = E_DRAM_acc*main_memory_size\n",
    "        main_memory_unit_write_energy = main_memory_unit_read_energy\n",
    "        local_memory_static_energy = E_SRAM_static*local_memory_size\n",
    "        local_memory_unit_read_energy = E_SRAM_acc*local_memory_size\n",
    "        local_memory_unit_write_energy = local_memory_unit_read_energy\n",
    "        \n",
    "        # Calculate energy consumption\n",
    "        total_main_memory_access_energy = main_memory_reads*main_memory_unit_read_energy + \\\n",
    "                                          main_memory_writes*main_memory_unit_write_energy\n",
    "        total_local_memory_static_energy = local_memory_static_energy*spatial_fan_out\n",
    "        total_local_memory_access_energy = total_local_memory_reads*local_memory_unit_read_energy + \\\n",
    "                                           total_local_memory_writes*local_memory_unit_write_energy\n",
    "        total_MAC_energy = total_num_macs*E_MAC\n",
    "        total_problem_energy = total_MAC_energy + total_local_memory_access_energy + \\\n",
    "                               total_local_memory_static_energy + total_main_memory_access_energy\n",
    "        \n",
    "        # Calculate latency in cycles\n",
    "        total_problem_latency = local_num_macs\n",
    "        \n",
    "        # Calculate EDP\n",
    "        problem_edp = total_problem_energy*total_problem_latency\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def oneOpt(res_lst, stp_lst):\n",
    "    \n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    \n",
    "    M = 2*3*2\n",
    "    K = 5*3\n",
    "    N = 5*7\n",
    "    \n",
    "    #M = M.cuda()\n",
    "    #K = K.cuda()\n",
    "    #N = N.cuda()\n",
    "    \n",
    "    net = ArchMap_spGEMM(2*3*2, 5*3, 5*7)\n",
    "    \n",
    "    if use_cuda and (not bypass_cuda):\n",
    "        net.cuda()\n",
    "    \n",
    "    optimizer = optim.Adam(net.parameters() , lr=0.0001)\n",
    "\n",
    "    T = torch.tensor([1.0])\n",
    "    \n",
    "    if use_cuda and (not bypass_cuda):\n",
    "        T = T.cuda()\n",
    "\n",
    "    edp_list = []\n",
    "    edp_pen_list = []\n",
    "    cooling_points = []\n",
    "    temperature_list = []\n",
    "\n",
    "    thresh_pct = 0.5\n",
    "\n",
    "    edp = 0.0\n",
    "\n",
    "    pct = 100.0\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    net(T)\n",
    "\n",
    "    target_temp = 0.99\n",
    "    \n",
    "    while(T.item() > target_temp):\n",
    "        cooling_points.append(i)\n",
    "        temperature_list.append(T.item())\n",
    "\n",
    "        print(\"Temperature: \", T.item())\n",
    "        print(\"Map: \", net.calcMap(T))\n",
    "        print(\"Arch details:\")\n",
    "        net.archMapStats()\n",
    "        print(\"-----------------------\")\n",
    "        pct = 100.0\n",
    "\n",
    "        j = i\n",
    "        while((net.constraint_violation or (pct > 1.0  and (i-j)<100000)) and T.item() > target_temp):\n",
    "            assert stp_lst[0] == False\n",
    "            \n",
    "            optimizer.zero_grad() # clear gradients\n",
    "            edp_pen = net(T) # forward step\n",
    "            edp = net.problem_edp\n",
    "            edp_pen_list.append(edp_pen.item())\n",
    "            edp_list.append(edp.item())\n",
    "            loss = edp_pen\n",
    "            loss.backward() # backprop\n",
    "            optimizer.step() # optimize weights\n",
    "            if i % 1000 == 0:\n",
    "                pct = 100.0\n",
    "                if i > 0:\n",
    "                    pct = 100.0*abs(edp_list[-1]-edp_list[-500])/edp_list[-500] #100.0*abs(edp_list[-1]-edp_list[-2])/edp_list[-2]\n",
    "                print(\"EDP: \", edp_list[-1], \"EDP (penalized): \",  edp_pen_list[-1], \" % decrease: \", pct)    \n",
    "\n",
    "            i = i + 1\n",
    "        print(\"Percentage threshold reached\")\n",
    "        T = T/2.0\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.plot(edp_list)\n",
    "    plt.xlabel(\"Gradient descent iterations\")\n",
    "    plt.ylabel(\"EDP\")\n",
    "    plt.title(\"Gradient-descent optimization of mapping + architecture\")\n",
    "    plt.grid(\"on\")\n",
    "\n",
    "    for jdx in range(len(cooling_points)):\n",
    "        plt.plot(np.array([cooling_points[jdx],cooling_points[jdx]]), np.array([-10.0,edp_list[0]]))\n",
    "    # len(edp_list)<2 or 100.0*math.abs(edp_list[-1]-edp_list[-2])/edp_list[-2] > thresh_pct\n",
    "\n",
    "    print(\"EDP: \", net(T), \" Map: \", net.calcMap(T))\n",
    "    \n",
    "    res_lst.append(net)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_220/1070192147.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax1((1.0/temperature)*self.W) * (factors - baselines) + baselines\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature:  1.0\n",
      "Map:  tensor([3.4992, 3.4473, 1.1812, 2.4572, 4.5385, 4.6964, 4.4852, 7.2759, 5.6332,\n",
      "        2.1234, 1.1876, 3.6339], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  38.56421661376953\n",
      "Local memory size:  38.65717315673828\n",
      "A tile size:  5.5472588539123535 B tile size:  26.45611000061035 Z tile size:  6.653806686401367\n",
      "-----------------------\n",
      "EDP:  1169412992.0 EDP (penalized):  287741149184.0  % decrease:  100.0\n",
      "EDP:  1038614592.0 EDP (penalized):  205145931776.0  % decrease:  5.482936278666679\n",
      "EDP:  939764288.0 EDP (penalized):  146425233408.0  % decrease:  4.685205075738363\n",
      "EDP:  861794112.0 EDP (penalized):  102788612096.0  % decrease:  4.0892543617540325\n",
      "EDP:  798869760.0 EDP (penalized):  69351628800.0  % decrease:  3.5920818831733454\n",
      "EDP:  747699072.0 EDP (penalized):  43204775936.0  % decrease:  3.136618697335378\n",
      "EDP:  706254848.0 EDP (penalized):  22484131840.0  % decrease:  2.695168138509083\n",
      "EDP:  673149888.0 EDP (penalized):  5913790464.0  % decrease:  2.257843465603165\n",
      "EDP:  650401344.0 EDP (penalized):  650401344.0  % decrease:  1.4876234782837972\n",
      "EDP:  629399936.0 EDP (penalized):  629399936.0  % decrease:  1.6746468410407254\n",
      "EDP:  606150016.0 EDP (penalized):  606150016.0  % decrease:  1.9296097466773043\n",
      "EDP:  579960064.0 EDP (penalized):  579960064.0  % decrease:  2.2711747786727807\n",
      "EDP:  550195840.0 EDP (penalized):  550195840.0  % decrease:  2.7118056746174957\n",
      "EDP:  516314624.0 EDP (penalized):  516314624.0  % decrease:  3.2687296411079627\n",
      "EDP:  478104992.0 EDP (penalized):  478104992.0  % decrease:  3.9374890778005227\n",
      "EDP:  436004320.0 EDP (penalized):  436004320.0  % decrease:  4.686929220270557\n",
      "EDP:  391123072.0 EDP (penalized):  391123072.0  % decrease:  5.4738797515001485\n",
      "EDP:  345153440.0 EDP (penalized):  345153440.0  % decrease:  6.2349173243350755\n",
      "EDP:  300163168.0 EDP (penalized):  300163168.0  % decrease:  6.884544605703887\n",
      "EDP:  258205552.0 EDP (penalized):  258205552.0  % decrease:  7.337223928284372\n",
      "EDP:  220764928.0 EDP (penalized):  220764928.0  % decrease:  7.562111380965435\n",
      "EDP:  188437392.0 EDP (penalized):  188437392.0  % decrease:  7.594615518058314\n",
      "EDP:  161100480.0 EDP (penalized):  161100480.0  % decrease:  7.490153674073588\n",
      "EDP:  138254816.0 EDP (penalized):  138254816.0  % decrease:  7.293353656515125\n",
      "EDP:  119283272.0 EDP (penalized):  119283272.0  % decrease:  7.031441341005055\n",
      "EDP:  118505320.0 EDP (penalized):  118505320.0  % decrease:  0.0077357630739627375\n",
      "Percentage threshold reached\n",
      "EDP:  tensor(2.3487e+12, grad_fn=<AddBackward0>)  Map:  tensor([ 5.8941,  2.1391,  1.0166,  9.5634,  2.7171,  1.2945, 11.1664,  5.6950,\n",
      "         1.2009,  1.5502,  1.3483,  1.9909], grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_220/1070192147.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax1((1.0/temperature)*self.W) * (factors - baselines) + baselines\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stp_lst = [False]\n",
    "res_lst0 = []\n",
    "\n",
    "oneOpt(res_lst0, stp_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#import threading\n",
    "\n",
    "#stp_lst = [False]\n",
    "\n",
    "#res_lst0 = []\n",
    "#res_lst1 = []\n",
    "#res_lst2 = []\n",
    "#res_lst3 = []\n",
    "\n",
    "#th0 = threading.Thread(target=oneOpt, args=(res_lst0,stp_lst))\n",
    "#th1 = threading.Thread(target=oneOpt, args=(res_lst1,stp_lst))\n",
    "#th2 = threading.Thread(target=oneOpt, args=(res_lst2,stp_lst))\n",
    "#th3 = threading.Thread(target=oneOpt, args=(res_lst3,stp_lst))\n",
    "\n",
    "#th0.start()\n",
    "#th1.start()\n",
    "#th2.start()\n",
    "#th3.start()\n",
    "\n",
    "#th0.join()\n",
    "#th1.join()\n",
    "#th2.join()\n",
    "#th3.join()\n",
    "\n",
    "#T = torch.tensor([1.0e-05])\n",
    "\n",
    "#print(res_lst0[0](T), res_lst1[0](T), res_lst2[0](T), res_lst3[0](T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stp_lst[0] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
