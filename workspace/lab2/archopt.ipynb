{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your name:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starter Code\n",
    "\n",
    "This notebook implements starter code to help you get started with the assignment. If you have a personal GPU, copy this starter code to another directory and run this notebook using your personal GPU. In that case, the docker we provide will not support PyTorch with GPU, and you can create your own virtual environment (e.g., conda) with PyTorch support (https://pytorch.org/get-started/locally/). \n",
    "\n",
    "To run this notebook you must __first create a folder called `./dataset` and download all the data files from the Kaggle competition page__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "%matplotlib inline\n",
    "\n",
    "log_interval = 1000,\n",
    "epochs = 1\n",
    "\n",
    "params = {\n",
    "    'log_interval': 1000,\n",
    "    'epochs': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "bypass_cuda=True\n",
    "\n",
    "# GPU setup\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"Using {}\".format('GPU' if use_cuda else 'CPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abstract a \"one-of-N\" or N-way one-hot decision (usually for assigning a factor of a rank to a memory level)\n",
    "#\n",
    "# Initialization:\n",
    "# - num_factors: number of decision ways (factors) to choose between\n",
    "#\n",
    "# Input: \n",
    "# - x: [factors, baselines, temperature]\n",
    "# - factors is a list length num_factors containing the factors to select among\n",
    "# - baselines is a list of length num_factors containing the way-wise value that \n",
    "#   an output way should have when it is unselected\n",
    "# - temperature is a software parameter; high temperature smooths the softmax, \n",
    "#   low temperature approximates a discrete decision\n",
    "#\n",
    "# Trainable parameters:\n",
    "# - W: way-wise weights input to softmax\n",
    "#\n",
    "# Output: tensor of num_factors outputs. The way i which is weighted highest in W \n",
    "#         should be railed to factors[i], the other ways should be weighted to baselines[i]\n",
    "\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class FactorMux(nn.Module):\n",
    "    def __init__(self, num_factors):\n",
    "        super(FactorMux, self).__init__()\n",
    "        self.num_factors = num_factors\n",
    "        self.W = torch.nn.Parameter(torch.randn(self.num_factors))\n",
    "        self.W.requires_grad = True\n",
    "        self.softmax1 = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [factors, baselines, temperature]\n",
    "        \n",
    "        assert len(x) == 2*self.num_factors + 1\n",
    "        \n",
    "        factors = x[0:self.num_factors]\n",
    "        baselines = x[self.num_factors:(2*self.num_factors)]\n",
    "        temperature = x[2*self.num_factors].item()\n",
    "        \n",
    "        #print(factors, baselines, 1.0/temperature)\n",
    "        \n",
    "        x = self.softmax1((1.0/temperature)*self.W) * (factors - baselines) + baselines\n",
    "        \n",
    "        return x\n",
    "\n",
    "class LoopNestSelector(FactorMux):\n",
    "    def __init__(self, num_datatypes):\n",
    "        super(LoopNestSelector, self).__init__(num_datatypes) # FactorMux num_factors\n",
    "        \n",
    "        use_cuda = torch.cuda.is_available()\n",
    "        self.use_cuda = use_cuda        \n",
    "        \n",
    "        if use_cuda and (not bypass_cuda):\n",
    "            self.baseline = torch.full((num_datatypes,),1.0).cuda()            \n",
    "        else:\n",
    "            self.baseline = torch.full((num_datatypes,),1.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [factors, temperature]\n",
    "\n",
    "        if not torch.is_tensor(x):\n",
    "            x = torch.tensor(x)\n",
    "        \n",
    "        reuse_factors = x[0:self.num_factors]\n",
    "        temperature = x[self.num_factors][None]\n",
    "        \n",
    "        inputs = torch.cat((reuse_factors, self.baseline, temperature), 0)\n",
    "        x = super().forward(inputs)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class RankLoopBoundSelector(nn.Module):\n",
    "    def __init__(self, num_rank_loops, rank_factor_list):\n",
    "        super(RankLoopBoundSelector, self).__init__() # FactorMux\n",
    "        \n",
    "        use_cuda = torch.cuda.is_available()\n",
    "        self.use_cuda = use_cuda\n",
    "    \n",
    "        if not torch.is_tensor(rank_factor_list):\n",
    "            rank_factor_list = torch.tensor(rank_factor_list)            \n",
    "            \n",
    "        if not torch.is_tensor(num_rank_loops):\n",
    "            num_rank_loops = torch.tensor(num_rank_loops)\n",
    "            \n",
    "        if use_cuda  and (not bypass_cuda):\n",
    "            #print(\"USING CUDA\")\n",
    "            rank_factor_list = rank_factor_list.cuda()\n",
    "            num_rank_loops = num_rank_loops.cuda()\n",
    "        \n",
    "        self.num_rank_loops = num_rank_loops\n",
    "        self.rank_factor_list = rank_factor_list\n",
    "        self.num_rank_factors = len(self.rank_factor_list)\n",
    "        self.factorMuxes = nn.ModuleList([FactorMux(self.num_rank_loops) for factor in self.rank_factor_list])\n",
    "        \n",
    "        self.baseline = 1.0\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [temperature]\n",
    "\n",
    "        if not torch.is_tensor(x):\n",
    "            x = torch.tensor([x])\n",
    "        \n",
    "        torch.full((self.num_rank_loops,), self.rank_factor_list[self.num_rank_factors-1])\n",
    "\n",
    "\n",
    "        #rint(torch.full((self.num_rank_loops,), self.rank_factor_list[self.num_rank_factors-1]).cuda().device)\n",
    "        #rint(torch.full((self.num_rank_loops,), self.baseline).device)\n",
    "        #rint(x.device)       \n",
    "        \n",
    "        if self.use_cuda  and (not bypass_cuda):\n",
    "            x = torch.stack( \\\n",
    "                [self.factorMuxes[mdx](\n",
    "                torch.cat( \\\n",
    "                (torch.full((self.num_rank_loops,), self.rank_factor_list[mdx]).cuda(), torch.full((self.num_rank_loops,), self.baseline).cuda(), \\\n",
    "                x),0) \\\n",
    "                ) \\\n",
    "                for mdx in range(self.num_rank_factors)])\n",
    "        else:\n",
    "            x = torch.stack( \\\n",
    "                [self.factorMuxes[mdx](\n",
    "                torch.cat( \\\n",
    "                (torch.full((self.num_rank_loops,), self.rank_factor_list[mdx]), torch.full((self.num_rank_loops,), self.baseline), \\\n",
    "                x),0) \\\n",
    "                ) \\\n",
    "                for mdx in range(self.num_rank_factors)])            \n",
    "        \n",
    "        x = torch.prod(x,0)\n",
    "        \n",
    "        #print(x)\n",
    "        \n",
    "        #x = torch.tensor([  for vec in x])\n",
    "        \n",
    "        return x\n",
    "\n",
    "class MapSelector_spGEMM(nn.Module):\n",
    "    \n",
    "    def repeat_prime(self, n, d):\n",
    "        lst = [d]\n",
    "        fac = d\n",
    "\n",
    "        while n % (fac * d) == 0:\n",
    "            fac = fac * d\n",
    "            lst.append(d)\n",
    "\n",
    "        return lst\n",
    "\n",
    "    # https://stackoverflow.com/questions/16996217/prime-factorization-list\n",
    "    def primes(self, n):\n",
    "        divisors = [ self.repeat_prime(n, d) for d in range(2,n//2+1) if n % d == 0 ]\n",
    "        divisors = sum(divisors, [])\n",
    "        return [ d for d in divisors if \\\n",
    "                 all( d % od != 0 for od in divisors if od != d ) ]    \n",
    "    \n",
    "    def __init__(self, M, K, N):\n",
    "        super(MapSelector_spGEMM, self).__init__() # FactorMux\n",
    "        \n",
    "        self.M = M\n",
    "        self.K = K\n",
    "        self.N = N\n",
    "        self.M_factors = self.primes(self.M)\n",
    "        self.K_factors = self.primes(self.K)\n",
    "        self.N_factors = self.primes(self.N)\n",
    "        self.main_mem_loops = 2\n",
    "        self.local_mem_loops = 1\n",
    "        self.total_loops = self.main_mem_loops + self.local_mem_loops\n",
    "        \n",
    "        # Loop bounds\n",
    "        self.M_bound_selector = RankLoopBoundSelector(self.total_loops, self.M_factors)\n",
    "        self.K_bound_selector = RankLoopBoundSelector(self.total_loops, self.K_factors)\n",
    "        self.N_bound_selector = RankLoopBoundSelector(self.total_loops, self.N_factors)        \n",
    "        \n",
    "        # Loop nest ordering\n",
    "        self.num_datatypes = 3\n",
    "        self.main_mem_temporal_LoopNestSelector = LoopNestSelector(self.num_datatypes)        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [temperature]\n",
    "\n",
    "        if not torch.is_tensor(x):\n",
    "            x = torch.tensor([x])\n",
    "        \n",
    "        # Calculate loop bounds\n",
    "        M_loop_bounds = self.M_bound_selector(x)\n",
    "        K_loop_bounds = self.K_bound_selector(x)\n",
    "        N_loop_bounds = self.N_bound_selector(x)        \n",
    "        M_main_mem_temporal = M_loop_bounds[1][None] # B reuse ceiling\n",
    "        K_main_mem_temporal = K_loop_bounds[1][None] # Z reuse ceiling\n",
    "        N_main_mem_temporal = N_loop_bounds[1][None] # A reuse ceiling\n",
    "        \n",
    "        #print(torch.flatten(torch.cat((N_main_mem_temporal, M_main_mem_temporal, K_main_mem_temporal, x),0)))\n",
    "        \n",
    "        # Calculate loop nest ordering\n",
    "        main_mem_loop_nest = self.main_mem_temporal_LoopNestSelector( \\\n",
    "            torch.flatten(torch.cat((N_main_mem_temporal, M_main_mem_temporal, K_main_mem_temporal, x),0)))\n",
    "        \n",
    "        #print(M_loop_bounds,K_loop_bounds,N_loop_bounds, main_mem_loop_nest)        \n",
    "        \n",
    "        x = torch.cat((M_loop_bounds,K_loop_bounds,N_loop_bounds, main_mem_loop_nest),0)\n",
    "        \n",
    "        # torch.tensor([L1 spatial bound & L1 temporal bound & L0 temporal bound For ranks M, K, N; reuse factor for A, B, Z])\n",
    "        return x\n",
    "\n",
    "class ArchMap_spGEMM(nn.Module): \n",
    "    \n",
    "    def __init__(self, M, K, N):\n",
    "        super(ArchMap_spGEMM, self).__init__() # FactorMux\n",
    "        \n",
    "        self.M = M\n",
    "        self.K = K\n",
    "        self.N = N\n",
    "        self.mapper = MapSelector_spGEMM(M, K, N)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [temperature]\n",
    "\n",
    "        if not torch.is_tensor(x):\n",
    "            x = torch.tensor([x])\n",
    "        \n",
    "        # Problem characteristics\n",
    "        M = float(self.M)\n",
    "        K = float(self.K)\n",
    "        N = float(self.N)\n",
    "        A_matrix_size = M*K\n",
    "        B_matrix_size = K*N\n",
    "        Z_matrix_size = M*N\n",
    "        main_memory_size = A_matrix_size+B_matrix_size+Z_matrix_size\n",
    "        total_num_macs = M*K*N\n",
    "        \n",
    "        T = x\n",
    "        \n",
    "        # Calculate map (loop bounds & loop nest)\n",
    "        # torch.tensor([L1 spatial bound & L1 temporal bound & L0 temporal bound For ranks M, K, N; reuse factor for A, B, Z])\n",
    "        x = self.mapper(x)\n",
    "        \n",
    "        self.x = x\n",
    "        \n",
    "        # Break out map parameters\n",
    "        M_L1_spatial_bound = x[0]\n",
    "        M_L1_temporal_bound = x[1]\n",
    "        M_L0_temporal_bound = x[2]\n",
    "        K_L1_spatial_bound = x[3]\n",
    "        K_L1_temporal_bound = x[4]\n",
    "        K_L0_temporal_bound = x[5]\n",
    "        N_L1_spatial_bound = x[6]\n",
    "        N_L1_temporal_bound = x[7]\n",
    "        N_L0_temporal_bound = x[8]        \n",
    "        A_reuse = x[9]\n",
    "        B_reuse = x[10]\n",
    "        Z_reuse = x[11]\n",
    "\n",
    "        # Hook\n",
    "        self.M_L1_spatial_bound = M_L1_spatial_bound\n",
    "        self.M_L1_temporal_bound = M_L1_temporal_bound\n",
    "        self.M_L0_temporal_bound = M_L0_temporal_bound\n",
    "        self.K_L1_spatial_bound = K_L1_spatial_bound\n",
    "        self.K_L1_temporal_bound = K_L1_temporal_bound\n",
    "        self.K_L0_temporal_bound = K_L0_temporal_bound\n",
    "        self.N_L1_spatial_bound = N_L1_spatial_bound\n",
    "        self.N_L1_temporal_bound = N_L1_temporal_bound\n",
    "        self.N_L0_temporal_bound = N_L0_temporal_bound       \n",
    "        self.A_reuse = A_reuse\n",
    "        self.B_reuse = B_reuse\n",
    "        self.Z_reuse = Z_reuse \n",
    "        \n",
    "        # Spatial characteristics\n",
    "        spatial_fan_out = M_L1_spatial_bound*K_L1_spatial_bound*N_L1_spatial_bound\n",
    "        \n",
    "        # Tiling\n",
    "        main_memory_tile_pair_count = M*K*N/M_L0_temporal_bound/K_L0_temporal_bound/N_L0_temporal_bound\n",
    "        A_tile_size = M_L0_temporal_bound*K_L0_temporal_bound\n",
    "        B_tile_size = K_L0_temporal_bound*N_L0_temporal_bound\n",
    "        Z_tile_size = M_L0_temporal_bound*N_L0_temporal_bound \n",
    "        local_memory_num_macs_per_tile = M_L0_temporal_bound*K_L0_temporal_bound*N_L0_temporal_bound\n",
    "        \n",
    "        # Per-PE characteristics\n",
    "        local_memory_size = A_tile_size + B_tile_size + Z_tile_size\n",
    "        local_num_macs = M*K*N/spatial_fan_out\n",
    "        \n",
    "        # Global characteristics\n",
    "        total_local_memory_size = local_memory_size*spatial_fan_out\n",
    "        \n",
    "        # Access counts\n",
    "        main_memory_reads = main_memory_tile_pair_count*(A_tile_size/A_reuse + B_tile_size/B_reuse + Z_tile_size/Z_reuse)\n",
    "        main_memory_writes = main_memory_tile_pair_count*(Z_tile_size/Z_reuse)\n",
    "        local_memory_reads = local_num_macs*3 # A, B, Z\n",
    "        local_memory_writes = local_num_macs # Just Z\n",
    "        total_local_memory_reads = local_memory_reads * spatial_fan_out\n",
    "        total_local_memory_writes = local_memory_writes * spatial_fan_out\n",
    "        \n",
    "        # Energy constants (currently arbitrary)\n",
    "        E_DRAM_static = 0.05\n",
    "        E_SRAM_static = 0.02\n",
    "        E_DRAM_acc = 1.0\n",
    "        E_SRAM_acc = 0.7\n",
    "        E_MAC = 0.1\n",
    "        \n",
    "        # Scale energy consumption of memories to memory size\n",
    "        main_memory_unit_read_energy = E_DRAM_acc*main_memory_size\n",
    "        main_memory_unit_write_energy = main_memory_unit_read_energy\n",
    "        local_memory_static_energy = E_SRAM_static*local_memory_size\n",
    "        local_memory_unit_read_energy = E_SRAM_acc*local_memory_size\n",
    "        local_memory_unit_write_energy = local_memory_unit_read_energy\n",
    "        \n",
    "        # Calculate energy consumption\n",
    "        total_main_memory_access_energy = main_memory_reads*main_memory_unit_read_energy + \\\n",
    "                                          main_memory_writes*main_memory_unit_write_energy\n",
    "        total_local_memory_static_energy = local_memory_static_energy*spatial_fan_out\n",
    "        total_local_memory_access_energy = total_local_memory_reads*local_memory_unit_read_energy + \\\n",
    "                                           total_local_memory_writes*local_memory_unit_write_energy\n",
    "        total_MAC_energy = total_num_macs*E_MAC\n",
    "        total_problem_energy = total_MAC_energy + total_local_memory_access_energy + \\\n",
    "                               total_local_memory_static_energy + total_main_memory_access_energy\n",
    "        \n",
    "        # Calculate latency in cycles\n",
    "        total_problem_latency = local_num_macs\n",
    "        \n",
    "        problem_edp = total_problem_energy*total_problem_latency\n",
    "        \n",
    "        self.problem_edp = problem_edp\n",
    "        \n",
    "        limit_spatial_fan_out = 512.0\n",
    "        \n",
    "        self.constraint_violation = False\n",
    "        \n",
    "        # Calculate EDP\n",
    "        if spatial_fan_out.item() > limit_spatial_fan_out:\n",
    "\n",
    "            self.constraint_violation = True\n",
    "            \n",
    "            problem_edp = problem_edp + 1.0e10*((spatial_fan_out - limit_spatial_fan_out)/T.item())   \n",
    "            #print(1.0e20*((spatial_fan_out - 512.0)))\n",
    "#            problem_edp = total_problem_energy*total_problem_latency + torch.exp((spatial_fan_out - 512.0))\n",
    "#            print(\"Being used: \", torch.exp((spatial_fan_out - 512.0)), \\\n",
    "#                   \"delta: \", spatial_fan_out - 512.0, \\\n",
    "#                   \"spatial fan-out: \", spatial_fan_out)\n",
    "\n",
    "            #            problem_edp = total_problem_energy*total_problem_latency + torch.exp(-(spatial_fan_out.item() - 512.0)/T.item())\n",
    "            \n",
    "            #1.0e10/(1+math.exp(-(spatial_fan_out.item() - 512.0)/T.item()))\n",
    "\n",
    "        limit_local_memory_size = 10.0\n",
    "        \n",
    "        if local_memory_size.item() > limit_local_memory_size:\n",
    "            \n",
    "            self.constraint_violation = True\n",
    "            \n",
    "            problem_edp = problem_edp + 1.0e10*((local_memory_size - limit_local_memory_size)/T.item())   \n",
    "        \n",
    "        return problem_edp\n",
    "    \n",
    "    def calcMap(self,x):\n",
    "        return self.x\n",
    "    \n",
    "    def archMapStats(self):\n",
    "        # Problem characteristics\n",
    "        M = float(self.M)\n",
    "        K = float(self.K)\n",
    "        N = float(self.N)\n",
    "        A_matrix_size = M*K\n",
    "        B_matrix_size = K*N\n",
    "        Z_matrix_size = M*N\n",
    "        main_memory_size = A_matrix_size+B_matrix_size+Z_matrix_size\n",
    "        total_num_macs = M*K*N        \n",
    "        \n",
    "        x = self.calcMap(1.0)\n",
    "        \n",
    "        M_L1_spatial_bound = x[0]\n",
    "        M_L1_temporal_bound = x[1]\n",
    "        M_L0_temporal_bound = x[2]\n",
    "        K_L1_spatial_bound = x[3]\n",
    "        K_L1_temporal_bound = x[4]\n",
    "        K_L0_temporal_bound = x[5]\n",
    "        N_L1_spatial_bound = x[6]\n",
    "        N_L1_temporal_bound = x[7]\n",
    "        N_L0_temporal_bound = x[8]        \n",
    "        A_reuse = x[9]\n",
    "        B_reuse = x[10]\n",
    "        Z_reuse = x[11]  \n",
    "        \n",
    "        # Spatial characteristics\n",
    "        spatial_fan_out = M_L1_spatial_bound*K_L1_spatial_bound*N_L1_spatial_bound\n",
    "        \n",
    "        # Tiling\n",
    "        main_memory_tile_pair_count = M*K*N/M_L0_temporal_bound/K_L0_temporal_bound/N_L0_temporal_bound\n",
    "        A_tile_size = M_L0_temporal_bound*K_L0_temporal_bound\n",
    "        B_tile_size = K_L0_temporal_bound*N_L0_temporal_bound\n",
    "        Z_tile_size = M_L0_temporal_bound*N_L0_temporal_bound \n",
    "        local_memory_num_macs_per_tile = M_L0_temporal_bound*K_L0_temporal_bound*N_L0_temporal_bound\n",
    "        \n",
    "        # Per-PE characteristics\n",
    "        local_memory_size = A_tile_size + B_tile_size + Z_tile_size\n",
    "        local_num_macs = M*K*N/spatial_fan_out\n",
    "        \n",
    "        print(\"Spatial fan-out: \", spatial_fan_out.item())\n",
    "        print(\"Local memory size: \", local_memory_size.item())\n",
    "        print(\"A tile size: \", A_tile_size.item(), \"B tile size: \", B_tile_size.item(), \"Z tile size: \", Z_tile_size.item())\n",
    "        \n",
    "        # Global characteristics\n",
    "        total_local_memory_size = local_memory_size*spatial_fan_out\n",
    "        \n",
    "        # Access counts\n",
    "        main_memory_reads = main_memory_tile_pair_count*(A_tile_size/A_reuse + B_tile_size/B_reuse + Z_tile_size/Z_reuse)\n",
    "        main_memory_writes = main_memory_tile_pair_count*(Z_tile_size/Z_reuse)\n",
    "        local_memory_reads = local_num_macs*3 # A, B, Z\n",
    "        local_memory_writes = local_num_macs # Just Z\n",
    "        total_local_memory_reads = local_memory_reads * spatial_fan_out\n",
    "        total_local_memory_writes = local_memory_writes * spatial_fan_out\n",
    "        \n",
    "        # Energy constants (currently arbitrary)\n",
    "        E_DRAM_static = 0.05\n",
    "        E_SRAM_static = 0.02\n",
    "        E_DRAM_acc = 1.0\n",
    "        E_SRAM_acc = 0.7\n",
    "        E_MAC = 0.1\n",
    "        \n",
    "        # Scale energy consumption of memories to memory size\n",
    "        main_memory_unit_read_energy = E_DRAM_acc*main_memory_size\n",
    "        main_memory_unit_write_energy = main_memory_unit_read_energy\n",
    "        local_memory_static_energy = E_SRAM_static*local_memory_size\n",
    "        local_memory_unit_read_energy = E_SRAM_acc*local_memory_size\n",
    "        local_memory_unit_write_energy = local_memory_unit_read_energy\n",
    "        \n",
    "        # Calculate energy consumption\n",
    "        total_main_memory_access_energy = main_memory_reads*main_memory_unit_read_energy + \\\n",
    "                                          main_memory_writes*main_memory_unit_write_energy\n",
    "        total_local_memory_static_energy = local_memory_static_energy*spatial_fan_out\n",
    "        total_local_memory_access_energy = total_local_memory_reads*local_memory_unit_read_energy + \\\n",
    "                                           total_local_memory_writes*local_memory_unit_write_energy\n",
    "        total_MAC_energy = total_num_macs*E_MAC\n",
    "        total_problem_energy = total_MAC_energy + total_local_memory_access_energy + \\\n",
    "                               total_local_memory_static_energy + total_main_memory_access_energy\n",
    "        \n",
    "        # Calculate latency in cycles\n",
    "        total_problem_latency = local_num_macs\n",
    "        \n",
    "        # Calculate EDP\n",
    "        problem_edp = total_problem_energy*total_problem_latency\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def oneOpt(res_lst, stp_lst):\n",
    "    \n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    \n",
    "    M = 2*3*2\n",
    "    K = 5*3\n",
    "    N = 5*7\n",
    "    \n",
    "    #M = M.cuda()\n",
    "    #K = K.cuda()\n",
    "    #N = N.cuda()\n",
    "    \n",
    "    net = ArchMap_spGEMM(2*3*2, 5*3, 5*7)\n",
    "    \n",
    "    if use_cuda and (not bypass_cuda):\n",
    "        net.cuda()\n",
    "    \n",
    "    optimizer = optim.Adam(net.parameters() , lr=0.0001)\n",
    "\n",
    "    T = torch.tensor([1.0])\n",
    "    \n",
    "    if use_cuda and (not bypass_cuda):\n",
    "        T = T.cuda()\n",
    "\n",
    "    edp_list = []\n",
    "    edp_pen_list = []\n",
    "    cooling_points = []\n",
    "    temperature_list = []\n",
    "\n",
    "    thresh_pct = 0.5\n",
    "\n",
    "    edp = 0.0\n",
    "\n",
    "    pct = 100.0\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    net(T)\n",
    "\n",
    "    target_temp = 0.99\n",
    "    \n",
    "    while(T.item() > target_temp):\n",
    "        cooling_points.append(i)\n",
    "        temperature_list.append(T.item())\n",
    "\n",
    "        print(\"Temperature: \", T.item())\n",
    "        print(\"Map: \", net.calcMap(T))\n",
    "        print(\"Arch details:\")\n",
    "        net.archMapStats()\n",
    "        print(\"-----------------------\")\n",
    "        pct = 100.0\n",
    "\n",
    "        j = i\n",
    "        while((net.constraint_violation or (pct > 1.0  and (i-j)<100000)) and T.item() > target_temp):\n",
    "            assert stp_lst[0] == False\n",
    "            \n",
    "            optimizer.zero_grad() # clear gradients\n",
    "            edp_pen = net(T) # forward step\n",
    "            edp = net.problem_edp\n",
    "            edp_pen_list.append(edp_pen.item())\n",
    "            edp_list.append(edp.item())\n",
    "            loss = edp_pen\n",
    "            loss.backward() # backprop\n",
    "            optimizer.step() # optimize weights\n",
    "            if i % 1000 == 0:\n",
    "                pct = 100.0\n",
    "                if i > 0:\n",
    "                    pct = 100.0*abs(edp_list[-1]-edp_list[-500])/edp_list[-500] #100.0*abs(edp_list[-1]-edp_list[-2])/edp_list[-2]\n",
    "                print(\"EDP: \", edp_list[-1], \"EDP (penalized): \",  edp_pen_list[-1], \" % decrease: \", pct)    \n",
    "\n",
    "            i = i + 1\n",
    "        print(\"Percentage threshold reached\")\n",
    "        T = T/2.0\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.plot(edp_list)\n",
    "    plt.xlabel(\"Gradient descent iterations\")\n",
    "    plt.ylabel(\"EDP\")\n",
    "    plt.title(\"Gradient-descent optimization of mapping + architecture\")\n",
    "    plt.grid(\"on\")\n",
    "\n",
    "    for jdx in range(len(cooling_points)):\n",
    "        plt.plot(np.array([cooling_points[jdx],cooling_points[jdx]]), np.array([-10.0,edp_list[0]]))\n",
    "    # len(edp_list)<2 or 100.0*math.abs(edp_list[-1]-edp_list[-2])/edp_list[-2] > thresh_pct\n",
    "\n",
    "    print(\"EDP: \", net(T), \" Map: \", net.calcMap(T))\n",
    "    \n",
    "    res_lst.append(net)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature:  1.0\n",
      "Map:  tensor([ 3.4299,  2.6456,  2.3661,  6.1589,  1.9130,  3.1442,  4.5090,  6.0182,\n",
      "        10.6774,  2.1967,  1.3760,  1.4867], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  95.24890899658203\n",
      "Local memory size:  66.27417755126953\n",
      "A tile size:  7.43930721282959 B tile size:  33.57149124145508 Z tile size:  25.263376235961914\n",
      "-----------------------\n",
      "EDP:  441932128.0 EDP (penalized):  563183681536.0  % decrease:  100.0\n",
      "EDP:  378750752.0 EDP (penalized):  421457854464.0  % decrease:  6.922405461367088\n",
      "EDP:  336255744.0 EDP (penalized):  317641555968.0  % decrease:  5.419039518273995\n",
      "EDP:  306189888.0 EDP (penalized):  239009447936.0  % decrease:  4.3062341640651605\n",
      "EDP:  284245152.0 EDP (penalized):  178097504256.0  % decrease:  3.437182636684052\n",
      "EDP:  267969936.0 EDP (penalized):  130233442304.0  % decrease:  2.7309646662966736\n",
      "EDP:  255826976.0 EDP (penalized):  92285968384.0  % decrease:  2.1486113299806764\n",
      "EDP:  246744160.0 EDP (penalized):  62025576448.0  % decrease:  1.675704028982297\n",
      "EDP:  239904880.0 EDP (penalized):  37791100928.0  % decrease:  1.3063076583233482\n",
      "EDP:  234716448.0 EDP (penalized):  18310889472.0  % decrease:  1.0163821378760776\n",
      "EDP:  230801792.0 EDP (penalized):  2598107648.0  % decrease:  0.779376247255462\n",
      "Percentage threshold reached\n",
      "EDP:  tensor(3.3217e+08, grad_fn=<MulBackward0>)  Map:  tensor([ 5.2076,  2.6955,  1.0902,  8.0154,  2.3411,  1.0733,  6.6238, 12.5846,\n",
      "         1.4821,  1.5459,  1.3595,  1.9935], grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stp_lst = [False]\n",
    "res_lst0 = []\n",
    "\n",
    "oneOpt(res_lst0, stp_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#import threading\n",
    "\n",
    "#stp_lst = [False]\n",
    "\n",
    "#res_lst0 = []\n",
    "#res_lst1 = []\n",
    "#res_lst2 = []\n",
    "#res_lst3 = []\n",
    "\n",
    "#th0 = threading.Thread(target=oneOpt, args=(res_lst0,stp_lst))\n",
    "#th1 = threading.Thread(target=oneOpt, args=(res_lst1,stp_lst))\n",
    "#th2 = threading.Thread(target=oneOpt, args=(res_lst2,stp_lst))\n",
    "#th3 = threading.Thread(target=oneOpt, args=(res_lst3,stp_lst))\n",
    "\n",
    "#th0.start()\n",
    "#th1.start()\n",
    "#th2.start()\n",
    "#th3.start()\n",
    "\n",
    "#th0.join()\n",
    "#th1.join()\n",
    "#th2.join()\n",
    "#th3.join()\n",
    "\n",
    "#T = torch.tensor([1.0e-05])\n",
    "\n",
    "#print(res_lst0[0](T), res_lst1[0](T), res_lst2[0](T), res_lst3[0](T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stp_lst[0] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
