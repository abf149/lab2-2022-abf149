{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your name:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starter Code\n",
    "\n",
    "This notebook implements starter code to help you get started with the assignment. If you have a personal GPU, copy this starter code to another directory and run this notebook using your personal GPU. In that case, the docker we provide will not support PyTorch with GPU, and you can create your own virtual environment (e.g., conda) with PyTorch support (https://pytorch.org/get-started/locally/). \n",
    "\n",
    "To run this notebook you must __first create a folder called `./dataset` and download all the data files from the Kaggle competition page__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "%matplotlib inline\n",
    "\n",
    "log_interval = 1000,\n",
    "epochs = 1\n",
    "\n",
    "params = {\n",
    "    'log_interval': 1000,\n",
    "    'epochs': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "# GPU setup\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"Using {}\".format('GPU' if use_cuda else 'CPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abstract a \"one-of-N\" or N-way one-hot decision (usually for assigning a factor of a rank to a memory level)\n",
    "#\n",
    "# Initialization:\n",
    "# - num_factors: number of decision ways (factors) to choose between\n",
    "#\n",
    "# Input: \n",
    "# - x: [factors, baselines, temperature]\n",
    "# - factors is a list length num_factors containing the factors to select among\n",
    "# - baselines is a list of length num_factors containing the way-wise value that \n",
    "#   an output way should have when it is unselected\n",
    "# - temperature is a software parameter; high temperature smooths the softmax, \n",
    "#   low temperature approximates a discrete decision\n",
    "#\n",
    "# Trainable parameters:\n",
    "# - W: way-wise weights input to softmax\n",
    "#\n",
    "# Output: tensor of num_factors outputs. The way i which is weighted highest in W \n",
    "#         should be railed to factors[i], the other ways should be weighted to baselines[i]\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class FactorMux(nn.Module):\n",
    "    def __init__(self, num_factors):\n",
    "        super(FactorMux, self).__init__()\n",
    "        self.num_factors = num_factors\n",
    "        self.W = torch.nn.Parameter(torch.randn(self.num_factors))\n",
    "        self.W.requires_grad = True\n",
    "        self.softmax1 = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [factors, baselines, temperature]\n",
    "        \n",
    "        assert len(x) == 2*self.num_factors + 1\n",
    "        \n",
    "        factors = x[0:self.num_factors]\n",
    "        baselines = x[self.num_factors:(2*self.num_factors)]\n",
    "        temperature = x[2*self.num_factors].item()\n",
    "        \n",
    "        #print(factors, baselines, 1.0/temperature)\n",
    "        \n",
    "        x = self.softmax1((1.0/temperature)*self.W) * (factors - baselines) + baselines\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "fmux = FactorMux(2)\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2., 1.], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test FactorMux\n",
    "fmux.W.data = torch.tensor([1, 0])\n",
    "fmux(torch.tensor([2.0, 2.0, 1.0, 1.0, 0.01]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LoopNestSelector(FactorMux):\n",
    "    def __init__(self, num_datatypes):\n",
    "        super(LoopNestSelector, self).__init__(num_datatypes) # FactorMux num_factors\n",
    "        self.baseline = 1.0\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [factors, temperature]\n",
    "\n",
    "        if not torch.is_tensor(x):\n",
    "            x = torch.tensor(x)\n",
    "        \n",
    "        reuse_factors = x[0:self.num_factors]\n",
    "        temperature = torch.tensor([x[self.num_factors].item()])\n",
    "        \n",
    "        #print(reuse_factors, reuse_factors*0.0 + self.baseline, temperature)\n",
    "        \n",
    "        inputs = torch.cat((reuse_factors, reuse_factors*0.0 + self.baseline, temperature), 0)\n",
    "        x = super().forward(inputs)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1., 4., 1.], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmux = LoopNestSelector(3)\n",
    "rmux.W.data = torch.tensor([0.0,0.1,0.0])\n",
    "rmux([3, 4, 5, 0.001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RankLoopBoundSelector(nn.Module):\n",
    "    def __init__(self, num_rank_loops, rank_factor_list):\n",
    "        super(RankLoopBoundSelector, self).__init__() # FactorMux\n",
    "            \n",
    "        if not torch.is_tensor(rank_factor_list):\n",
    "            rank_factor_list = torch.tensor(rank_factor_list)            \n",
    "        \n",
    "        self.num_rank_loops = num_rank_loops\n",
    "        self.rank_factor_list = rank_factor_list\n",
    "        self.num_rank_factors = len(self.rank_factor_list)\n",
    "        self.factorMuxes = nn.ModuleList([FactorMux(self.num_rank_loops) for factor in self.rank_factor_list])\n",
    "        \n",
    "        self.baseline = 1.0\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [temperature]\n",
    "\n",
    "        if not torch.is_tensor(x):\n",
    "            x = torch.tensor([x])\n",
    "        \n",
    "        x = torch.stack( \\\n",
    "            [self.factorMuxes[mdx](\n",
    "            torch.cat( \\\n",
    "            (torch.full((self.num_rank_loops,), self.rank_factor_list[mdx]), torch.full((self.num_rank_loops,), self.baseline), \\\n",
    "            x),0) \\\n",
    "            ) \\\n",
    "            for mdx in range(self.num_rank_factors)])\n",
    "        \n",
    "        x = torch.prod(x,0)\n",
    "        \n",
    "        #print(x)\n",
    "        \n",
    "        #x = torch.tensor([  for vec in x])\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlbs = RankLoopBoundSelector(3, [3, 2, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 3., 5.], grad_fn=<ProdBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "print(rlbs(0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([ 0.0168,  0.2230, -0.1170], requires_grad=True), Parameter containing:\n",
       " tensor([ 1.5208, -0.1559, -1.6177], requires_grad=True), Parameter containing:\n",
       " tensor([-0.5039, -0.8544,  0.7811], requires_grad=True)]"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(rlbs.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 61]"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "\n",
    "primes(244)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.426264754702098"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.log(86,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MapSelector_spGEMM(nn.Module):\n",
    "    \n",
    "    def repeat_prime(self, n, d):\n",
    "        lst = [d]\n",
    "        fac = d\n",
    "\n",
    "        while n % (fac * d) == 0:\n",
    "            fac = fac * d\n",
    "            lst.append(d)\n",
    "\n",
    "        return lst\n",
    "\n",
    "    # https://stackoverflow.com/questions/16996217/prime-factorization-list\n",
    "    def primes(self, n):\n",
    "        divisors = [ self.repeat_prime(n, d) for d in range(2,n//2+1) if n % d == 0 ]\n",
    "        divisors = sum(divisors, [])\n",
    "        return [ d for d in divisors if \\\n",
    "                 all( d % od != 0 for od in divisors if od != d ) ]    \n",
    "    \n",
    "    def __init__(self, M, K, N):\n",
    "        super(MapSelector_spGEMM, self).__init__() # FactorMux\n",
    "        \n",
    "        self.M = M\n",
    "        self.K = K\n",
    "        self.N = N\n",
    "        self.M_factors = self.primes(self.M)\n",
    "        self.K_factors = self.primes(self.K)\n",
    "        self.N_factors = self.primes(self.N)\n",
    "        self.main_mem_loops = 2\n",
    "        self.local_mem_loops = 1\n",
    "        self.total_loops = self.main_mem_loops + self.local_mem_loops\n",
    "        \n",
    "        # Loop bounds\n",
    "        self.M_bound_selector = RankLoopBoundSelector(self.total_loops, self.M_factors)\n",
    "        self.K_bound_selector = RankLoopBoundSelector(self.total_loops, self.K_factors)\n",
    "        self.N_bound_selector = RankLoopBoundSelector(self.total_loops, self.N_factors)        \n",
    "        \n",
    "        # Loop nest ordering\n",
    "        self.num_datatypes = 3\n",
    "        self.main_mem_temporal_LoopNestSelector = LoopNestSelector(self.num_datatypes)        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [temperature]\n",
    "\n",
    "        if not torch.is_tensor(x):\n",
    "            x = torch.tensor([x])\n",
    "        \n",
    "        # Calculate loop bounds\n",
    "        M_loop_bounds = self.M_bound_selector(x)\n",
    "        K_loop_bounds = self.K_bound_selector(x)\n",
    "        N_loop_bounds = self.N_bound_selector(x)        \n",
    "        M_main_mem_temporal = M_loop_bounds[1][None] # B reuse ceiling\n",
    "        K_main_mem_temporal = K_loop_bounds[1][None] # Z reuse ceiling\n",
    "        N_main_mem_temporal = N_loop_bounds[1][None] # A reuse ceiling\n",
    "        \n",
    "        #print(torch.flatten(torch.cat((N_main_mem_temporal, M_main_mem_temporal, K_main_mem_temporal, x),0)))\n",
    "        \n",
    "        # Calculate loop nest ordering\n",
    "        main_mem_loop_nest = self.main_mem_temporal_LoopNestSelector( \\\n",
    "            torch.flatten(torch.cat((N_main_mem_temporal, M_main_mem_temporal, K_main_mem_temporal, x),0)))\n",
    "        \n",
    "        #print(M_loop_bounds,K_loop_bounds,N_loop_bounds, main_mem_loop_nest)        \n",
    "        \n",
    "        x = torch.cat((M_loop_bounds,K_loop_bounds,N_loop_bounds, main_mem_loop_nest),0)\n",
    "        \n",
    "        # torch.tensor([L1 spatial bound & L1 temporal bound & L0 temporal bound For ranks M, K, N; reuse factor for A, B, Z])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  2.,  3.,  5.,  5.,  1.,  1., 21.,  1.,  1.,  2.,  1.],\n",
       "       grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSs = MapSelector_spGEMM(2*3, 5*5, 3*7)\n",
    "MSs(0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ArchMap_spGEMM(nn.Module): \n",
    "    \n",
    "    def __init__(self, M, K, N):\n",
    "        super(ArchMap_spGEMM, self).__init__() # FactorMux\n",
    "        \n",
    "        self.M = M\n",
    "        self.K = K\n",
    "        self.N = N\n",
    "        self.mapper = MapSelector_spGEMM(M, K, N)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [temperature]\n",
    "\n",
    "        if not torch.is_tensor(x):\n",
    "            x = torch.tensor([x])\n",
    "        \n",
    "        # Problem characteristics\n",
    "        M = float(self.M)\n",
    "        K = float(self.K)\n",
    "        N = float(self.N)\n",
    "        A_matrix_size = M*K\n",
    "        B_matrix_size = K*N\n",
    "        Z_matrix_size = M*N\n",
    "        main_memory_size = A_matrix_size+B_matrix_size+Z_matrix_size\n",
    "        total_num_macs = M*K*N\n",
    "        \n",
    "        # Calculate map (loop bounds & loop nest)\n",
    "        # torch.tensor([L1 spatial bound & L1 temporal bound & L0 temporal bound For ranks M, K, N; reuse factor for A, B, Z])\n",
    "        x = self.mapper(x)\n",
    "        \n",
    "        self.x = x\n",
    "        \n",
    "        # Break out map parameters\n",
    "        M_L1_spatial_bound = x[0]\n",
    "        M_L1_temporal_bound = x[1]\n",
    "        M_L0_temporal_bound = x[2]\n",
    "        K_L1_spatial_bound = x[3]\n",
    "        K_L1_temporal_bound = x[4]\n",
    "        K_L0_temporal_bound = x[5]\n",
    "        N_L1_spatial_bound = x[6]\n",
    "        N_L1_temporal_bound = x[7]\n",
    "        N_L0_temporal_bound = x[8]        \n",
    "        A_reuse = x[9]\n",
    "        B_reuse = x[10]\n",
    "        Z_reuse = x[11]\n",
    "\n",
    "        # Hook\n",
    "        self.M_L1_spatial_bound = M_L1_spatial_bound\n",
    "        self.M_L1_temporal_bound = M_L1_temporal_bound\n",
    "        self.M_L0_temporal_bound = M_L0_temporal_bound\n",
    "        self.K_L1_spatial_bound = K_L1_spatial_bound\n",
    "        self.K_L1_temporal_bound = K_L1_temporal_bound\n",
    "        self.K_L0_temporal_bound = K_L0_temporal_bound\n",
    "        self.N_L1_spatial_bound = N_L1_spatial_bound\n",
    "        self.N_L1_temporal_bound = N_L1_temporal_bound\n",
    "        self.N_L0_temporal_bound = N_L0_temporal_bound       \n",
    "        self.A_reuse = A_reuse\n",
    "        self.B_reuse = B_reuse\n",
    "        self.Z_reuse = Z_reuse \n",
    "        \n",
    "        # Spatial characteristics\n",
    "        spatial_fan_out = M_L1_spatial_bound*K_L1_spatial_bound*N_L1_spatial_bound\n",
    "        \n",
    "        # Tiling\n",
    "        main_memory_tile_pair_count = M*K*N/M_L0_temporal_bound/K_L0_temporal_bound/N_L0_temporal_bound\n",
    "        A_tile_size = M_L0_temporal_bound*K_L0_temporal_bound\n",
    "        B_tile_size = K_L0_temporal_bound*N_L0_temporal_bound\n",
    "        Z_tile_size = M_L0_temporal_bound*N_L0_temporal_bound \n",
    "        local_memory_num_macs_per_tile = M_L0_temporal_bound*K_L0_temporal_bound*N_L0_temporal_bound\n",
    "        \n",
    "        # Per-PE characteristics\n",
    "        local_memory_size = A_tile_size + B_tile_size + Z_tile_size\n",
    "        local_num_macs = M*K*N/spatial_fan_out\n",
    "        \n",
    "        # Global characteristics\n",
    "        total_local_memory_size = local_memory_size*spatial_fan_out\n",
    "        \n",
    "        # Access counts\n",
    "        main_memory_reads = main_memory_tile_pair_count*(A_tile_size/A_reuse + B_tile_size/B_reuse + Z_tile_size/Z_reuse)\n",
    "        main_memory_writes = main_memory_tile_pair_count*(Z_tile_size/Z_reuse)\n",
    "        local_memory_reads = local_num_macs*3 # A, B, Z\n",
    "        local_memory_writes = local_num_macs # Just Z\n",
    "        total_local_memory_reads = local_memory_reads * spatial_fan_out\n",
    "        total_local_memory_writes = local_memory_writes * spatial_fan_out\n",
    "        \n",
    "        # Energy constants (currently arbitrary)\n",
    "        E_DRAM_static = 0.05\n",
    "        E_SRAM_static = 0.02\n",
    "        E_DRAM_acc = 1.0\n",
    "        E_SRAM_acc = 0.7\n",
    "        E_MAC = 0.1\n",
    "        \n",
    "        # Scale energy consumption of memories to memory size\n",
    "        main_memory_unit_read_energy = E_DRAM_acc*main_memory_size\n",
    "        main_memory_unit_write_energy = main_memory_unit_read_energy\n",
    "        local_memory_static_energy = E_SRAM_static*local_memory_size\n",
    "        local_memory_unit_read_energy = E_SRAM_acc*local_memory_size\n",
    "        local_memory_unit_write_energy = local_memory_unit_read_energy\n",
    "        \n",
    "        # Calculate energy consumption\n",
    "        total_main_memory_access_energy = main_memory_reads*main_memory_unit_read_energy + \\\n",
    "                                          main_memory_writes*main_memory_unit_write_energy\n",
    "        total_local_memory_static_energy = local_memory_static_energy*spatial_fan_out\n",
    "        total_local_memory_access_energy = total_local_memory_reads*local_memory_unit_read_energy + \\\n",
    "                                           total_local_memory_writes*local_memory_unit_write_energy\n",
    "        total_MAC_energy = total_num_macs*E_MAC\n",
    "        total_problem_energy = total_MAC_energy + total_local_memory_access_energy + \\\n",
    "                               total_local_memory_static_energy + total_main_memory_access_energy\n",
    "        \n",
    "        # Calculate latency in cycles\n",
    "        total_problem_latency = local_num_macs\n",
    "        \n",
    "        # Calculate EDP\n",
    "        problem_edp = total_problem_energy*total_problem_latency\n",
    "        \n",
    "        return problem_edp\n",
    "    \n",
    "    def calcMap(self,x):\n",
    "        return self.x\n",
    "    \n",
    "    def archMapStats(self):\n",
    "        # Problem characteristics\n",
    "        M = float(self.M)\n",
    "        K = float(self.K)\n",
    "        N = float(self.N)\n",
    "        A_matrix_size = M*K\n",
    "        B_matrix_size = K*N\n",
    "        Z_matrix_size = M*N\n",
    "        main_memory_size = A_matrix_size+B_matrix_size+Z_matrix_size\n",
    "        total_num_macs = M*K*N        \n",
    "        \n",
    "        x = self.calcMap(1.0)\n",
    "        \n",
    "        M_L1_spatial_bound = x[0]\n",
    "        M_L1_temporal_bound = x[1]\n",
    "        M_L0_temporal_bound = x[2]\n",
    "        K_L1_spatial_bound = x[3]\n",
    "        K_L1_temporal_bound = x[4]\n",
    "        K_L0_temporal_bound = x[5]\n",
    "        N_L1_spatial_bound = x[6]\n",
    "        N_L1_temporal_bound = x[7]\n",
    "        N_L0_temporal_bound = x[8]        \n",
    "        A_reuse = x[9]\n",
    "        B_reuse = x[10]\n",
    "        Z_reuse = x[11]  \n",
    "        \n",
    "        # Spatial characteristics\n",
    "        spatial_fan_out = M_L1_spatial_bound*K_L1_spatial_bound*N_L1_spatial_bound\n",
    "        \n",
    "        # Tiling\n",
    "        main_memory_tile_pair_count = M*K*N/M_L0_temporal_bound/K_L0_temporal_bound/N_L0_temporal_bound\n",
    "        A_tile_size = M_L0_temporal_bound*K_L0_temporal_bound\n",
    "        B_tile_size = K_L0_temporal_bound*N_L0_temporal_bound\n",
    "        Z_tile_size = M_L0_temporal_bound*N_L0_temporal_bound \n",
    "        local_memory_num_macs_per_tile = M_L0_temporal_bound*K_L0_temporal_bound*N_L0_temporal_bound\n",
    "        \n",
    "        # Per-PE characteristics\n",
    "        local_memory_size = A_tile_size + B_tile_size + Z_tile_size\n",
    "        local_num_macs = M*K*N/spatial_fan_out\n",
    "        \n",
    "        print(\"Spatial fan-out: \", spatial_fan_out.item())\n",
    "        print(\"Local memory size: \", local_memory_size.item())\n",
    "        print(\"A tile size: \", A_tile_size.item(), \"B tile size: \", B_tile_size.item(), \"Z tile size: \", Z_tile_size.item())\n",
    "        \n",
    "        # Global characteristics\n",
    "        total_local_memory_size = local_memory_size*spatial_fan_out\n",
    "        \n",
    "        # Access counts\n",
    "        main_memory_reads = main_memory_tile_pair_count*(A_tile_size/A_reuse + B_tile_size/B_reuse + Z_tile_size/Z_reuse)\n",
    "        main_memory_writes = main_memory_tile_pair_count*(Z_tile_size/Z_reuse)\n",
    "        local_memory_reads = local_num_macs*3 # A, B, Z\n",
    "        local_memory_writes = local_num_macs # Just Z\n",
    "        total_local_memory_reads = local_memory_reads * spatial_fan_out\n",
    "        total_local_memory_writes = local_memory_writes * spatial_fan_out\n",
    "        \n",
    "        # Energy constants (currently arbitrary)\n",
    "        E_DRAM_static = 0.05\n",
    "        E_SRAM_static = 0.02\n",
    "        E_DRAM_acc = 1.0\n",
    "        E_SRAM_acc = 0.7\n",
    "        E_MAC = 0.1\n",
    "        \n",
    "        # Scale energy consumption of memories to memory size\n",
    "        main_memory_unit_read_energy = E_DRAM_acc*main_memory_size\n",
    "        main_memory_unit_write_energy = main_memory_unit_read_energy\n",
    "        local_memory_static_energy = E_SRAM_static*local_memory_size\n",
    "        local_memory_unit_read_energy = E_SRAM_acc*local_memory_size\n",
    "        local_memory_unit_write_energy = local_memory_unit_read_energy\n",
    "        \n",
    "        # Calculate energy consumption\n",
    "        total_main_memory_access_energy = main_memory_reads*main_memory_unit_read_energy + \\\n",
    "                                          main_memory_writes*main_memory_unit_write_energy\n",
    "        total_local_memory_static_energy = local_memory_static_energy*spatial_fan_out\n",
    "        total_local_memory_access_energy = total_local_memory_reads*local_memory_unit_read_energy + \\\n",
    "                                           total_local_memory_writes*local_memory_unit_write_energy\n",
    "        total_MAC_energy = total_num_macs*E_MAC\n",
    "        total_problem_energy = total_MAC_energy + total_local_memory_access_energy + \\\n",
    "                               total_local_memory_static_energy + total_main_memory_access_energy\n",
    "        \n",
    "        # Calculate latency in cycles\n",
    "        total_problem_latency = local_num_macs\n",
    "        \n",
    "        # Calculate EDP\n",
    "        problem_edp = total_problem_energy*total_problem_latency        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "net = ArchMap_spGEMM(2*3, 5*5, 3*7)\n",
    "T = torch.tensor([1.0])\n",
    "net(T)\n",
    "optimizer = optim.Adam(net.parameters() , lr=0.002) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = torch.tensor([1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad() # clear gradients\n",
    "edp = net(T) # forward step\n",
    "loss = edp\n",
    "loss.backward() # backprop\n",
    "optimizer.step() # optimize weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.4132e+08, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature:  1.0\n",
      "Map:  tensor([2.9236, 1.9345, 1.5721, 7.7177, 3.3924, 5.2541, 3.1835, 4.1396, 6.0647,\n",
      "        3.6347, 1.1075, 1.1095], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  71.8307113647461\n",
      "Local memory size:  49.658653259277344\n",
      "A tile size:  8.25989055633545 B tile size:  31.864486694335938 Z tile size:  9.534276008605957\n",
      "-----------------------\n",
      "EDP:  125059336.0  % decrease:  100.0\n",
      "EDP:  15756853.0  % decrease:  43.227679360625146\n",
      "EDP:  10750628.0  % decrease:  12.026013601604054\n",
      "EDP:  9535943.0  % decrease:  4.538872121738885\n",
      "EDP:  9019358.0  % decrease:  2.3312980027021037\n",
      "EDP:  8727493.0  % decrease:  1.4500883566786922\n",
      "EDP:  8536586.0  % decrease:  0.9921734185713923\n",
      "EDP:  8430831.0  % decrease:  0.501381797565388\n",
      "EDP:  8379710.5  % decrease:  0.2566446216814386\n",
      "EDP:  8351057.5  % decrease:  0.14801891753387175\n",
      "EDP:  8334161.0  % decrease:  0.08816134268981647\n",
      "EDP:  8324011.5  % decrease:  0.05319716396259257\n",
      "EDP:  8317862.0  % decrease:  0.032371632834895116\n",
      "EDP:  8314109.5  % decrease:  0.019739642354718666\n",
      "EDP:  8311813.5  % decrease:  0.012089755790541914\n",
      "EDP:  8310408.5  % decrease:  0.007423872370037564\n",
      "EDP:  8309550.5  % decrease:  0.004506658934547608\n",
      "EDP:  8309023.5  % decrease:  0.002780033462697156\n",
      "EDP:  8308698.0  % decrease:  0.0017330935967426987\n",
      "EDP:  8308501.0  % decrease:  0.0010531273247785695\n",
      "EDP:  8308376.0  % decrease:  0.0006499422484186393\n",
      "EDP:  8308301.0  % decrease:  0.00039719139943408653\n",
      "EDP:  8308259.0  % decrease:  0.00022868760875449867\n",
      "EDP:  8308231.5  % decrease:  0.0001323986231265369\n",
      "EDP:  8308211.5  % decrease:  6.619949880961265e-05\n",
      "EDP:  8308206.0  % decrease:  6.619959442517569e-05\n",
      "EDP:  8308194.5  % decrease:  2.4072604419284827e-05\n",
      "EDP:  8308194.5  % decrease:  3.0090770011370097e-05\n",
      "EDP:  8308188.5  % decrease:  3.6108941398377736e-05\n",
      "EDP:  8308189.5  % decrease:  1.203631742128158e-05\n",
      "EDP:  8308186.5  % decrease:  5.4163421876485734e-05\n",
      "EDP:  8308185.5  % decrease:  2.4072637740022252e-05\n",
      "EDP:  8308186.0  % decrease:  6.018160883735631e-06\n",
      "Percentage threshold reached\n",
      "Temperature:  0.5\n",
      "Map:  tensor([ 5.7123,  1.0000,  1.1438, 19.0099,  1.7879,  1.6974, 18.9328,  1.0000,\n",
      "         1.6891,  1.0000,  1.0000,  1.7879], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  2055.920654296875\n",
      "Local memory size:  6.740689754486084\n",
      "A tile size:  1.9415769577026367 B tile size:  2.867079019546509 Z tile size:  1.9320340156555176\n",
      "-----------------------\n",
      "EDP:  8308186.5  % decrease:  0.0\n",
      "Percentage threshold reached\n",
      "Temperature:  0.25\n",
      "Map:  tensor([ 5.7123,  1.0000,  1.1438, 19.0100,  1.7879,  1.6974, 18.9327,  1.0000,\n",
      "         1.6891,  1.0000,  1.0000,  1.7879], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  2055.924560546875\n",
      "Local memory size:  6.7407121658325195\n",
      "A tile size:  1.9415634870529175 B tile size:  2.8670830726623535 Z tile size:  1.932065486907959\n",
      "-----------------------\n",
      "EDP:  8308186.5  % decrease:  1.2036322491836515e-05\n",
      "EDP:  8308186.5  % decrease:  0.0\n",
      "Percentage threshold reached\n",
      "Temperature:  0.125\n",
      "Map:  tensor([ 5.7123,  1.0000,  1.1438, 19.0100,  1.7879,  1.6974, 18.9327,  1.0000,\n",
      "         1.6891,  1.0000,  1.0000,  1.7879], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  2055.924560546875\n",
      "Local memory size:  6.740712642669678\n",
      "A tile size:  1.9415634870529175 B tile size:  2.8670830726623535 Z tile size:  1.9320658445358276\n",
      "-----------------------\n",
      "EDP:  8308186.5  % decrease:  0.0\n",
      "Percentage threshold reached\n",
      "Temperature:  0.0625\n",
      "Map:  tensor([ 5.7123,  1.0000,  1.1438, 19.0100,  1.7879,  1.6974, 18.9327,  1.0000,\n",
      "         1.6891,  1.0000,  1.0000,  1.7879], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  2055.924560546875\n",
      "Local memory size:  6.740712642669678\n",
      "A tile size:  1.9415634870529175 B tile size:  2.8670830726623535 Z tile size:  1.9320658445358276\n",
      "-----------------------\n",
      "EDP:  8308187.0  % decrease:  1.203631959437603e-05\n",
      "EDP:  8308186.0  % decrease:  1.805447830501669e-05\n",
      "EDP:  8308186.5  % decrease:  0.0\n",
      "Percentage threshold reached\n",
      "Temperature:  0.03125\n",
      "Map:  tensor([ 5.7123,  1.0000,  1.1438, 19.0100,  1.7879,  1.6974, 18.9327,  1.0000,\n",
      "         1.6891,  1.0000,  1.0000,  1.7879], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  2055.92529296875\n",
      "Local memory size:  6.740712642669678\n",
      "A tile size:  1.9415638446807861 B tile size:  2.86708402633667 Z tile size:  1.9320645332336426\n",
      "-----------------------\n",
      "EDP:  8308187.0  % decrease:  2.407264788113456e-05\n",
      "EDP:  8308186.5  % decrease:  1.2036321043106097e-05\n",
      "EDP:  8308185.0  % decrease:  3.0090798985940074e-05\n",
      "EDP:  8308185.0  % decrease:  1.8054483737754772e-05\n",
      "EDP:  8308188.5  % decrease:  3.0090808040504636e-05\n",
      "EDP:  8308186.0  % decrease:  1.8054483737754772e-05\n",
      "EDP:  8308184.5  % decrease:  1.8054484824302782e-05\n",
      "EDP:  8308186.0  % decrease:  3.610896530241379e-05\n",
      "EDP:  8308185.0  % decrease:  1.8054482651206894e-05\n",
      "EDP:  8308187.0  % decrease:  2.407263918875206e-05\n",
      "EDP:  8308185.0  % decrease:  1.2036321043106097e-05\n",
      "EDP:  8308198.0  % decrease:  0.0\n",
      "Percentage threshold reached\n",
      "Temperature:  0.015625\n",
      "Map:  tensor([ 5.7116,  1.0000,  1.1442, 19.0235,  1.7857,  1.6955, 18.9274,  1.0000,\n",
      "         1.6909,  1.0000,  1.0000,  1.7857], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  2056.54150390625\n",
      "Local memory size:  6.741565704345703\n",
      "A tile size:  1.9400222301483154 B tile size:  2.86683988571167 Z tile size:  1.934704065322876\n",
      "-----------------------\n",
      "EDP:  8308184.5  % decrease:  6.018161608100927e-06\n",
      "Percentage threshold reached\n",
      "Temperature:  0.0078125\n",
      "Map:  tensor([ 5.7123,  1.0000,  1.1438, 19.0100,  1.7879,  1.6974, 18.9327,  1.0000,\n",
      "         1.6891,  1.0000,  1.0000,  1.7879], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  2055.9208984375\n",
      "Local memory size:  6.74074125289917\n",
      "A tile size:  1.9415695667266846 B tile size:  2.8670971393585205 Z tile size:  1.9320744276046753\n",
      "-----------------------\n",
      "EDP:  8823351.0  % decrease:  4.533422943993526e-05\n",
      "EDP:  8823333.0  % decrease:  0.0001246693005134222\n",
      "EDP:  8360147.0  % decrease:  5.248827674531283\n",
      "EDP:  8308184.0  % decrease:  6.018160521553049e-06\n",
      "Percentage threshold reached\n",
      "Temperature:  0.00390625\n",
      "Map:  tensor([ 5.7123,  1.0000,  1.1438, 19.0100,  1.7879,  1.6974, 18.9327,  1.0000,\n",
      "         1.6891,  1.0000,  1.0000,  1.7879], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  2055.927734375\n",
      "Local memory size:  6.74070405960083\n",
      "A tile size:  1.9415587186813354 B tile size:  2.8670833110809326 Z tile size:  1.9320622682571411\n",
      "-----------------------\n",
      "EDP:  10119563.0  % decrease:  0.0\n",
      "Percentage threshold reached\n",
      "Temperature:  0.001953125\n",
      "Map:  tensor([ 6.0000,  1.0000,  1.0000, 25.0000,  1.0000,  1.0000, 21.0000,  1.0000,\n",
      "         1.0000,  1.0000,  1.0000,  1.0000], grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  3149.999755859375\n",
      "Local memory size:  3.000000476837158\n",
      "A tile size:  1.000000238418579 B tile size:  1.0 Z tile size:  1.000000238418579\n",
      "-----------------------\n",
      "EDP:  10119563.0  % decrease:  0.0\n",
      "Percentage threshold reached\n",
      "Temperature:  0.0009765625\n",
      "Map:  tensor([ 6.,  1.,  1., 25.,  1.,  1., 21.,  1.,  1.,  1.,  1.,  1.],\n",
      "       grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  3150.0\n",
      "Local memory size:  3.0\n",
      "A tile size:  1.0 B tile size:  1.0 Z tile size:  1.0\n",
      "-----------------------\n",
      "EDP:  10119563.0  % decrease:  0.0\n",
      "Percentage threshold reached\n",
      "Temperature:  0.00048828125\n",
      "Map:  tensor([ 6.,  1.,  1., 25.,  1.,  1., 21.,  1.,  1.,  1.,  1.,  1.],\n",
      "       grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  3150.0\n",
      "Local memory size:  3.0\n",
      "A tile size:  1.0 B tile size:  1.0 Z tile size:  1.0\n",
      "-----------------------\n",
      "EDP:  10119563.0  % decrease:  0.0\n",
      "Percentage threshold reached\n",
      "Temperature:  0.000244140625\n",
      "Map:  tensor([ 6.,  1.,  1., 25.,  1.,  1., 21.,  1.,  1.,  1.,  1.,  1.],\n",
      "       grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  3150.0\n",
      "Local memory size:  3.0\n",
      "A tile size:  1.0 B tile size:  1.0 Z tile size:  1.0\n",
      "-----------------------\n",
      "EDP:  10119563.0  % decrease:  0.0\n",
      "Percentage threshold reached\n",
      "Temperature:  0.0001220703125\n",
      "Map:  tensor([ 6.,  1.,  1., 25.,  1.,  1., 21.,  1.,  1.,  1.,  1.,  1.],\n",
      "       grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  3150.0\n",
      "Local memory size:  3.0\n",
      "A tile size:  1.0 B tile size:  1.0 Z tile size:  1.0\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDP:  10119563.0  % decrease:  0.0\n",
      "Percentage threshold reached\n",
      "Temperature:  6.103515625e-05\n",
      "Map:  tensor([ 6.,  1.,  1., 25.,  1.,  1., 21.,  1.,  1.,  1.,  1.,  1.],\n",
      "       grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  3150.0\n",
      "Local memory size:  3.0\n",
      "A tile size:  1.0 B tile size:  1.0 Z tile size:  1.0\n",
      "-----------------------\n",
      "EDP:  10119563.0  % decrease:  0.0\n",
      "Percentage threshold reached\n",
      "Temperature:  3.0517578125e-05\n",
      "Map:  tensor([ 6.,  1.,  1., 25.,  1.,  1., 21.,  1.,  1.,  1.,  1.,  1.],\n",
      "       grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  3150.0\n",
      "Local memory size:  3.0\n",
      "A tile size:  1.0 B tile size:  1.0 Z tile size:  1.0\n",
      "-----------------------\n",
      "EDP:  10119563.0  % decrease:  0.0\n",
      "Percentage threshold reached\n",
      "Temperature:  1.52587890625e-05\n",
      "Map:  tensor([ 6.,  1.,  1., 25.,  1.,  1., 21.,  1.,  1.,  1.,  1.,  1.],\n",
      "       grad_fn=<CatBackward>)\n",
      "Arch details:\n",
      "Spatial fan-out:  3150.0\n",
      "Local memory size:  3.0\n",
      "A tile size:  1.0 B tile size:  1.0 Z tile size:  1.0\n",
      "-----------------------\n",
      "EDP:  10119563.0  % decrease:  0.0\n",
      "Percentage threshold reached\n",
      "EDP:  tensor(10119563., grad_fn=<MulBackward0>)  Map:  tensor([ 6.,  1.,  1., 25.,  1.,  1., 21.,  1.,  1.,  1.,  1.,  1.],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "net = ArchMap_spGEMM(2*3, 5*5, 3*7)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters() , lr=0.002)\n",
    "\n",
    "T = torch.tensor([1.0])\n",
    "\n",
    "edp_list = []\n",
    "cooling_points = []\n",
    "temperature_list = []\n",
    "\n",
    "thresh_pct = 0.5\n",
    "\n",
    "pct = 100.0\n",
    "\n",
    "i = 0\n",
    "\n",
    "net(T)\n",
    "\n",
    "while(T.item() > 1.0e-05):\n",
    "    cooling_points.append(i)\n",
    "    temperature_list.append(T.item())\n",
    "    \n",
    "    print(\"Temperature: \", T.item())\n",
    "    print(\"Map: \", net.calcMap(T))\n",
    "    print(\"Arch details:\")\n",
    "    net.archMapStats()\n",
    "    print(\"-----------------------\")\n",
    "    pct = 100.0\n",
    "    while(pct > 0.00001 and T.item() > 1.0e-05):\n",
    "        optimizer.zero_grad() # clear gradients\n",
    "        edp = net(T) # forward step\n",
    "        edp_list.append(edp.item())\n",
    "        loss = edp\n",
    "        loss.backward() # backprop\n",
    "        optimizer.step() # optimize weights\n",
    "        if i % 1000 == 0:\n",
    "            pct = 100.0\n",
    "            if i > 0:\n",
    "                pct = 100.0*abs(edp_list[-1]-edp_list[-500])/edp_list[-500] #100.0*abs(edp_list[-1]-edp_list[-2])/edp_list[-2]\n",
    "            print(\"EDP: \", net(T).item(), \" % decrease: \", pct)    \n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "        i = i + 1\n",
    "    print(\"Percentage threshold reached\")\n",
    "    T = T/2.0\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(edp_list)\n",
    "plt.xlabel(\"Gradient descent iterations\")\n",
    "plt.ylabel(\"EDP\")\n",
    "plt.title(\"Gradient-descent optimization of mapping + architecture\")\n",
    "plt.grid(\"on\")\n",
    "\n",
    "for jdx in range(len(cooling_points)):\n",
    "    plt.plot(np.array([cooling_points[jdx],cooling_points[jdx]]), np.array([-10.0,edp_list[0]]))\n",
    "# len(edp_list)<2 or 100.0*math.abs(edp_list[-1]-edp_list[-2])/edp_list[-2] > thresh_pct\n",
    "\n",
    "print(\"EDP: \", net(T), \" Map: \", net.calcMap(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(edp_list)\n",
    "plt.xlabel(\"Gradient descent iterations\")\n",
    "plt.ylabel(\"EDP\")\n",
    "plt.title(\"Gradient-descent optimization of mapping + architecture\")\n",
    "plt.grid(\"on\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(10119563., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6.,  1.,  1., 25.,  1.,  1., 21.,  1.,  1.,  1.,  1.,  1.],\n",
       "       grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.calcMap(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature:  1.0\n",
      "-----------------------\n",
      "tensor(1.4132e+08, grad_fn=<MulBackward0>)\n",
      "tensor(1.4044e+08, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16999984., grad_fn=<MulBackward0>)\n",
      "tensor(11566562., grad_fn=<MulBackward0>)\n",
      "tensor(9905352., grad_fn=<MulBackward0>)\n",
      "tensor(9195953., grad_fn=<MulBackward0>)\n",
      "tensor(8873597., grad_fn=<MulBackward0>)\n",
      "tensor(8706566., grad_fn=<MulBackward0>)\n",
      "tensor(8613530., grad_fn=<MulBackward0>)\n",
      "tensor(8559025., grad_fn=<MulBackward0>)\n",
      "tensor(8526076., grad_fn=<MulBackward0>)\n",
      "tensor(8505949., grad_fn=<MulBackward0>)\n",
      "tensor(8493617., grad_fn=<MulBackward0>)\n",
      "tensor(8486057., grad_fn=<MulBackward0>)\n",
      "tensor(8481417., grad_fn=<MulBackward0>)\n",
      "tensor(8478573., grad_fn=<MulBackward0>)\n",
      "tensor(8476829., grad_fn=<MulBackward0>)\n",
      "tensor(8475757., grad_fn=<MulBackward0>)\n",
      "tensor(8475103., grad_fn=<MulBackward0>)\n",
      "tensor(8474698., grad_fn=<MulBackward0>)\n",
      "tensor(8474454., grad_fn=<MulBackward0>)\n",
      "-----\n",
      "Final EDP:  tensor(8474303., grad_fn=<MulBackward0>)\n",
      "Final map:  tensor([ 5.7557,  1.0000,  1.1221, 19.6578,  1.0000,  2.4532, 18.6267,  1.4193,\n",
      "         1.3717,  1.4193,  1.0000,  1.0000], grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "T = torch.tensor([1.0])\n",
    "print(\"Temperature: \", T.item())\n",
    "print(\"-----------------------\")\n",
    "print(net(T))\n",
    "for i in range(20000):\n",
    "    optimizer.zero_grad() # clear gradients\n",
    "    edp = net(T) # forward step\n",
    "    loss = edp\n",
    "    loss.backward() # backprop\n",
    "    optimizer.step() # optimize weights\n",
    "    if i % 1000 == 0:\n",
    "        print(net(T))\n",
    "print(\"-----\")\n",
    "print(\"Final EDP: \", net(T))\n",
    "print(\"Final map: \", net.calcMap(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final map:  tensor([1.7869, 3.3463, 1.5824, 5.2726, 3.2067, 6.5668, 5.0695, 6.7205, 2.4300,\n",
      "        2.7369, 1.3967, 2.1636], grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Final map: \", net.calcMap(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature:  0.10000000149011612\n",
      "-----------------------\n",
      "tensor(8512693., grad_fn=<MulBackward0>)\n",
      "tensor(8512693., grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8512692., grad_fn=<MulBackward0>)\n",
      "tensor(8512693., grad_fn=<MulBackward0>)\n",
      "tensor(8474068., grad_fn=<MulBackward0>)\n",
      "tensor(8474070., grad_fn=<MulBackward0>)\n",
      "tensor(8474067., grad_fn=<MulBackward0>)\n",
      "tensor(8474067., grad_fn=<MulBackward0>)\n",
      "tensor(8474068., grad_fn=<MulBackward0>)\n",
      "tensor(8474066., grad_fn=<MulBackward0>)\n",
      "tensor(8474067., grad_fn=<MulBackward0>)\n",
      "tensor(8474066., grad_fn=<MulBackward0>)\n",
      "tensor(8474065., grad_fn=<MulBackward0>)\n",
      "tensor(8474066., grad_fn=<MulBackward0>)\n",
      "tensor(8474065., grad_fn=<MulBackward0>)\n",
      "tensor(8474065., grad_fn=<MulBackward0>)\n",
      "tensor(8474068., grad_fn=<MulBackward0>)\n",
      "tensor(8474066., grad_fn=<MulBackward0>)\n",
      "tensor(8474066., grad_fn=<MulBackward0>)\n",
      "tensor(8474065., grad_fn=<MulBackward0>)\n",
      "tensor(8474067., grad_fn=<MulBackward0>)\n",
      "-----\n",
      "Final EDP:  tensor(8474069., grad_fn=<MulBackward0>)\n",
      "Final map:  tensor([ 5.7559,  1.0000,  1.1221, 19.6561,  1.0000,  2.4539, 18.6278,  1.4192,\n",
      "         1.3716,  1.4192,  1.0000,  1.0000], grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "T = torch.tensor([0.1])\n",
    "print(\"Temperature: \", T.item())\n",
    "print(\"-----------------------\")\n",
    "print(net(T))\n",
    "for i in range(20000):\n",
    "    optimizer.zero_grad() # clear gradients\n",
    "    edp = net(T) # forward step\n",
    "    loss = edp\n",
    "    loss.backward() # backprop\n",
    "    optimizer.step() # optimize weights\n",
    "    if i % 1000 == 0:\n",
    "        print(net(T))\n",
    "print(\"-----\")\n",
    "print(\"Final EDP: \", net(T))\n",
    "print(\"Final map: \", net.calcMap(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature:  0.0010000000474974513\n",
      "-----------------------\n",
      "tensor(10119563., grad_fn=<MulBackward0>)\n",
      "tensor(10119563., grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10119563., grad_fn=<MulBackward0>)\n",
      "tensor(10119563., grad_fn=<MulBackward0>)\n",
      "tensor(10119563., grad_fn=<MulBackward0>)\n",
      "tensor(10119563., grad_fn=<MulBackward0>)\n",
      "tensor(10119563., grad_fn=<MulBackward0>)\n",
      "tensor(10119563., grad_fn=<MulBackward0>)\n",
      "tensor(10119563., grad_fn=<MulBackward0>)\n",
      "tensor(10119563., grad_fn=<MulBackward0>)\n",
      "tensor(10119563., grad_fn=<MulBackward0>)\n",
      "-----\n",
      "Final EDP:  tensor(10119563., grad_fn=<MulBackward0>)\n",
      "Final map:  tensor([ 6.,  1.,  1., 25.,  1.,  1., 21.,  1.,  1.,  1.,  1.,  1.],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "T = torch.tensor([0.001])\n",
    "print(\"Temperature: \", T.item())\n",
    "print(\"-----------------------\")\n",
    "print(net(T))\n",
    "for i in range(10000):\n",
    "    optimizer.zero_grad() # clear gradients\n",
    "    edp = net(T) # forward step\n",
    "    loss = edp\n",
    "    loss.backward() # backprop\n",
    "    optimizer.step() # optimize weights\n",
    "    if i % 1000 == 0:\n",
    "        print(net(T))\n",
    "print(\"-----\")\n",
    "print(\"Final EDP: \", net(T))\n",
    "print(\"Final map: \", net.calcMap(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature:  0.009999999776482582\n",
      "-----------------------\n",
      "tensor(9359604., grad_fn=<MulBackward0>)\n",
      "tensor(9359609., grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9359602., grad_fn=<MulBackward0>)\n",
      "tensor(9359610., grad_fn=<MulBackward0>)\n",
      "tensor(9359603., grad_fn=<MulBackward0>)\n",
      "tensor(9359601., grad_fn=<MulBackward0>)\n",
      "tensor(9359624., grad_fn=<MulBackward0>)\n",
      "tensor(9359604., grad_fn=<MulBackward0>)\n",
      "tensor(9359759., grad_fn=<MulBackward0>)\n",
      "tensor(9359612., grad_fn=<MulBackward0>)\n",
      "tensor(9048232., grad_fn=<MulBackward0>)\n",
      "-----\n",
      "Final EDP:  tensor(9048230., grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Temperature: \", T.item())\n",
    "print(\"-----------------------\")\n",
    "print(net(T))\n",
    "for i in range(10000):\n",
    "    optimizer.zero_grad() # clear gradients\n",
    "    edp = net(T) # forward step\n",
    "    loss = edp\n",
    "    loss.backward() # backprop\n",
    "    optimizer.step() # optimize weights\n",
    "    if i % 1000 == 0:\n",
    "        print(net(T))\n",
    "print(\"-----\")\n",
    "print(\"Final EDP: \", net(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
