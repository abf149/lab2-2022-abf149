{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time, os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "%matplotlib inline\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "log_interval = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "# GPU setup\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"Using {}\".format('GPU' if use_cuda else 'CPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 32, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "def read_labels(label_file):\n",
    "    labels = np.zeros(50000).astype(np.uint8)\n",
    "    with open(label_file, 'r') as f:\n",
    "        n, header_seen = 0, False\n",
    "        for line in f:\n",
    "            if not header_seen:\n",
    "                header_seen = True\n",
    "                continue\n",
    "            labels[n] = int(line.strip().split(',')[1])\n",
    "            n += 1\n",
    "    return labels\n",
    "\n",
    "train_labels = read_labels(\"dataset/train_labels.csv\")\n",
    "\n",
    "train_images = np.load(\"dataset/train_data.npy\")\n",
    "\n",
    "num_train = len(train_images)\n",
    "indices = list(range(num_train))\n",
    "split = 10000\n",
    "\n",
    "# shuffle data\n",
    "np.random.seed(8256)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "class CIFAR10Dataset(Dataset):\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        #transforms.ToPILImage(),\n",
    "        transforms.RandomAffine(0.2,translate=(0.02,0.02),scale=(0.95,1.05)),\n",
    "        transforms.RandomHorizontalFlip()\n",
    "        #transforms.RandomVerticalFlip()\n",
    "        #transforms.ToTensor()\n",
    "    ])    \n",
    "    \n",
    "    apply_transform=False\n",
    "    \n",
    "    def __init__(self, lbls, imgs):\n",
    "        self.samples = [(torch.from_numpy(imgs[idx]),lbls[idx].item()) for idx in range(len(train_val_labels))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        res = []\n",
    "        \n",
    "        if self.apply_transform:\n",
    "            res = self.transform(self.samples[idx][0])\n",
    "            \n",
    "            res = res + torch.normal(0, 255.0*0.0002, size=(3,32,32))\n",
    "            \n",
    "        else:\n",
    "            res = self.samples[idx][0]\n",
    "            \n",
    "            \n",
    "        return (res*2.0/255.0 - 1.0,self.samples[idx][1])\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "trainset_noxform = CIFAR10Dataset(train_labels,train_images)\n",
    "trainset_noxform.apply_transform=False\n",
    "\n",
    "trainset_xform = CIFAR10Dataset(train_labels,train_images)\n",
    "trainset_xform.apply_transform=False\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset_xform, batch_size=25, sampler=train_sampler, shuffle=False)\n",
    "\n",
    "validloader = torch.utils.data.DataLoader(trainset_noxform, batch_size=25, sampler=valid_sampler, shuffle=False)\n",
    "\n",
    "plt.figure(1, figsize=(10,5))\n",
    "\n",
    "print(np.transpose(torch.nn.functional.pad(trainset_noxform[0][0],(10,10), \"reflect\").numpy()).shape)\n",
    "\n",
    "# No transform\n",
    "for idx in range(8):\n",
    "    plt.subplot(2,8,idx+1)\n",
    "    plt.imshow(np.transpose(trainset_noxform[1][0].numpy()))\n",
    "    plt.title(\"%s\" % (class_names[train_labels[1]]))\n",
    "    plt.axis('off')\n",
    "\n",
    "# Transform\n",
    "for idx in range(8):\n",
    "    plt.subplot(2,8,idx+9)\n",
    "    plt.imshow(np.transpose(trainset_xform[1][0].numpy()))\n",
    "    plt.title(\"%s\" % (class_names[train_labels[1]]))\n",
    "    plt.axis('off')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1001,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(trainset_noxform[0][0].numpy()>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 5)\n",
    "        self.conv1_bn = nn.BatchNorm2d(64)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(64, 32, 5)\n",
    "        self.conv2_bn = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3)\n",
    "        self.conv3_bn = nn.BatchNorm2d(64)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 120)\n",
    "        self.fc1_bn = nn.BatchNorm1d(120)        \n",
    "        self.dropout1 = nn.Dropout(p=0.5)        \n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc2_bn = nn.BatchNorm1d(84)\n",
    "        self.dropout2 = nn.Dropout(p=0.5)        \n",
    "        self.fc3 = nn.Linear(84, 84)\n",
    "        self.fc3_bn = nn.BatchNorm1d(84)\n",
    "        self.dropout3 = nn.Dropout(p=0.5)        \n",
    "        self.fc4 = nn.Linear(84, 10)\n",
    "        self.fc4_bn = nn.BatchNorm1d(10)\n",
    "        self.dropout4 = nn.Dropout(p=0.5)        \n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1_bn(self.conv1(x))))\n",
    "        x = F.relu(self.conv2_bn(self.conv2(x)))\n",
    "        x = F.relu(self.conv3_bn(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        #x = self.dropout1(x)\n",
    "        x = F.relu((self.fc1(x)))\n",
    "        x = F.relu((self.fc2(x)))\n",
    "        x = (self.fc3(x))\n",
    "        x = ((self.fc4(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "#net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "#optimizer = optim.Adam([var1, var2], lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/kuangliu/pytorch-cifar/blob/master/models/resnet.py\n",
    "\n",
    "'''ResNet in PyTorch.\n",
    "For Pre-activation ResNet, see 'preact_resnet.py'.\n",
    "Reference:\n",
    "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
    "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    " #       self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "class ResNetEff(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNetEff, self).__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, self.in_planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_planes)\n",
    "        self.layer1 = self._make_layer(block, self.in_planes, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 16, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 16, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 16, num_blocks[3], stride=2)\n",
    "        self.layer5 = self._make_layer(block, 32, num_blocks[4], stride=2)\n",
    "        self.layer6 = self._make_layer(block, 64, num_blocks[5], stride=2)\n",
    "        self.layer7 = self._make_layer(block, 128, num_blocks[6], stride=2)\n",
    "        self.layer8 = self._make_layer(block, 128, num_blocks[7], stride=1)\n",
    "        self.linear = nn.Linear(128*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        \n",
    "        out = self.layer6(out)\n",
    "        #print(out.shape)\n",
    "        out = self.layer7(out)\n",
    "        out = self.layer8(out)\n",
    "        #print(out.shape)\n",
    "        out = F.avg_pool2d(out, 1)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out    \n",
    "\n",
    "def ResNetMake():\n",
    "    return ResNetEff(BasicBlock, [2, 2, 2, 2, 2, 2, 2, 1])    \n",
    "    \n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet50():\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet101():\n",
    "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "\n",
    "def ResNet152():\n",
    "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
    "\n",
    "\n",
    "def test():\n",
    "    net = ResNet18()\n",
    "    y = net(torch.randn(1, 3, 32, 32))\n",
    "    print(y.size())\n",
    "    \n",
    "    \n",
    "net = ResNetMake()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "#optimizer = optim.Adam([var1, var2], lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1000] loss: 1.878, training error: 69.8%\n",
      "Accuracy  of the network on the 50000 training images after epoch 1: train: 33.96 valid: 43.56 % (47.1 sec)\n",
      "[2,  1000] loss: 1.471, training error: 53.7%\n",
      "Accuracy  of the network on the 50000 training images after epoch 2: train: 48.48 valid: 55.15 % (92.6 sec)\n",
      "[3,  1000] loss: 1.241, training error: 43.9%\n",
      "Accuracy  of the network on the 50000 training images after epoch 3: train: 57.06 valid: 59.57 % (137.3 sec)\n",
      "[4,  1000] loss: 1.085, training error: 38.2%\n",
      "Accuracy  of the network on the 50000 training images after epoch 4: train: 62.25 valid: 62.94 % (182.9 sec)\n",
      "[5,  1000] loss: 0.981, training error: 34.5%\n",
      "Accuracy  of the network on the 50000 training images after epoch 5: train: 66.05 valid: 66.29 % (228.6 sec)\n",
      "[6,  1000] loss: 0.876, training error: 30.5%\n",
      "Accuracy  of the network on the 50000 training images after epoch 6: train: 69.24 valid: 67.67 % (274.0 sec)\n"
     ]
    }
   ],
   "source": [
    "training_acc_vect = np.zeros(num_epochs)\n",
    "valid_acc_vect = np.zeros(num_epochs)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# initialize weights and biases\n",
    "#nn.init.kaiming_uniform_(net.conv1.weight, nonlinearity = 'relu')\n",
    "#stdv = 1./np.sqrt(net.conv1.bias.size(0))\n",
    "#nn.init.uniform_(net.conv1.bias, -stdv, stdv)\n",
    "#nn.init.kaiming_uniform_(net.conv2.weight, nonlinearity = 'relu')\n",
    "#stdv = 1./np.sqrt(net.conv2.bias.size(0))\n",
    "#nn.init.uniform_(net.conv2.bias, -stdv, stdv)\n",
    "#nn.init.kaiming_uniform_(net.conv3.weight, nonlinearity = 'relu')\n",
    "#stdv = 1./np.sqrt(net.conv3.bias.size(0))\n",
    "#nn.init.uniform_(net.conv3.bias, -stdv, stdv)\n",
    "#nn.init.kaiming_uniform_(net.fc1.weight, nonlinearity = 'relu')\n",
    "#stdv = 1./np.sqrt(net.fc1.bias.size(0))\n",
    "#nn.init.uniform_(net.fc1.bias, -stdv, stdv)\n",
    "#nn.init.kaiming_uniform_(net.fc2.weight, nonlinearity = 'relu')\n",
    "#stdv = 1./np.sqrt(net.fc2.bias.size(0))\n",
    "#nn.init.uniform_(net.fc2.bias, -stdv, stdv)\n",
    "#nn.init.kaiming_uniform_(net.fc3.weight, nonlinearity = 'relu')\n",
    "#stdv = 1./np.sqrt(net.fc3.bias.size(0))\n",
    "#nn.init.uniform_(net.fc3.bias, -stdv, stdv)\n",
    "#nn.init.kaiming_uniform_(net.fc4.weight, nonlinearity = 'relu')\n",
    "#stdv = 1./np.sqrt(net.fc4.bias.size(0))\n",
    "#nn.init.uniform_(net.fc4.bias, -stdv, stdv)\n",
    "\n",
    "training_error_log = np.zeros(int(num_epochs*len(train_labels)/log_interval))\n",
    "training_loss_log = np.zeros(int(num_epochs*len(train_labels)/log_interval))\n",
    "valid_error_vect = np.zeros(num_epochs)\n",
    "\n",
    "if use_cuda:\n",
    "    net.cuda()\n",
    "    criterion.cuda()\n",
    "\n",
    "optimizer = optim.Adam(net.parameters() , lr=0.002) \n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.0001,\n",
    "#                      momentum=0.9, weight_decay=5e-4)\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200) \n",
    "    \n",
    "    \n",
    "# train network\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times while training\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    correct_valid = 0    \n",
    "    total_valid = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data # list of [inputs, labels]\n",
    "        \n",
    "        if use_cuda:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()  \n",
    "        \n",
    "        #print(labels)\n",
    "        optimizer.zero_grad() # clear gradients\n",
    "        outputs = net(inputs) # forward step\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward() # backprop\n",
    "        optimizer.step() # optimize weights\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        running_loss += loss.item()\n",
    "        training_error = 1-correct_train/total_train\n",
    "    \n",
    "    \n",
    "        if i % log_interval == log_interval-1:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f, training error: %.1f%%' % \n",
    "                  (epoch + 1, i + 1, running_loss / log_interval, training_error*100))\n",
    "            training_loss_log[int((epoch*len(train_labels)/log_interval)+(i+1)/log_interval-1)] = running_loss/log_interval\n",
    "            training_error_log[int((epoch*len(train_labels)/log_interval)+(i+1)/log_interval-1)] = training_error\n",
    "            running_loss = 0.0    \n",
    "    \n",
    "    training_acc = correct_train / total_train * 100\n",
    "    training_acc_vect[epoch] = training_acc\n",
    "    \n",
    "    for i, data in enumerate(validloader, 0):\n",
    "        inputs, labels = data # list of [inputs, labels]   \n",
    "        \n",
    "        if use_cuda:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()        \n",
    "        \n",
    "        outputs = net(inputs) # forward step        \n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_valid += labels.size(0)    \n",
    "        correct_valid += (predicted == labels).sum().item()        \n",
    "\n",
    "        # print statistics\n",
    "        duration = time.time() - start_time        \n",
    "    \n",
    "    valid_acc = correct_valid / total_valid * 100\n",
    "    valid_acc_vect[epoch] = valid_acc    \n",
    "    \n",
    "    print('Accuracy  of the network on the 50000 training images after epoch %d: train: %.2f valid: %.2f %% (%.1f sec)' % (\n",
    "        epoch + 1, training_acc, valid_acc, duration))\n",
    "    \n",
    "    # your code here to calculate the validation error after each epoch\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_vect = np.linspace(1, num_epochs, num_epochs)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(epoch_vect, 100-training_acc_vect)\n",
    "plt.plot(epoch_vect, 100-valid_acc_vect)\n",
    "plt.grid('on')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('% error')\n",
    "plt.title('DNN error (train & valid)')\n",
    "plt.legend(['train','valid'])\n",
    "\n",
    "print(\"Final Accuracy: train: %g valid %g\" % (training_acc, valid_acc))\n",
    "\n",
    "# Your code here to plot validation error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100.0-valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELPATH = './cifar10_sample.pth.tar'\n",
    "torch.save(net.state_dict(), MODELPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in net.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate assignment grade on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_complexity = {}\n",
    "network_complexity['energy'] = 0.45815967 # Estimated energy in mJ.\n",
    "network_complexity['latency'] = 0.06159200 # Number of cycles in Million (1e6).\n",
    "network_complexity['activation'] = 131072 # Activation size in byte. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy = 1-valid_error_vect[-1]\n",
    "def get_score(accuracy, network_complexity):\n",
    "    error_rate = (1-accuracy) * 100\n",
    "    #error_rate = 20\n",
    "    print(str(error_rate))\n",
    "    loss = error_rate / 12 + network_complexity['latency'] / 0.3\n",
    "    \n",
    "    if error_rate > 50:\n",
    "        return (0, loss)\n",
    "    elif network_complexity['activation'] > 1000000:\n",
    "        return (0, loss)\n",
    "    else:\n",
    "        score = 0\n",
    "        if network_complexity['energy'] > 2:\n",
    "            score += 0\n",
    "        elif network_complexity['energy'] > 1.5:\n",
    "            score += 5\n",
    "        elif network_complexity['energy'] > 1:\n",
    "            score += 10\n",
    "        elif network_complexity['energy'] > 0.5:\n",
    "            score += 15\n",
    "        else:\n",
    "            score += 20\n",
    "            \n",
    "        if network_complexity['latency'] > 1:\n",
    "            score += 0\n",
    "        elif network_complexity['latency'] > 0.5:\n",
    "            score += 5\n",
    "        elif network_complexity['latency'] > 0.25:\n",
    "            score += 10\n",
    "        elif network_complexity['latency'] > 0.1:\n",
    "            score += 15\n",
    "        else:\n",
    "            score += 20\n",
    "            \n",
    "        if error_rate < 5:\n",
    "            score += 80\n",
    "        elif error_rate < 10:\n",
    "            score += 70\n",
    "        elif error_rate < 20:\n",
    "            score += 60\n",
    "        elif error_rate < 30:\n",
    "            score += 50\n",
    "        elif error_rate < 40:\n",
    "            score += 40\n",
    "        else:\n",
    "            score += 30\n",
    "            \n",
    "        return (score, loss)\n",
    "\n",
    "base_score, loss = get_score(valid_acc/100.0, network_complexity)\n",
    "    \n",
    "# Calculated at the end of the competition based on everyones loss\n",
    "competition_bonus = 0\n",
    "final_score = base_score + (competition_bonus if base_score > 0 else 0)\n",
    "\n",
    "print(\"Base Score: %d, Loss: %g\" % (base_score, loss))\n",
    "print(\"Final Score: %d\" % (final_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def create_submission(labels):\n",
    "    now = time.time()\n",
    "    now_str = datetime.datetime.fromtimestamp(now).strftime('%m%d-%H%M%S')\n",
    "    complexity_str = '{:.4f}-{:.4f}-{}'.format(network_complexity['energy'], \\\n",
    "                                               network_complexity['latency'], \\\n",
    "                                               network_complexity['activation']).replace('.', 'p')\n",
    "    filename = 'submission-%s-%s.csv' % (complexity_str, now_str)\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for n in range(labels.shape[0]):\n",
    "            f.write(\"%d,%d\\n\" % (n,labels[n]))\n",
    "    return now_str, filename\n",
    "\n",
    "test_images = np.load(\"dataset/test_data.npy\")\n",
    "\n",
    "# convert to torch format\n",
    "test_images = torch.from_numpy(np.expand_dims(test_images, axis=1))\n",
    "dummy_lbls = torch.zeros(test_images.shape[0])\n",
    "\n",
    "print(test_images.shape) \n",
    "\n",
    "test_result = torch.zeros(test_images.shape[0])\n",
    "\n",
    "bt_sz=25\n",
    "\n",
    "print(test_images.shape[0]/bt_sz)\n",
    "\n",
    "# test on validation data\n",
    "with torch.no_grad():\n",
    "    for i in range(int(test_images.shape[0]/bt_sz)):\n",
    "        images = test_images[(i*bt_sz):(i*bt_sz + bt_sz)]\n",
    "        images = (images/255.0)*2.0-1 # normalization [-1 to 1]\n",
    "        images = images.float() # convert to torch format\n",
    "        if use_cuda:\n",
    "            images =images.cuda()\n",
    "        #print(images.squeeze().shape)    \n",
    "        outputs = net(images.squeeze())\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        #print(str(predicted.cpu().numpy()))\n",
    "        test_result[(i*bt_sz):(i*bt_sz + bt_sz)] = predicted\n",
    "        #print((i*bt_sz) % 1000)\n",
    "        if (i*bt_sz) % 5000 == 1000-bt_sz:\n",
    "            print('Test data processed: %d/300000' % (i+1))\n",
    "\n",
    "            \n",
    "print(\"Writing file\")\n",
    "            \n",
    "now_str, filename = create_submission(test_result.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(valid_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
