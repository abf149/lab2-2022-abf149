{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time, os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "%matplotlib inline\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "log_interval = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "# GPU setup\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"Using {}\".format('GPU' if use_cuda else 'CPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 32, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "def read_labels(label_file):\n",
    "    labels = np.zeros(50000).astype(np.uint8)\n",
    "    with open(label_file, 'r') as f:\n",
    "        n, header_seen = 0, False\n",
    "        for line in f:\n",
    "            if not header_seen:\n",
    "                header_seen = True\n",
    "                continue\n",
    "            labels[n] = int(line.strip().split(',')[1])\n",
    "            n += 1\n",
    "    return labels\n",
    "\n",
    "train_labels = read_labels(\"dataset/train_labels.csv\")\n",
    "\n",
    "train_images = np.load(\"dataset/train_data.npy\")\n",
    "\n",
    "num_train = len(train_images)\n",
    "indices = list(range(num_train))\n",
    "split = 0\n",
    "\n",
    "# shuffle data\n",
    "np.random.seed(8256)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "class CIFAR10Dataset(Dataset):\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        #transforms.ToPILImage(),\n",
    "        transforms.RandomAffine(0.5,translate=(0.05,0.05),scale=(0.9,1.1)),\n",
    "        transforms.RandomHorizontalFlip()\n",
    "        #transforms.RandomVerticalFlip()\n",
    "        #transforms.ToTensor()\n",
    "    ])    \n",
    "    \n",
    "    apply_transform=False\n",
    "    \n",
    "    def __init__(self, lbls, imgs):\n",
    "        self.samples = [(torch.from_numpy(imgs[idx]),lbls[idx].item()) for idx in range(len(lbls))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        res = []\n",
    "        \n",
    "        if self.apply_transform:\n",
    "            res = self.transform(self.samples[idx][0])\n",
    "            \n",
    "            res = res + torch.normal(0, 255.0*0.0005, size=(3,32,32))\n",
    "            \n",
    "        else:\n",
    "            res = self.samples[idx][0]\n",
    "            \n",
    "            \n",
    "        return (res*2.0/255.0 - 1.0,self.samples[idx][1])\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "trainset_noxform = CIFAR10Dataset(train_labels,train_images)\n",
    "trainset_noxform.apply_transform=False\n",
    "\n",
    "trainset_xform = CIFAR10Dataset(train_labels,train_images)\n",
    "trainset_xform.apply_transform=False\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset_xform, batch_size=25, sampler=train_sampler, shuffle=False)\n",
    "\n",
    "validloader = torch.utils.data.DataLoader(trainset_noxform, batch_size=25, sampler=valid_sampler, shuffle=False)\n",
    "\n",
    "plt.figure(1, figsize=(10,5))\n",
    "\n",
    "print(np.transpose(torch.nn.functional.pad(trainset_noxform[0][0],(10,10), \"reflect\").numpy()).shape)\n",
    "\n",
    "# No transform\n",
    "for idx in range(8):\n",
    "    plt.subplot(2,8,idx+1)\n",
    "    plt.imshow(np.transpose(trainset_noxform[1][0].numpy()))\n",
    "    plt.title(\"%s\" % (class_names[train_labels[1]]))\n",
    "    plt.axis('off')\n",
    "\n",
    "# Transform\n",
    "for idx in range(8):\n",
    "    plt.subplot(2,8,idx+9)\n",
    "    plt.imshow(np.transpose(trainset_xform[1][0].numpy()))\n",
    "    plt.title(\"%s\" % (class_names[train_labels[1]]))\n",
    "    plt.axis('off')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(trainset_noxform[0][0].numpy()>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 5)\n",
    "        self.conv1_bn = nn.BatchNorm2d(64)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(64, 32, 5)\n",
    "        self.conv2_bn = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3)\n",
    "        self.conv3_bn = nn.BatchNorm2d(64)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 120)\n",
    "        self.fc1_bn = nn.BatchNorm1d(120)        \n",
    "        self.dropout1 = nn.Dropout(p=0.5)        \n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc2_bn = nn.BatchNorm1d(84)\n",
    "        self.dropout2 = nn.Dropout(p=0.5)        \n",
    "        self.fc3 = nn.Linear(84, 84)\n",
    "        self.fc3_bn = nn.BatchNorm1d(84)\n",
    "        self.dropout3 = nn.Dropout(p=0.5)        \n",
    "        self.fc4 = nn.Linear(84, 10)\n",
    "        self.fc4_bn = nn.BatchNorm1d(10)\n",
    "        self.dropout4 = nn.Dropout(p=0.5)        \n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1_bn(self.conv1(x))))\n",
    "        x = F.relu(self.conv2_bn(self.conv2(x)))\n",
    "        x = F.relu(self.conv3_bn(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        #x = self.dropout1(x)\n",
    "        x = F.relu((self.fc1(x)))\n",
    "        x = F.relu((self.fc2(x)))\n",
    "        x = (self.fc3(x))\n",
    "        x = ((self.fc4(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "#net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "#optimizer = optim.Adam([var1, var2], lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/kuangliu/pytorch-cifar/blob/master/models/resnet.py\n",
    "\n",
    "'''ResNet in PyTorch.\n",
    "For Pre-activation ResNet, see 'preact_resnet.py'.\n",
    "Reference:\n",
    "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
    "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    " #       self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "class ResNetEff(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNetEff, self).__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, self.in_planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_planes)\n",
    "        self.layer1 = self._make_layer(block, self.in_planes, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 16, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 16, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 16, num_blocks[3], stride=2)\n",
    "        self.layer5 = self._make_layer(block, 32, num_blocks[4], stride=2)\n",
    "        self.layer6 = self._make_layer(block, 64, num_blocks[5], stride=2)\n",
    "        self.layer7 = self._make_layer(block, 128, num_blocks[6], stride=2)\n",
    "        self.layer8 = self._make_layer(block, 128, num_blocks[7], stride=1)\n",
    "        self.linear = nn.Linear(128*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        \n",
    "        out = self.layer6(out)\n",
    "        #print(out.shape)\n",
    "        out = self.layer7(out)\n",
    "        out = self.layer8(out)\n",
    "        #print(out.shape)\n",
    "        out = F.avg_pool2d(out, 1)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out    \n",
    "\n",
    "def ResNetMake():\n",
    "    return ResNetEff(BasicBlock, [2, 2, 2, 2, 2, 2, 2, 1])    \n",
    "    \n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet50():\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet101():\n",
    "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "\n",
    "def ResNet152():\n",
    "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
    "\n",
    "\n",
    "def test():\n",
    "    net = ResNet18()\n",
    "    y = net(torch.randn(1, 3, 32, 32))\n",
    "    print(y.size())\n",
    "    \n",
    "    \n",
    "net = ResNetMake()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "#optimizer = optim.Adam([var1, var2], lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1000] loss: 1.921, training error: 71.7%\n",
      "[1,  2000] loss: 1.578, training error: 64.8%\n",
      "Accuracy  of the network on the 50000 training images after epoch 1: train: 35.20 valid: 35.20 % (1412.5 sec)\n",
      "[2,  1000] loss: 1.404, training error: 50.3%\n",
      "[2,  2000] loss: 1.260, training error: 47.7%\n",
      "Accuracy  of the network on the 50000 training images after epoch 2: train: 52.31 valid: 52.31 % (1412.5 sec)\n",
      "[3,  1000] loss: 1.152, training error: 40.9%\n",
      "[3,  2000] loss: 1.078, training error: 39.5%\n",
      "Accuracy  of the network on the 50000 training images after epoch 3: train: 60.48 valid: 60.48 % (1412.5 sec)\n",
      "[4,  1000] loss: 0.997, training error: 35.2%\n",
      "[4,  2000] loss: 0.960, training error: 34.5%\n",
      "Accuracy  of the network on the 50000 training images after epoch 4: train: 65.48 valid: 65.48 % (1412.5 sec)\n",
      "[5,  1000] loss: 0.893, training error: 31.1%\n",
      "[5,  2000] loss: 0.870, training error: 30.8%\n",
      "Accuracy  of the network on the 50000 training images after epoch 5: train: 69.15 valid: 69.15 % (1412.5 sec)\n",
      "[6,  1000] loss: 0.811, training error: 28.1%\n",
      "[6,  2000] loss: 0.801, training error: 27.9%\n",
      "Accuracy  of the network on the 50000 training images after epoch 6: train: 72.05 valid: 72.05 % (1412.5 sec)\n",
      "[7,  1000] loss: 0.753, training error: 26.3%\n",
      "[7,  2000] loss: 0.740, training error: 26.1%\n",
      "Accuracy  of the network on the 50000 training images after epoch 7: train: 73.95 valid: 73.95 % (1412.5 sec)\n",
      "[8,  1000] loss: 0.699, training error: 24.3%\n",
      "[8,  2000] loss: 0.700, training error: 24.3%\n",
      "Accuracy  of the network on the 50000 training images after epoch 8: train: 75.70 valid: 75.70 % (1412.5 sec)\n",
      "[9,  1000] loss: 0.658, training error: 22.7%\n",
      "[9,  2000] loss: 0.673, training error: 23.0%\n",
      "Accuracy  of the network on the 50000 training images after epoch 9: train: 76.96 valid: 76.96 % (1412.5 sec)\n",
      "[10,  1000] loss: 0.621, training error: 21.5%\n",
      "[10,  2000] loss: 0.634, training error: 21.8%\n",
      "Accuracy  of the network on the 50000 training images after epoch 10: train: 78.17 valid: 78.17 % (1412.5 sec)\n",
      "[11,  1000] loss: 0.597, training error: 20.8%\n",
      "[11,  2000] loss: 0.613, training error: 21.0%\n",
      "Accuracy  of the network on the 50000 training images after epoch 11: train: 79.04 valid: 79.04 % (1412.5 sec)\n",
      "[12,  1000] loss: 0.569, training error: 19.6%\n",
      "[12,  2000] loss: 0.584, training error: 20.0%\n",
      "Accuracy  of the network on the 50000 training images after epoch 12: train: 80.05 valid: 80.05 % (1412.5 sec)\n",
      "[13,  1000] loss: 0.542, training error: 18.9%\n",
      "[13,  2000] loss: 0.566, training error: 19.2%\n",
      "Accuracy  of the network on the 50000 training images after epoch 13: train: 80.76 valid: 80.76 % (1412.5 sec)\n",
      "[14,  1000] loss: 0.515, training error: 18.0%\n",
      "[14,  2000] loss: 0.552, training error: 18.5%\n",
      "Accuracy  of the network on the 50000 training images after epoch 14: train: 81.49 valid: 81.49 % (1412.5 sec)\n",
      "[15,  1000] loss: 0.514, training error: 17.8%\n",
      "[15,  2000] loss: 0.514, training error: 17.9%\n",
      "Accuracy  of the network on the 50000 training images after epoch 15: train: 82.07 valid: 82.07 % (1412.5 sec)\n",
      "[16,  1000] loss: 0.485, training error: 16.7%\n",
      "[16,  2000] loss: 0.507, training error: 17.2%\n",
      "Accuracy  of the network on the 50000 training images after epoch 16: train: 82.79 valid: 82.79 % (1412.5 sec)\n",
      "[17,  1000] loss: 0.457, training error: 15.8%\n",
      "[17,  2000] loss: 0.496, training error: 16.6%\n",
      "Accuracy  of the network on the 50000 training images after epoch 17: train: 83.41 valid: 83.41 % (1412.5 sec)\n",
      "[18,  1000] loss: 0.460, training error: 16.1%\n",
      "[18,  2000] loss: 0.473, training error: 16.2%\n",
      "Accuracy  of the network on the 50000 training images after epoch 18: train: 83.79 valid: 83.79 % (1412.5 sec)\n",
      "[19,  1000] loss: 0.442, training error: 15.6%\n",
      "[19,  2000] loss: 0.454, training error: 15.7%\n",
      "Accuracy  of the network on the 50000 training images after epoch 19: train: 84.31 valid: 84.31 % (1412.5 sec)\n",
      "[20,  1000] loss: 0.426, training error: 14.8%\n",
      "[20,  2000] loss: 0.444, training error: 15.1%\n",
      "Accuracy  of the network on the 50000 training images after epoch 20: train: 84.90 valid: 84.90 % (1412.5 sec)\n",
      "[21,  1000] loss: 0.417, training error: 14.5%\n",
      "[21,  2000] loss: 0.425, training error: 14.7%\n",
      "Accuracy  of the network on the 50000 training images after epoch 21: train: 85.30 valid: 85.30 % (1412.5 sec)\n",
      "[22,  1000] loss: 0.399, training error: 13.7%\n",
      "[22,  2000] loss: 0.417, training error: 14.3%\n",
      "Accuracy  of the network on the 50000 training images after epoch 22: train: 85.70 valid: 85.70 % (1412.5 sec)\n",
      "[23,  1000] loss: 0.388, training error: 13.7%\n",
      "[23,  2000] loss: 0.411, training error: 14.0%\n",
      "Accuracy  of the network on the 50000 training images after epoch 23: train: 85.98 valid: 85.98 % (1412.5 sec)\n",
      "[24,  1000] loss: 0.377, training error: 13.4%\n",
      "[24,  2000] loss: 0.400, training error: 13.7%\n",
      "Accuracy  of the network on the 50000 training images after epoch 24: train: 86.29 valid: 86.29 % (1412.5 sec)\n",
      "[25,  1000] loss: 0.361, training error: 12.8%\n",
      "[25,  2000] loss: 0.390, training error: 13.1%\n",
      "Accuracy  of the network on the 50000 training images after epoch 25: train: 86.87 valid: 86.87 % (1412.5 sec)\n",
      "[26,  1000] loss: 0.355, training error: 12.5%\n",
      "[26,  2000] loss: 0.379, training error: 12.9%\n",
      "Accuracy  of the network on the 50000 training images after epoch 26: train: 87.12 valid: 87.12 % (1412.5 sec)\n",
      "[27,  1000] loss: 0.334, training error: 11.8%\n",
      "[27,  2000] loss: 0.363, training error: 12.3%\n",
      "Accuracy  of the network on the 50000 training images after epoch 27: train: 87.69 valid: 87.69 % (1412.5 sec)\n",
      "[28,  1000] loss: 0.331, training error: 11.7%\n",
      "[28,  2000] loss: 0.356, training error: 12.1%\n",
      "Accuracy  of the network on the 50000 training images after epoch 28: train: 87.90 valid: 87.90 % (1412.5 sec)\n",
      "[29,  1000] loss: 0.321, training error: 11.4%\n",
      "[29,  2000] loss: 0.346, training error: 11.8%\n",
      "Accuracy  of the network on the 50000 training images after epoch 29: train: 88.23 valid: 88.23 % (1412.5 sec)\n",
      "[30,  1000] loss: 0.318, training error: 11.2%\n",
      "[30,  2000] loss: 0.341, training error: 11.6%\n",
      "Accuracy  of the network on the 50000 training images after epoch 30: train: 88.40 valid: 88.40 % (1412.5 sec)\n",
      "[31,  1000] loss: 0.310, training error: 10.9%\n",
      "[31,  2000] loss: 0.337, training error: 11.5%\n",
      "Accuracy  of the network on the 50000 training images after epoch 31: train: 88.53 valid: 88.53 % (1412.5 sec)\n",
      "[32,  1000] loss: 0.298, training error: 10.4%\n",
      "[32,  2000] loss: 0.326, training error: 11.0%\n",
      "Accuracy  of the network on the 50000 training images after epoch 32: train: 89.03 valid: 89.03 % (1412.5 sec)\n",
      "[33,  1000] loss: 0.293, training error: 10.3%\n",
      "[33,  2000] loss: 0.325, training error: 11.0%\n",
      "Accuracy  of the network on the 50000 training images after epoch 33: train: 89.02 valid: 89.02 % (1412.5 sec)\n",
      "[34,  1000] loss: 0.286, training error: 9.9%\n",
      "[34,  2000] loss: 0.320, training error: 10.7%\n",
      "Accuracy  of the network on the 50000 training images after epoch 34: train: 89.34 valid: 89.34 % (1412.5 sec)\n",
      "[35,  1000] loss: 0.278, training error: 9.8%\n",
      "[35,  2000] loss: 0.311, training error: 10.4%\n",
      "Accuracy  of the network on the 50000 training images after epoch 35: train: 89.56 valid: 89.56 % (1412.5 sec)\n",
      "[36,  1000] loss: 0.274, training error: 9.9%\n",
      "[36,  2000] loss: 0.303, training error: 10.2%\n",
      "Accuracy  of the network on the 50000 training images after epoch 36: train: 89.75 valid: 89.75 % (1412.5 sec)\n",
      "[37,  1000] loss: 0.262, training error: 9.2%\n",
      "[37,  2000] loss: 0.296, training error: 9.9%\n",
      "Accuracy  of the network on the 50000 training images after epoch 37: train: 90.08 valid: 90.08 % (1412.5 sec)\n",
      "[38,  1000] loss: 0.262, training error: 9.1%\n",
      "[38,  2000] loss: 0.284, training error: 9.6%\n",
      "Accuracy  of the network on the 50000 training images after epoch 38: train: 90.44 valid: 90.44 % (1412.5 sec)\n",
      "[39,  1000] loss: 0.260, training error: 9.2%\n",
      "[39,  2000] loss: 0.275, training error: 9.4%\n",
      "Accuracy  of the network on the 50000 training images after epoch 39: train: 90.57 valid: 90.57 % (1412.5 sec)\n",
      "[40,  1000] loss: 0.248, training error: 8.8%\n",
      "[40,  2000] loss: 0.274, training error: 9.3%\n",
      "Accuracy  of the network on the 50000 training images after epoch 40: train: 90.73 valid: 90.73 % (1412.5 sec)\n",
      "[41,  1000] loss: 0.250, training error: 8.7%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41,  2000] loss: 0.262, training error: 9.0%\n",
      "Accuracy  of the network on the 50000 training images after epoch 41: train: 91.01 valid: 91.01 % (1412.5 sec)\n",
      "[42,  1000] loss: 0.235, training error: 8.3%\n",
      "[42,  2000] loss: 0.267, training error: 8.8%\n",
      "Accuracy  of the network on the 50000 training images after epoch 42: train: 91.17 valid: 91.17 % (1412.5 sec)\n",
      "[43,  1000] loss: 0.234, training error: 8.4%\n",
      "[43,  2000] loss: 0.260, training error: 8.8%\n",
      "Accuracy  of the network on the 50000 training images after epoch 43: train: 91.23 valid: 91.23 % (1412.5 sec)\n",
      "[44,  1000] loss: 0.231, training error: 8.3%\n",
      "[44,  2000] loss: 0.254, training error: 8.6%\n",
      "Accuracy  of the network on the 50000 training images after epoch 44: train: 91.40 valid: 91.40 % (1412.5 sec)\n",
      "[45,  1000] loss: 0.225, training error: 8.1%\n",
      "[45,  2000] loss: 0.247, training error: 8.5%\n",
      "Accuracy  of the network on the 50000 training images after epoch 45: train: 91.52 valid: 91.52 % (1412.5 sec)\n",
      "[46,  1000] loss: 0.223, training error: 7.8%\n",
      "[46,  2000] loss: 0.239, training error: 8.1%\n",
      "Accuracy  of the network on the 50000 training images after epoch 46: train: 91.86 valid: 91.86 % (1412.5 sec)\n",
      "[47,  1000] loss: 0.212, training error: 7.6%\n",
      "[47,  2000] loss: 0.240, training error: 8.1%\n",
      "Accuracy  of the network on the 50000 training images after epoch 47: train: 91.87 valid: 91.87 % (1412.5 sec)\n",
      "[48,  1000] loss: 0.211, training error: 7.4%\n",
      "[48,  2000] loss: 0.230, training error: 7.8%\n",
      "Accuracy  of the network on the 50000 training images after epoch 48: train: 92.17 valid: 92.17 % (1412.5 sec)\n",
      "[49,  1000] loss: 0.213, training error: 7.6%\n",
      "[49,  2000] loss: 0.222, training error: 7.7%\n",
      "Accuracy  of the network on the 50000 training images after epoch 49: train: 92.29 valid: 92.29 % (1412.5 sec)\n",
      "[50,  1000] loss: 0.199, training error: 7.1%\n",
      "[50,  2000] loss: 0.225, training error: 7.6%\n",
      "Accuracy  of the network on the 50000 training images after epoch 50: train: 92.45 valid: 92.45 % (1412.5 sec)\n",
      "[51,  1000] loss: 0.195, training error: 6.9%\n",
      "[51,  2000] loss: 0.228, training error: 7.5%\n",
      "Accuracy  of the network on the 50000 training images after epoch 51: train: 92.54 valid: 92.54 % (1412.5 sec)\n",
      "[52,  1000] loss: 0.193, training error: 7.0%\n",
      "[52,  2000] loss: 0.223, training error: 7.4%\n",
      "Accuracy  of the network on the 50000 training images after epoch 52: train: 92.60 valid: 92.60 % (1412.5 sec)\n",
      "[53,  1000] loss: 0.194, training error: 6.9%\n",
      "[53,  2000] loss: 0.214, training error: 7.2%\n",
      "Accuracy  of the network on the 50000 training images after epoch 53: train: 92.80 valid: 92.80 % (1412.5 sec)\n",
      "[54,  1000] loss: 0.185, training error: 6.6%\n",
      "[54,  2000] loss: 0.214, training error: 7.1%\n",
      "Accuracy  of the network on the 50000 training images after epoch 54: train: 92.94 valid: 92.94 % (1412.5 sec)\n",
      "[55,  1000] loss: 0.172, training error: 6.1%\n",
      "[55,  2000] loss: 0.215, training error: 6.8%\n",
      "Accuracy  of the network on the 50000 training images after epoch 55: train: 93.19 valid: 93.19 % (1412.5 sec)\n",
      "[56,  1000] loss: 0.187, training error: 6.7%\n",
      "[56,  2000] loss: 0.208, training error: 7.1%\n",
      "Accuracy  of the network on the 50000 training images after epoch 56: train: 92.94 valid: 92.94 % (1412.5 sec)\n",
      "[57,  1000] loss: 0.182, training error: 6.5%\n",
      "[57,  2000] loss: 0.195, training error: 6.7%\n",
      "Accuracy  of the network on the 50000 training images after epoch 57: train: 93.33 valid: 93.33 % (1412.5 sec)\n",
      "[58,  1000] loss: 0.176, training error: 6.3%\n",
      "[58,  2000] loss: 0.195, training error: 6.7%\n",
      "Accuracy  of the network on the 50000 training images after epoch 58: train: 93.33 valid: 93.33 % (1412.5 sec)\n",
      "[59,  1000] loss: 0.171, training error: 6.0%\n",
      "[59,  2000] loss: 0.191, training error: 6.4%\n",
      "Accuracy  of the network on the 50000 training images after epoch 59: train: 93.59 valid: 93.59 % (1412.5 sec)\n",
      "[60,  1000] loss: 0.171, training error: 6.3%\n",
      "[60,  2000] loss: 0.193, training error: 6.6%\n",
      "Accuracy  of the network on the 50000 training images after epoch 60: train: 93.41 valid: 93.41 % (1412.5 sec)\n",
      "[61,  1000] loss: 0.174, training error: 6.1%\n",
      "[61,  2000] loss: 0.176, training error: 6.2%\n",
      "Accuracy  of the network on the 50000 training images after epoch 61: train: 93.80 valid: 93.80 % (1412.5 sec)\n",
      "[62,  1000] loss: 0.160, training error: 5.7%\n",
      "[62,  2000] loss: 0.185, training error: 6.2%\n",
      "Accuracy  of the network on the 50000 training images after epoch 62: train: 93.82 valid: 93.82 % (1412.5 sec)\n",
      "[63,  1000] loss: 0.157, training error: 5.6%\n",
      "[63,  2000] loss: 0.184, training error: 6.1%\n",
      "Accuracy  of the network on the 50000 training images after epoch 63: train: 93.93 valid: 93.93 % (1412.5 sec)\n",
      "[64,  1000] loss: 0.163, training error: 5.8%\n",
      "[64,  2000] loss: 0.179, training error: 6.2%\n",
      "Accuracy  of the network on the 50000 training images after epoch 64: train: 93.84 valid: 93.84 % (1412.5 sec)\n",
      "[65,  1000] loss: 0.161, training error: 5.8%\n",
      "[65,  2000] loss: 0.174, training error: 5.9%\n",
      "Accuracy  of the network on the 50000 training images after epoch 65: train: 94.06 valid: 94.06 % (1412.5 sec)\n",
      "[66,  1000] loss: 0.153, training error: 5.6%\n",
      "[66,  2000] loss: 0.174, training error: 5.9%\n",
      "Accuracy  of the network on the 50000 training images after epoch 66: train: 94.10 valid: 94.10 % (1412.5 sec)\n",
      "[67,  1000] loss: 0.151, training error: 5.5%\n",
      "[67,  2000] loss: 0.172, training error: 5.8%\n",
      "Accuracy  of the network on the 50000 training images after epoch 67: train: 94.21 valid: 94.21 % (1412.5 sec)\n",
      "[68,  1000] loss: 0.145, training error: 5.0%\n",
      "[68,  2000] loss: 0.167, training error: 5.5%\n",
      "Accuracy  of the network on the 50000 training images after epoch 68: train: 94.54 valid: 94.54 % (1412.5 sec)\n",
      "[69,  1000] loss: 0.166, training error: 6.0%\n",
      "[69,  2000] loss: 0.165, training error: 5.9%\n",
      "Accuracy  of the network on the 50000 training images after epoch 69: train: 94.12 valid: 94.12 % (1412.5 sec)\n",
      "[70,  1000] loss: 0.141, training error: 5.1%\n",
      "[70,  2000] loss: 0.160, training error: 5.4%\n",
      "Accuracy  of the network on the 50000 training images after epoch 70: train: 94.56 valid: 94.56 % (1412.5 sec)\n",
      "[71,  1000] loss: 0.148, training error: 5.3%\n",
      "[71,  2000] loss: 0.160, training error: 5.4%\n",
      "Accuracy  of the network on the 50000 training images after epoch 71: train: 94.56 valid: 94.56 % (1412.5 sec)\n",
      "[72,  1000] loss: 0.148, training error: 5.3%\n",
      "[72,  2000] loss: 0.159, training error: 5.4%\n",
      "Accuracy  of the network on the 50000 training images after epoch 72: train: 94.57 valid: 94.57 % (1412.5 sec)\n",
      "[73,  1000] loss: 0.141, training error: 4.9%\n",
      "[73,  2000] loss: 0.153, training error: 5.2%\n",
      "Accuracy  of the network on the 50000 training images after epoch 73: train: 94.81 valid: 94.81 % (1412.5 sec)\n",
      "[74,  1000] loss: 0.136, training error: 4.7%\n",
      "[74,  2000] loss: 0.154, training error: 5.1%\n",
      "Accuracy  of the network on the 50000 training images after epoch 74: train: 94.94 valid: 94.94 % (1412.5 sec)\n",
      "[75,  1000] loss: 0.134, training error: 4.9%\n",
      "[75,  2000] loss: 0.150, training error: 5.1%\n",
      "Accuracy  of the network on the 50000 training images after epoch 75: train: 94.89 valid: 94.89 % (1412.5 sec)\n",
      "[76,  1000] loss: 0.131, training error: 4.7%\n",
      "[76,  2000] loss: 0.157, training error: 5.1%\n",
      "Accuracy  of the network on the 50000 training images after epoch 76: train: 94.85 valid: 94.85 % (1412.5 sec)\n",
      "[77,  1000] loss: 0.133, training error: 4.7%\n",
      "[77,  2000] loss: 0.155, training error: 5.0%\n",
      "Accuracy  of the network on the 50000 training images after epoch 77: train: 94.99 valid: 94.99 % (1412.5 sec)\n",
      "[78,  1000] loss: 0.134, training error: 4.6%\n",
      "[78,  2000] loss: 0.147, training error: 4.9%\n",
      "Accuracy  of the network on the 50000 training images after epoch 78: train: 95.06 valid: 95.06 % (1412.5 sec)\n",
      "[79,  1000] loss: 0.133, training error: 4.8%\n",
      "[79,  2000] loss: 0.147, training error: 5.0%\n",
      "Accuracy  of the network on the 50000 training images after epoch 79: train: 94.98 valid: 94.98 % (1412.5 sec)\n",
      "[80,  1000] loss: 0.127, training error: 4.4%\n",
      "[80,  2000] loss: 0.149, training error: 5.0%\n",
      "Accuracy  of the network on the 50000 training images after epoch 80: train: 95.04 valid: 95.04 % (1412.5 sec)\n",
      "[81,  1000] loss: 0.126, training error: 4.5%\n",
      "[81,  2000] loss: 0.143, training error: 4.7%\n",
      "Accuracy  of the network on the 50000 training images after epoch 81: train: 95.25 valid: 95.25 % (1412.5 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[82,  1000] loss: 0.127, training error: 4.5%\n",
      "[82,  2000] loss: 0.137, training error: 4.7%\n",
      "Accuracy  of the network on the 50000 training images after epoch 82: train: 95.30 valid: 95.30 % (1412.5 sec)\n",
      "[83,  1000] loss: 0.124, training error: 4.2%\n",
      "[83,  2000] loss: 0.135, training error: 4.4%\n",
      "Accuracy  of the network on the 50000 training images after epoch 83: train: 95.55 valid: 95.55 % (1412.5 sec)\n",
      "[84,  1000] loss: 0.127, training error: 4.4%\n",
      "[84,  2000] loss: 0.144, training error: 4.7%\n",
      "Accuracy  of the network on the 50000 training images after epoch 84: train: 95.27 valid: 95.27 % (1412.5 sec)\n",
      "[85,  1000] loss: 0.127, training error: 4.5%\n",
      "[85,  2000] loss: 0.134, training error: 4.7%\n",
      "Accuracy  of the network on the 50000 training images after epoch 85: train: 95.30 valid: 95.30 % (1412.5 sec)\n",
      "[86,  1000] loss: 0.120, training error: 4.2%\n",
      "[86,  2000] loss: 0.138, training error: 4.5%\n",
      "Accuracy  of the network on the 50000 training images after epoch 86: train: 95.48 valid: 95.48 % (1412.5 sec)\n",
      "[87,  1000] loss: 0.121, training error: 4.4%\n",
      "[87,  2000] loss: 0.134, training error: 4.6%\n",
      "Accuracy  of the network on the 50000 training images after epoch 87: train: 95.35 valid: 95.35 % (1412.5 sec)\n",
      "[88,  1000] loss: 0.123, training error: 4.3%\n",
      "[88,  2000] loss: 0.135, training error: 4.6%\n",
      "Accuracy  of the network on the 50000 training images after epoch 88: train: 95.45 valid: 95.45 % (1412.5 sec)\n",
      "[89,  1000] loss: 0.113, training error: 4.0%\n",
      "[89,  2000] loss: 0.137, training error: 4.4%\n",
      "Accuracy  of the network on the 50000 training images after epoch 89: train: 95.58 valid: 95.58 % (1412.5 sec)\n",
      "[90,  1000] loss: 0.110, training error: 3.9%\n",
      "[90,  2000] loss: 0.127, training error: 4.2%\n",
      "Accuracy  of the network on the 50000 training images after epoch 90: train: 95.83 valid: 95.83 % (1412.5 sec)\n",
      "[91,  1000] loss: 0.107, training error: 3.8%\n",
      "[91,  2000] loss: 0.128, training error: 4.1%\n",
      "Accuracy  of the network on the 50000 training images after epoch 91: train: 95.86 valid: 95.86 % (1412.5 sec)\n",
      "[92,  1000] loss: 0.117, training error: 4.0%\n",
      "[92,  2000] loss: 0.124, training error: 4.2%\n",
      "Accuracy  of the network on the 50000 training images after epoch 92: train: 95.79 valid: 95.79 % (1412.5 sec)\n",
      "[93,  1000] loss: 0.111, training error: 3.9%\n",
      "[93,  2000] loss: 0.131, training error: 4.3%\n",
      "Accuracy  of the network on the 50000 training images after epoch 93: train: 95.69 valid: 95.69 % (1412.5 sec)\n",
      "[94,  1000] loss: 0.110, training error: 3.9%\n",
      "[94,  2000] loss: 0.122, training error: 4.1%\n",
      "Accuracy  of the network on the 50000 training images after epoch 94: train: 95.93 valid: 95.93 % (1412.5 sec)\n",
      "[95,  1000] loss: 0.115, training error: 4.0%\n",
      "[95,  2000] loss: 0.124, training error: 4.2%\n",
      "Accuracy  of the network on the 50000 training images after epoch 95: train: 95.82 valid: 95.82 % (1412.5 sec)\n",
      "[96,  1000] loss: 0.108, training error: 3.7%\n",
      "[96,  2000] loss: 0.125, training error: 4.0%\n",
      "Accuracy  of the network on the 50000 training images after epoch 96: train: 96.01 valid: 96.01 % (1412.5 sec)\n",
      "[97,  1000] loss: 0.105, training error: 3.8%\n",
      "[97,  2000] loss: 0.125, training error: 4.2%\n",
      "Accuracy  of the network on the 50000 training images after epoch 97: train: 95.82 valid: 95.82 % (1412.5 sec)\n",
      "[98,  1000] loss: 0.109, training error: 3.8%\n",
      "[98,  2000] loss: 0.118, training error: 4.0%\n",
      "Accuracy  of the network on the 50000 training images after epoch 98: train: 95.95 valid: 95.95 % (1412.5 sec)\n",
      "[99,  1000] loss: 0.110, training error: 3.9%\n",
      "[99,  2000] loss: 0.121, training error: 4.1%\n",
      "Accuracy  of the network on the 50000 training images after epoch 99: train: 95.91 valid: 95.91 % (1412.5 sec)\n",
      "[100,  1000] loss: 0.113, training error: 3.9%\n",
      "[100,  2000] loss: 0.120, training error: 4.1%\n",
      "Accuracy  of the network on the 50000 training images after epoch 100: train: 95.87 valid: 95.87 % (1412.5 sec)\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "training_acc_vect = np.zeros(num_epochs)\n",
    "valid_acc_vect = np.zeros(num_epochs)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# initialize weights and biases\n",
    "#nn.init.kaiming_uniform_(net.conv1.weight, nonlinearity = 'relu')\n",
    "#stdv = 1./np.sqrt(net.conv1.bias.size(0))\n",
    "#nn.init.uniform_(net.conv1.bias, -stdv, stdv)\n",
    "#nn.init.kaiming_uniform_(net.conv2.weight, nonlinearity = 'relu')\n",
    "#stdv = 1./np.sqrt(net.conv2.bias.size(0))\n",
    "#nn.init.uniform_(net.conv2.bias, -stdv, stdv)\n",
    "#nn.init.kaiming_uniform_(net.conv3.weight, nonlinearity = 'relu')\n",
    "#stdv = 1./np.sqrt(net.conv3.bias.size(0))\n",
    "#nn.init.uniform_(net.conv3.bias, -stdv, stdv)\n",
    "#nn.init.kaiming_uniform_(net.fc1.weight, nonlinearity = 'relu')\n",
    "#stdv = 1./np.sqrt(net.fc1.bias.size(0))\n",
    "#nn.init.uniform_(net.fc1.bias, -stdv, stdv)\n",
    "#nn.init.kaiming_uniform_(net.fc2.weight, nonlinearity = 'relu')\n",
    "#stdv = 1./np.sqrt(net.fc2.bias.size(0))\n",
    "#nn.init.uniform_(net.fc2.bias, -stdv, stdv)\n",
    "#nn.init.kaiming_uniform_(net.fc3.weight, nonlinearity = 'relu')\n",
    "#stdv = 1./np.sqrt(net.fc3.bias.size(0))\n",
    "#nn.init.uniform_(net.fc3.bias, -stdv, stdv)\n",
    "#nn.init.kaiming_uniform_(net.fc4.weight, nonlinearity = 'relu')\n",
    "#stdv = 1./np.sqrt(net.fc4.bias.size(0))\n",
    "#nn.init.uniform_(net.fc4.bias, -stdv, stdv)\n",
    "\n",
    "training_error_log = np.zeros(int(num_epochs*len(train_labels)/log_interval))\n",
    "training_loss_log = np.zeros(int(num_epochs*len(train_labels)/log_interval))\n",
    "valid_error_vect = np.zeros(num_epochs)\n",
    "\n",
    "if use_cuda:\n",
    "    net.cuda()\n",
    "    criterion.cuda()\n",
    "\n",
    "optimizer = optim.Adam(net.parameters() , lr=0.002) \n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.0001,\n",
    "#                      momentum=0.9, weight_decay=5e-4)\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200) \n",
    "    \n",
    "    \n",
    "# train network\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times while training\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    correct_valid = 0    \n",
    "    total_valid = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data # list of [inputs, labels]\n",
    "        \n",
    "        #print(inputs.shape)\n",
    "        \n",
    "        if use_cuda:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()  \n",
    "        \n",
    "        #print(labels)\n",
    "        optimizer.zero_grad() # clear gradients\n",
    "        outputs = net(inputs) # forward step\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward() # backprop\n",
    "        optimizer.step() # optimize weights\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        running_loss += loss.item()\n",
    "        training_error = 1-correct_train/total_train\n",
    "    \n",
    "    \n",
    "        if i % log_interval == log_interval-1:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f, training error: %.1f%%' % \n",
    "                  (epoch + 1, i + 1, running_loss / log_interval, training_error*100))\n",
    "            training_loss_log[int((epoch*len(train_labels)/log_interval)+(i+1)/log_interval-1)] = running_loss/log_interval\n",
    "            training_error_log[int((epoch*len(train_labels)/log_interval)+(i+1)/log_interval-1)] = training_error\n",
    "            running_loss = 0.0    \n",
    "    \n",
    "    training_acc = correct_train / total_train * 100\n",
    "    training_acc_vect[epoch] = training_acc\n",
    "    \n",
    "    for i, data in enumerate(validloader, 0):\n",
    "        inputs, labels = data # list of [inputs, labels]   \n",
    "        \n",
    "        if use_cuda:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()        \n",
    "        \n",
    "        outputs = net(inputs) # forward step        \n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_valid += labels.size(0)    \n",
    "        correct_valid += (predicted == labels).sum().item()        \n",
    "\n",
    "        # print statistics\n",
    "        duration = time.time() - start_time        \n",
    "    \n",
    "    if split > 0:\n",
    "        valid_acc = correct_valid / total_valid * 100\n",
    "    else:\n",
    "        valid_acc = training_acc\n",
    "    valid_acc_vect[epoch] = valid_acc    \n",
    "    \n",
    "    print('Accuracy  of the network on the 50000 training images after epoch %d: train: %.2f valid: %.2f %% (%.1f sec)' % (\n",
    "        epoch + 1, training_acc, valid_acc, duration))\n",
    "    \n",
    "    # your code here to calculate the validation error after each epoch\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: train: 95.874 valid 95.874\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_vect = np.linspace(1, num_epochs, num_epochs)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(epoch_vect, 100-training_acc_vect)\n",
    "plt.plot(epoch_vect, 100-valid_acc_vect)\n",
    "plt.grid('on')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('% error')\n",
    "plt.title('DNN error (train & valid)')\n",
    "plt.legend(['train','valid'])\n",
    "\n",
    "print(\"Final Accuracy: train: %g valid %g\" % (training_acc, valid_acc))\n",
    "\n",
    "# Your code here to plot validation error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.125999999999991"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100.0-valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELPATH = './cifar10_sample.pth.tar'\n",
    "torch.save(net.state_dict(), MODELPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1025786"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in net.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate assignment grade on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_complexity = {}\n",
    "network_complexity['energy'] = 0.49993034 # Estimated energy in mJ.\n",
    "network_complexity['latency'] = 0.06274400 # Number of cycles in Million (1e6).\n",
    "network_complexity['activation'] = 131072 # Activation size in byte. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "Base Score: 100, Loss: 1.79248\n",
      "Final Score: 100\n"
     ]
    }
   ],
   "source": [
    "#accuracy = 1-valid_error_vect[-1]\n",
    "def get_score(accuracy, network_complexity):\n",
    "    error_rate = (1-accuracy) * 100\n",
    "    error_rate = 19\n",
    "    print(str(error_rate))\n",
    "    loss = error_rate / 12 + network_complexity['latency'] / 0.3\n",
    "    \n",
    "    if error_rate > 50:\n",
    "        return (0, loss)\n",
    "    elif network_complexity['activation'] > 1000000:\n",
    "        return (0, loss)\n",
    "    else:\n",
    "        score = 0\n",
    "        if network_complexity['energy'] > 2:\n",
    "            score += 0\n",
    "        elif network_complexity['energy'] > 1.5:\n",
    "            score += 5\n",
    "        elif network_complexity['energy'] > 1:\n",
    "            score += 10\n",
    "        elif network_complexity['energy'] > 0.5:\n",
    "            score += 15\n",
    "        else:\n",
    "            score += 20\n",
    "            \n",
    "        if network_complexity['latency'] > 1:\n",
    "            score += 0\n",
    "        elif network_complexity['latency'] > 0.5:\n",
    "            score += 5\n",
    "        elif network_complexity['latency'] > 0.25:\n",
    "            score += 10\n",
    "        elif network_complexity['latency'] > 0.1:\n",
    "            score += 15\n",
    "        else:\n",
    "            score += 20\n",
    "            \n",
    "        if error_rate < 5:\n",
    "            score += 80\n",
    "        elif error_rate < 10:\n",
    "            score += 70\n",
    "        elif error_rate < 20:\n",
    "            score += 60\n",
    "        elif error_rate < 30:\n",
    "            score += 50\n",
    "        elif error_rate < 40:\n",
    "            score += 40\n",
    "        else:\n",
    "            score += 30\n",
    "            \n",
    "        return (score, loss)\n",
    "\n",
    "base_score, loss = get_score(valid_acc/100.0, network_complexity)\n",
    "    \n",
    "# Calculated at the end of the competition based on everyones loss\n",
    "competition_bonus = 0\n",
    "final_score = base_score + (competition_bonus if base_score > 0 else 0)\n",
    "\n",
    "print(\"Base Score: %d, Loss: %g\" % (base_score, loss))\n",
    "print(\"Final Score: %d\" % (final_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([300000, 1, 3, 32, 32])\n",
      "12000.0\n",
      "Test data processed: 1000/300000\n",
      "Test data processed: 6000/300000\n",
      "Test data processed: 11000/300000\n",
      "Test data processed: 16000/300000\n",
      "Test data processed: 21000/300000\n",
      "Test data processed: 26000/300000\n",
      "Test data processed: 31000/300000\n",
      "Test data processed: 36000/300000\n",
      "Test data processed: 41000/300000\n",
      "Test data processed: 46000/300000\n",
      "Test data processed: 51000/300000\n",
      "Test data processed: 56000/300000\n",
      "Test data processed: 61000/300000\n",
      "Test data processed: 66000/300000\n",
      "Test data processed: 71000/300000\n",
      "Test data processed: 76000/300000\n",
      "Test data processed: 81000/300000\n",
      "Test data processed: 86000/300000\n",
      "Test data processed: 91000/300000\n",
      "Test data processed: 96000/300000\n",
      "Test data processed: 101000/300000\n",
      "Test data processed: 106000/300000\n",
      "Test data processed: 111000/300000\n",
      "Test data processed: 116000/300000\n",
      "Test data processed: 121000/300000\n",
      "Test data processed: 126000/300000\n",
      "Test data processed: 131000/300000\n",
      "Test data processed: 136000/300000\n",
      "Test data processed: 141000/300000\n",
      "Test data processed: 146000/300000\n",
      "Test data processed: 151000/300000\n",
      "Test data processed: 156000/300000\n",
      "Test data processed: 161000/300000\n",
      "Test data processed: 166000/300000\n",
      "Test data processed: 171000/300000\n",
      "Test data processed: 176000/300000\n",
      "Test data processed: 181000/300000\n",
      "Test data processed: 186000/300000\n",
      "Test data processed: 191000/300000\n",
      "Test data processed: 196000/300000\n",
      "Test data processed: 201000/300000\n",
      "Test data processed: 206000/300000\n",
      "Test data processed: 211000/300000\n",
      "Test data processed: 216000/300000\n",
      "Test data processed: 221000/300000\n",
      "Test data processed: 226000/300000\n",
      "Test data processed: 231000/300000\n",
      "Test data processed: 236000/300000\n",
      "Test data processed: 241000/300000\n",
      "Test data processed: 246000/300000\n",
      "Test data processed: 251000/300000\n",
      "Test data processed: 256000/300000\n",
      "Test data processed: 261000/300000\n",
      "Test data processed: 266000/300000\n",
      "Test data processed: 271000/300000\n",
      "Test data processed: 276000/300000\n",
      "Test data processed: 281000/300000\n",
      "Test data processed: 286000/300000\n",
      "Test data processed: 291000/300000\n",
      "Test data processed: 296000/300000\n",
      "Writing file\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "def create_submission(labels):\n",
    "    now = time.time()\n",
    "    now_str = datetime.datetime.fromtimestamp(now).strftime('%m%d-%H%M%S')\n",
    "    complexity_str = '{:.4f}-{:.4f}-{}'.format(network_complexity['energy'], \\\n",
    "                                               network_complexity['latency'], \\\n",
    "                                               network_complexity['activation']).replace('.', 'p')\n",
    "    filename = 'submission-%s-%s.csv' % (complexity_str, now_str)\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for n in range(labels.shape[0]):\n",
    "            f.write(\"%d,%d\\n\" % (n,labels[n]))\n",
    "    return now_str, filename\n",
    "\n",
    "test_images = np.load(\"dataset/test_data.npy\")\n",
    "\n",
    "# convert to torch format\n",
    "test_images = torch.from_numpy(np.expand_dims(test_images, axis=1))\n",
    "dummy_lbls = torch.zeros(test_images.shape[0])\n",
    "\n",
    "print(test_images.shape) \n",
    "\n",
    "test_result = torch.zeros(test_images.shape[0])\n",
    "\n",
    "bt_sz=25\n",
    "\n",
    "print(test_images.shape[0]/bt_sz)\n",
    "\n",
    "# test on validation data\n",
    "with torch.no_grad():\n",
    "    for i in range(int(test_images.shape[0]/bt_sz)):\n",
    "        images = test_images[(i*bt_sz):(i*bt_sz + bt_sz)]\n",
    "        images = (images/255.0)*2.0-1 # normalization [-1 to 1]\n",
    "        images = images.float() # convert to torch format\n",
    "        if use_cuda:\n",
    "            images =images.cuda()\n",
    "        #print(images.squeeze().shape)    \n",
    "        outputs = net(images.squeeze())\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        #print(str(predicted.cpu().numpy()))\n",
    "        test_result[(i*bt_sz):(i*bt_sz + bt_sz)] = predicted\n",
    "        #print((i*bt_sz) % 1000)\n",
    "        if (i*bt_sz) % 5000 == 1000-bt_sz:\n",
    "            print('Test data processed: %d/300000' % (i*bt_sz+bt_sz))\n",
    "\n",
    "            \n",
    "print(\"Writing file\")\n",
    "            \n",
    "now_str, filename = create_submission(test_result.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(valid_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
