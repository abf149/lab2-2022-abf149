{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time, os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "%matplotlib inline\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "log_interval = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "# GPU setup\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"Using {}\".format('GPU' if use_cuda else 'CPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 32, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "def read_labels(label_file):\n",
    "    labels = np.zeros(50000).astype(np.uint8)\n",
    "    with open(label_file, 'r') as f:\n",
    "        n, header_seen = 0, False\n",
    "        for line in f:\n",
    "            if not header_seen:\n",
    "                header_seen = True\n",
    "                continue\n",
    "            labels[n] = int(line.strip().split(',')[1])\n",
    "            n += 1\n",
    "    return labels\n",
    "\n",
    "train_labels = read_labels(\"dataset/train_labels.csv\")\n",
    "\n",
    "train_images = np.load(\"dataset/train_data.npy\")\n",
    "\n",
    "num_train = len(train_images)\n",
    "indices = list(range(num_train))\n",
    "split = 0\n",
    "\n",
    "# shuffle data\n",
    "np.random.seed(8256)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "class CIFAR10Dataset(Dataset):\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        #transforms.ToPILImage(),\n",
    "        transforms.RandomAffine(0.5,translate=(0.05,0.05),scale=(0.9,1.1)),\n",
    "        transforms.RandomHorizontalFlip()\n",
    "        #transforms.RandomVerticalFlip()\n",
    "        #transforms.ToTensor()\n",
    "    ])    \n",
    "    \n",
    "    apply_transform=False\n",
    "    \n",
    "    def __init__(self, lbls, imgs):\n",
    "        self.samples = [(torch.from_numpy(imgs[idx]),lbls[idx].item()) for idx in range(len(lbls))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        res = []\n",
    "        \n",
    "        if self.apply_transform:\n",
    "            res = self.transform(self.samples[idx][0])\n",
    "            \n",
    "            res = res + torch.normal(0, 255.0*0.0005, size=(3,32,32))\n",
    "            \n",
    "        else:\n",
    "            res = self.samples[idx][0]\n",
    "            \n",
    "            \n",
    "        return (res*2.0/255.0 - 1.0,self.samples[idx][1])\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "trainset_noxform = CIFAR10Dataset(train_labels,train_images)\n",
    "trainset_noxform.apply_transform=False\n",
    "\n",
    "trainset_xform = CIFAR10Dataset(train_labels,train_images)\n",
    "trainset_xform.apply_transform=True\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset_xform, batch_size=25, sampler=train_sampler, shuffle=False)\n",
    "\n",
    "validloader = torch.utils.data.DataLoader(trainset_noxform, batch_size=25, sampler=valid_sampler, shuffle=False)\n",
    "\n",
    "plt.figure(1, figsize=(10,5))\n",
    "\n",
    "print(np.transpose(torch.nn.functional.pad(trainset_noxform[0][0],(10,10), \"reflect\").numpy()).shape)\n",
    "\n",
    "# No transform\n",
    "for idx in range(8):\n",
    "    plt.subplot(2,8,idx+1)\n",
    "    plt.imshow(np.transpose(trainset_noxform[1][0].numpy()))\n",
    "    plt.title(\"%s\" % (class_names[train_labels[1]]))\n",
    "    plt.axis('off')\n",
    "\n",
    "# Transform\n",
    "for idx in range(8):\n",
    "    plt.subplot(2,8,idx+9)\n",
    "    plt.imshow(np.transpose(trainset_xform[1][0].numpy()))\n",
    "    plt.title(\"%s\" % (class_names[train_labels[1]]))\n",
    "    plt.axis('off')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(trainset_noxform[0][0].numpy()>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 5)\n",
    "        self.conv1_bn = nn.BatchNorm2d(64)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(64, 32, 5)\n",
    "        self.conv2_bn = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3)\n",
    "        self.conv3_bn = nn.BatchNorm2d(64)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 120)\n",
    "        self.fc1_bn = nn.BatchNorm1d(120)        \n",
    "        self.dropout1 = nn.Dropout(p=0.5)        \n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc2_bn = nn.BatchNorm1d(84)\n",
    "        self.dropout2 = nn.Dropout(p=0.5)        \n",
    "        self.fc3 = nn.Linear(84, 84)\n",
    "        self.fc3_bn = nn.BatchNorm1d(84)\n",
    "        self.dropout3 = nn.Dropout(p=0.5)        \n",
    "        self.fc4 = nn.Linear(84, 10)\n",
    "        self.fc4_bn = nn.BatchNorm1d(10)\n",
    "        self.dropout4 = nn.Dropout(p=0.5)        \n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1_bn(self.conv1(x))))\n",
    "        x = F.relu(self.conv2_bn(self.conv2(x)))\n",
    "        x = F.relu(self.conv3_bn(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        #x = self.dropout1(x)\n",
    "        x = F.relu((self.fc1(x)))\n",
    "        x = F.relu((self.fc2(x)))\n",
    "        x = (self.fc3(x))\n",
    "        x = ((self.fc4(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "#net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "#optimizer = optim.Adam([var1, var2], lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/kuangliu/pytorch-cifar/blob/master/models/resnet.py\n",
    "\n",
    "'''ResNet in PyTorch.\n",
    "For Pre-activation ResNet, see 'preact_resnet.py'.\n",
    "Reference:\n",
    "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
    "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    " #       self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "class ResNetEff(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNetEff, self).__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, self.in_planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_planes)\n",
    "        self.layer1 = self._make_layer(block, self.in_planes, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 16, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 16, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 16, num_blocks[3], stride=2)\n",
    "        self.layer5 = self._make_layer(block, 32, num_blocks[4], stride=2)\n",
    "        self.layer6 = self._make_layer(block, 64, num_blocks[5], stride=2)\n",
    "        self.layer7 = self._make_layer(block, 128, num_blocks[6], stride=2)\n",
    "        self.layer8 = self._make_layer(block, 128, num_blocks[7], stride=1)\n",
    "        self.linear = nn.Linear(128*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        \n",
    "        out = self.layer6(out)\n",
    "        #print(out.shape)\n",
    "        out = self.layer7(out)\n",
    "        out = self.layer8(out)\n",
    "        #print(out.shape)\n",
    "        out = F.avg_pool2d(out, 1)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out    \n",
    "\n",
    "def ResNetMake():\n",
    "    return ResNetEff(BasicBlock, [2, 2, 2, 2, 2, 2, 2, 1])    \n",
    "    \n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet50():\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet101():\n",
    "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "\n",
    "def ResNet152():\n",
    "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
    "\n",
    "\n",
    "def test():\n",
    "    net = ResNet18()\n",
    "    y = net(torch.randn(1, 3, 32, 32))\n",
    "    print(y.size())\n",
    "    \n",
    "    \n",
    "net = ResNetMake()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "#optimizer = optim.Adam([var1, var2], lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1000] loss: 1.956, training error: 72.0%\n",
      "[1,  2000] loss: 1.653, training error: 66.6%\n",
      "Accuracy  of the network on the 50000 training images after epoch 1: train: 33.36 valid: 33.36 % (1412.5 sec)\n",
      "[2,  1000] loss: 1.501, training error: 54.6%\n",
      "[2,  2000] loss: 1.378, training error: 52.0%\n",
      "Accuracy  of the network on the 50000 training images after epoch 2: train: 47.96 valid: 47.96 % (1412.5 sec)\n",
      "[3,  1000] loss: 1.270, training error: 45.8%\n",
      "[3,  2000] loss: 1.198, training error: 44.2%\n",
      "Accuracy  of the network on the 50000 training images after epoch 3: train: 55.78 valid: 55.78 % (1412.5 sec)\n",
      "[4,  1000] loss: 1.119, training error: 40.0%\n",
      "[4,  2000] loss: 1.075, training error: 39.2%\n",
      "Accuracy  of the network on the 50000 training images after epoch 4: train: 60.82 valid: 60.82 % (1412.5 sec)\n",
      "[5,  1000] loss: 1.020, training error: 36.0%\n",
      "[5,  2000] loss: 0.994, training error: 35.6%\n",
      "Accuracy  of the network on the 50000 training images after epoch 5: train: 64.40 valid: 64.40 % (1412.5 sec)\n",
      "[6,  1000] loss: 0.959, training error: 33.8%\n",
      "[6,  2000] loss: 0.908, training error: 32.9%\n",
      "Accuracy  of the network on the 50000 training images after epoch 6: train: 67.06 valid: 67.06 % (1412.5 sec)\n",
      "[7,  1000] loss: 0.893, training error: 32.0%\n",
      "[7,  2000] loss: 0.871, training error: 31.2%\n",
      "Accuracy  of the network on the 50000 training images after epoch 7: train: 68.76 valid: 68.76 % (1412.5 sec)\n",
      "[8,  1000] loss: 0.842, training error: 29.7%\n",
      "[8,  2000] loss: 0.833, training error: 29.4%\n",
      "Accuracy  of the network on the 50000 training images after epoch 8: train: 70.59 valid: 70.59 % (1412.5 sec)\n",
      "[9,  1000] loss: 0.799, training error: 28.1%\n",
      "[9,  2000] loss: 0.807, training error: 28.1%\n",
      "Accuracy  of the network on the 50000 training images after epoch 9: train: 71.90 valid: 71.90 % (1412.5 sec)\n",
      "[10,  1000] loss: 0.786, training error: 27.8%\n",
      "[10,  2000] loss: 0.779, training error: 27.5%\n",
      "Accuracy  of the network on the 50000 training images after epoch 10: train: 72.54 valid: 72.54 % (1412.5 sec)\n",
      "[11,  1000] loss: 0.763, training error: 26.8%\n",
      "[11,  2000] loss: 0.748, training error: 26.4%\n",
      "Accuracy  of the network on the 50000 training images after epoch 11: train: 73.59 valid: 73.59 % (1412.5 sec)\n",
      "[12,  1000] loss: 0.730, training error: 25.6%\n",
      "[12,  2000] loss: 0.723, training error: 25.4%\n",
      "Accuracy  of the network on the 50000 training images after epoch 12: train: 74.59 valid: 74.59 % (1412.5 sec)\n",
      "[13,  1000] loss: 0.709, training error: 24.8%\n",
      "[13,  2000] loss: 0.709, training error: 24.8%\n",
      "Accuracy  of the network on the 50000 training images after epoch 13: train: 75.21 valid: 75.21 % (1412.5 sec)\n",
      "[14,  1000] loss: 0.698, training error: 24.5%\n",
      "[14,  2000] loss: 0.691, training error: 24.2%\n",
      "Accuracy  of the network on the 50000 training images after epoch 14: train: 75.78 valid: 75.78 % (1412.5 sec)\n",
      "[15,  1000] loss: 0.677, training error: 23.7%\n",
      "[15,  2000] loss: 0.680, training error: 23.6%\n",
      "Accuracy  of the network on the 50000 training images after epoch 15: train: 76.37 valid: 76.37 % (1412.5 sec)\n",
      "[16,  1000] loss: 0.661, training error: 23.1%\n",
      "[16,  2000] loss: 0.671, training error: 23.2%\n",
      "Accuracy  of the network on the 50000 training images after epoch 16: train: 76.83 valid: 76.83 % (1412.5 sec)\n",
      "[17,  1000] loss: 0.652, training error: 22.7%\n",
      "[17,  2000] loss: 0.644, training error: 22.6%\n",
      "Accuracy  of the network on the 50000 training images after epoch 17: train: 77.43 valid: 77.43 % (1412.5 sec)\n",
      "[18,  1000] loss: 0.640, training error: 22.1%\n",
      "[18,  2000] loss: 0.644, training error: 22.3%\n",
      "Accuracy  of the network on the 50000 training images after epoch 18: train: 77.74 valid: 77.74 % (1412.5 sec)\n",
      "[19,  1000] loss: 0.627, training error: 21.9%\n",
      "[19,  2000] loss: 0.629, training error: 21.8%\n",
      "Accuracy  of the network on the 50000 training images after epoch 19: train: 78.25 valid: 78.25 % (1412.5 sec)\n",
      "[20,  1000] loss: 0.625, training error: 21.7%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-71618bd80fa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# optimize weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abf149/.local/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abf149/.local/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abf149/.local/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    116\u001b[0m                    \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                    eps=group['eps'])\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abf149/.local/lib/python3.7/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_acc_vect = np.zeros(num_epochs)\n",
    "valid_acc_vect = np.zeros(num_epochs)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# initialize weights and biases\n",
    "#nn.init.kaiming_uniform_(net.conv1.weight, nonlinearity = 'relu')\n",
    "#stdv = 1./np.sqrt(net.conv1.bias.size(0))\n",
    "#nn.init.uniform_(net.conv1.bias, -stdv, stdv)\n",
    "#nn.init.kaiming_uniform_(net.conv2.weight, nonlinearity = 'relu')\n",
    "#stdv = 1./np.sqrt(net.conv2.bias.size(0))\n",
    "#nn.init.uniform_(net.conv2.bias, -stdv, stdv)\n",
    "#nn.init.kaiming_uniform_(net.conv3.weight, nonlinearity = 'relu')\n",
    "#stdv = 1./np.sqrt(net.conv3.bias.size(0))\n",
    "#nn.init.uniform_(net.conv3.bias, -stdv, stdv)\n",
    "#nn.init.kaiming_uniform_(net.fc1.weight, nonlinearity = 'relu')\n",
    "#stdv = 1./np.sqrt(net.fc1.bias.size(0))\n",
    "#nn.init.uniform_(net.fc1.bias, -stdv, stdv)\n",
    "#nn.init.kaiming_uniform_(net.fc2.weight, nonlinearity = 'relu')\n",
    "#stdv = 1./np.sqrt(net.fc2.bias.size(0))\n",
    "#nn.init.uniform_(net.fc2.bias, -stdv, stdv)\n",
    "#nn.init.kaiming_uniform_(net.fc3.weight, nonlinearity = 'relu')\n",
    "#stdv = 1./np.sqrt(net.fc3.bias.size(0))\n",
    "#nn.init.uniform_(net.fc3.bias, -stdv, stdv)\n",
    "#nn.init.kaiming_uniform_(net.fc4.weight, nonlinearity = 'relu')\n",
    "#stdv = 1./np.sqrt(net.fc4.bias.size(0))\n",
    "#nn.init.uniform_(net.fc4.bias, -stdv, stdv)\n",
    "\n",
    "training_error_log = np.zeros(int(num_epochs*len(train_labels)/log_interval))\n",
    "training_loss_log = np.zeros(int(num_epochs*len(train_labels)/log_interval))\n",
    "valid_error_vect = np.zeros(num_epochs)\n",
    "\n",
    "if use_cuda:\n",
    "    net.cuda()\n",
    "    criterion.cuda()\n",
    "\n",
    "optimizer = optim.Adam(net.parameters() , lr=0.002) \n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.0001,\n",
    "#                      momentum=0.9, weight_decay=5e-4)\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200) \n",
    "    \n",
    "    \n",
    "# train network\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times while training\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    correct_valid = 0    \n",
    "    total_valid = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data # list of [inputs, labels]\n",
    "        \n",
    "        #print(inputs.shape)\n",
    "        \n",
    "        if use_cuda:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()  \n",
    "        \n",
    "        #print(labels)\n",
    "        optimizer.zero_grad() # clear gradients\n",
    "        outputs = net(inputs) # forward step\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward() # backprop\n",
    "        optimizer.step() # optimize weights\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        running_loss += loss.item()\n",
    "        training_error = 1-correct_train/total_train\n",
    "    \n",
    "    \n",
    "        if i % log_interval == log_interval-1:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f, training error: %.1f%%' % \n",
    "                  (epoch + 1, i + 1, running_loss / log_interval, training_error*100))\n",
    "            training_loss_log[int((epoch*len(train_labels)/log_interval)+(i+1)/log_interval-1)] = running_loss/log_interval\n",
    "            training_error_log[int((epoch*len(train_labels)/log_interval)+(i+1)/log_interval-1)] = training_error\n",
    "            running_loss = 0.0    \n",
    "    \n",
    "    training_acc = correct_train / total_train * 100\n",
    "    training_acc_vect[epoch] = training_acc\n",
    "    \n",
    "    for i, data in enumerate(validloader, 0):\n",
    "        inputs, labels = data # list of [inputs, labels]   \n",
    "        \n",
    "        if use_cuda:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()        \n",
    "        \n",
    "        outputs = net(inputs) # forward step        \n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_valid += labels.size(0)    \n",
    "        correct_valid += (predicted == labels).sum().item()        \n",
    "\n",
    "        # print statistics\n",
    "        duration = time.time() - start_time        \n",
    "    \n",
    "    if split > 0:\n",
    "        valid_acc = correct_valid / total_valid * 100\n",
    "    else:\n",
    "        valid_acc = training_acc\n",
    "    valid_acc_vect[epoch] = valid_acc    \n",
    "    \n",
    "    print('Accuracy  of the network on the 50000 training images after epoch %d: train: %.2f valid: %.2f %% (%.1f sec)' % (\n",
    "        epoch + 1, training_acc, valid_acc, duration))\n",
    "    \n",
    "    # your code here to calculate the validation error after each epoch\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_vect = np.linspace(1, num_epochs, num_epochs)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(epoch_vect, 100-training_acc_vect)\n",
    "plt.plot(epoch_vect, 100-valid_acc_vect)\n",
    "plt.grid('on')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('% error')\n",
    "plt.title('DNN error (train & valid)')\n",
    "plt.legend(['train','valid'])\n",
    "\n",
    "print(\"Final Accuracy: train: %g valid %g\" % (training_acc, valid_acc))\n",
    "\n",
    "# Your code here to plot validation error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100.0-valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELPATH = './cifar10_sample.pth.tar'\n",
    "torch.save(net.state_dict(), MODELPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in net.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate assignment grade on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_complexity = {}\n",
    "network_complexity['energy'] = 0.49993034 # Estimated energy in mJ.\n",
    "network_complexity['latency'] = 0.06274400 # Number of cycles in Million (1e6).\n",
    "network_complexity['activation'] = 131072 # Activation size in byte. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy = 1-valid_error_vect[-1]\n",
    "def get_score(accuracy, network_complexity):\n",
    "    error_rate = (1-accuracy) * 100\n",
    "    #error_rate = 20\n",
    "    print(str(error_rate))\n",
    "    loss = error_rate / 12 + network_complexity['latency'] / 0.3\n",
    "    \n",
    "    if error_rate > 50:\n",
    "        return (0, loss)\n",
    "    elif network_complexity['activation'] > 1000000:\n",
    "        return (0, loss)\n",
    "    else:\n",
    "        score = 0\n",
    "        if network_complexity['energy'] > 2:\n",
    "            score += 0\n",
    "        elif network_complexity['energy'] > 1.5:\n",
    "            score += 5\n",
    "        elif network_complexity['energy'] > 1:\n",
    "            score += 10\n",
    "        elif network_complexity['energy'] > 0.5:\n",
    "            score += 15\n",
    "        else:\n",
    "            score += 20\n",
    "            \n",
    "        if network_complexity['latency'] > 1:\n",
    "            score += 0\n",
    "        elif network_complexity['latency'] > 0.5:\n",
    "            score += 5\n",
    "        elif network_complexity['latency'] > 0.25:\n",
    "            score += 10\n",
    "        elif network_complexity['latency'] > 0.1:\n",
    "            score += 15\n",
    "        else:\n",
    "            score += 20\n",
    "            \n",
    "        if error_rate < 5:\n",
    "            score += 80\n",
    "        elif error_rate < 10:\n",
    "            score += 70\n",
    "        elif error_rate < 20:\n",
    "            score += 60\n",
    "        elif error_rate < 30:\n",
    "            score += 50\n",
    "        elif error_rate < 40:\n",
    "            score += 40\n",
    "        else:\n",
    "            score += 30\n",
    "            \n",
    "        return (score, loss)\n",
    "\n",
    "base_score, loss = get_score(valid_acc/100.0, network_complexity)\n",
    "    \n",
    "# Calculated at the end of the competition based on everyones loss\n",
    "competition_bonus = 0\n",
    "final_score = base_score + (competition_bonus if base_score > 0 else 0)\n",
    "\n",
    "print(\"Base Score: %d, Loss: %g\" % (base_score, loss))\n",
    "print(\"Final Score: %d\" % (final_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([300000, 1, 3, 32, 32])\n",
      "12000.0\n",
      "Test data processed: 1000/300000\n",
      "Test data processed: 6000/300000\n",
      "Test data processed: 11000/300000\n",
      "Test data processed: 16000/300000\n",
      "Test data processed: 21000/300000\n",
      "Test data processed: 26000/300000\n",
      "Test data processed: 31000/300000\n",
      "Test data processed: 36000/300000\n",
      "Test data processed: 41000/300000\n",
      "Test data processed: 46000/300000\n",
      "Test data processed: 51000/300000\n",
      "Test data processed: 56000/300000\n",
      "Test data processed: 61000/300000\n",
      "Test data processed: 66000/300000\n",
      "Test data processed: 71000/300000\n",
      "Test data processed: 76000/300000\n",
      "Test data processed: 81000/300000\n",
      "Test data processed: 86000/300000\n",
      "Test data processed: 91000/300000\n",
      "Test data processed: 96000/300000\n",
      "Test data processed: 101000/300000\n",
      "Test data processed: 106000/300000\n",
      "Test data processed: 111000/300000\n",
      "Test data processed: 116000/300000\n",
      "Test data processed: 121000/300000\n",
      "Test data processed: 126000/300000\n",
      "Test data processed: 131000/300000\n",
      "Test data processed: 136000/300000\n",
      "Test data processed: 141000/300000\n",
      "Test data processed: 146000/300000\n",
      "Test data processed: 151000/300000\n",
      "Test data processed: 156000/300000\n",
      "Test data processed: 161000/300000\n",
      "Test data processed: 166000/300000\n",
      "Test data processed: 171000/300000\n",
      "Test data processed: 176000/300000\n",
      "Test data processed: 181000/300000\n",
      "Test data processed: 186000/300000\n",
      "Test data processed: 191000/300000\n",
      "Test data processed: 196000/300000\n",
      "Test data processed: 201000/300000\n",
      "Test data processed: 206000/300000\n",
      "Test data processed: 211000/300000\n",
      "Test data processed: 216000/300000\n",
      "Test data processed: 221000/300000\n",
      "Test data processed: 226000/300000\n",
      "Test data processed: 231000/300000\n",
      "Test data processed: 236000/300000\n",
      "Test data processed: 241000/300000\n",
      "Test data processed: 246000/300000\n",
      "Test data processed: 251000/300000\n",
      "Test data processed: 256000/300000\n",
      "Test data processed: 261000/300000\n",
      "Test data processed: 266000/300000\n",
      "Test data processed: 271000/300000\n",
      "Test data processed: 276000/300000\n",
      "Test data processed: 281000/300000\n",
      "Test data processed: 286000/300000\n",
      "Test data processed: 291000/300000\n",
      "Test data processed: 296000/300000\n",
      "Writing file\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "def create_submission(labels):\n",
    "    now = time.time()\n",
    "    now_str = datetime.datetime.fromtimestamp(now).strftime('%m%d-%H%M%S')\n",
    "    complexity_str = '{:.4f}-{:.4f}-{}'.format(network_complexity['energy'], \\\n",
    "                                               network_complexity['latency'], \\\n",
    "                                               network_complexity['activation']).replace('.', 'p')\n",
    "    filename = 'submission-%s-%s.csv' % (complexity_str, now_str)\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for n in range(labels.shape[0]):\n",
    "            f.write(\"%d,%d\\n\" % (n,labels[n]))\n",
    "    return now_str, filename\n",
    "\n",
    "test_images = np.load(\"dataset/test_data.npy\")\n",
    "\n",
    "# convert to torch format\n",
    "test_images = torch.from_numpy(np.expand_dims(test_images, axis=1))\n",
    "dummy_lbls = torch.zeros(test_images.shape[0])\n",
    "\n",
    "print(test_images.shape) \n",
    "\n",
    "test_result = torch.zeros(test_images.shape[0])\n",
    "\n",
    "bt_sz=25\n",
    "\n",
    "print(test_images.shape[0]/bt_sz)\n",
    "\n",
    "# test on validation data\n",
    "with torch.no_grad():\n",
    "    for i in range(int(test_images.shape[0]/bt_sz)):\n",
    "        images = test_images[(i*bt_sz):(i*bt_sz + bt_sz)]\n",
    "        images = (images/255.0)*2.0-1 # normalization [-1 to 1]\n",
    "        images = images.float() # convert to torch format\n",
    "        if use_cuda:\n",
    "            images =images.cuda()\n",
    "        #print(images.squeeze().shape)    \n",
    "        outputs = net(images.squeeze())\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        #print(str(predicted.cpu().numpy()))\n",
    "        test_result[(i*bt_sz):(i*bt_sz + bt_sz)] = predicted\n",
    "        #print((i*bt_sz) % 1000)\n",
    "        if (i*bt_sz) % 5000 == 1000-bt_sz:\n",
    "            print('Test data processed: %d/300000' % (i*bt_sz+bt_sz))\n",
    "\n",
    "            \n",
    "print(\"Writing file\")\n",
    "            \n",
    "now_str, filename = create_submission(test_result.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(valid_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
